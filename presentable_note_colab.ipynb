{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "presentable_note.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPgQUo12p4WTaWXQRef/qlZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ozgekadioglu/Deposit_Next_NN/blob/main/presentable_note_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Packages"
      ],
      "metadata": {
        "id": "VnTRBVU7firW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.callbacks import CSVLogger\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import tensorflow as tf\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import random as python_random\n",
        "\n",
        "pd.options.display.max_rows = 200 #sets the max rows head() shows.\n",
        "\n",
        "SEED = 42\n",
        "import os\n",
        "import random as rn\n",
        "import numpy as np\n",
        "import tensorflow\n",
        "def reset_seeds():\n",
        "  os.environ['PYTHONHASHSEED']=str(SEED)\n",
        "  np.random.seed(SEED)\n",
        "  tensorflow.random.set_seed(SEED)\n",
        "  rn.seed(SEED)"
      ],
      "metadata": {
        "id": "dH98ooc7fmBc"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Data"
      ],
      "metadata": {
        "id": "_E11T4dhfkp6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('data.csv')"
      ],
      "metadata": {
        "id": "gWOfqu1BfqfZ"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Exploration"
      ],
      "metadata": {
        "id": "4SlUxkybfv7z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axes = plt.subplots(nrows=1, ncols=4, figsize=[8, 4])\n",
        "data.tenure.plot.box(ax=axes[0])\n",
        "data.withdrawal.plot.box(ax=axes[1])\n",
        "data.turnover.plot.box(ax=axes[2])\n",
        "data.deposit.plot.box(ax=axes[3])\n",
        "\n",
        "data.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 559
        },
        "id": "sUSwbbPOf0F6",
        "outputId": "897904a3-84cd-4337-9774-7becc0190859"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             tenure       deposit      turnover    withdrawal  deposit_next\n",
              "count  20000.000000  2.000000e+04  2.000000e+04  2.000000e+04  20000.000000\n",
              "mean    1864.481550  1.369928e+04  9.769238e+04  1.006292e+04    508.521096\n",
              "std     1981.166128  6.977305e+04  6.342309e+05  5.414502e+04   1999.365001\n",
              "min        0.000000  2.175000e+01  0.000000e+00  0.000000e+00      0.000000\n",
              "25%      197.000000  1.376875e+02  4.154825e+02  0.000000e+00      0.000000\n",
              "50%     1254.000000  8.297000e+02  3.382435e+03  3.289600e+02      0.000000\n",
              "75%     2970.000000  4.825380e+03  2.602971e+04  3.507213e+03    214.595000\n",
              "max     7969.000000  2.851920e+06  3.815992e+07  3.328575e+06  94871.490000"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b325032f-f740-400e-a4b6-53d940481f43\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tenure</th>\n",
              "      <th>deposit</th>\n",
              "      <th>turnover</th>\n",
              "      <th>withdrawal</th>\n",
              "      <th>deposit_next</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>20000.000000</td>\n",
              "      <td>2.000000e+04</td>\n",
              "      <td>2.000000e+04</td>\n",
              "      <td>2.000000e+04</td>\n",
              "      <td>20000.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>1864.481550</td>\n",
              "      <td>1.369928e+04</td>\n",
              "      <td>9.769238e+04</td>\n",
              "      <td>1.006292e+04</td>\n",
              "      <td>508.521096</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1981.166128</td>\n",
              "      <td>6.977305e+04</td>\n",
              "      <td>6.342309e+05</td>\n",
              "      <td>5.414502e+04</td>\n",
              "      <td>1999.365001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.175000e+01</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>197.000000</td>\n",
              "      <td>1.376875e+02</td>\n",
              "      <td>4.154825e+02</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>1254.000000</td>\n",
              "      <td>8.297000e+02</td>\n",
              "      <td>3.382435e+03</td>\n",
              "      <td>3.289600e+02</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>2970.000000</td>\n",
              "      <td>4.825380e+03</td>\n",
              "      <td>2.602971e+04</td>\n",
              "      <td>3.507213e+03</td>\n",
              "      <td>214.595000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>7969.000000</td>\n",
              "      <td>2.851920e+06</td>\n",
              "      <td>3.815992e+07</td>\n",
              "      <td>3.328575e+06</td>\n",
              "      <td>94871.490000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b325032f-f740-400e-a4b6-53d940481f43')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b325032f-f740-400e-a4b6-53d940481f43 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b325032f-f740-400e-a4b6-53d940481f43');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x288 with 4 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAewAAAEDCAYAAAD3ODc3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dfXiU5Zn///eHh0ABW0FREURotRbER1KQLethdOvT9ld7/NSW4O5ik++yWqR2111Acxy12sYqbbdfDdvtFxuq9isprrttWapYfg09FBUVBW0gWlnBGnxCAQU0CUnO3x/3NXEmTsgEJjO5Z87XccyRe665ZnJOrtxzzX3d131eMjOcc845178NyHcAzjnnnOuZd9jOOedcDHiH7ZxzzsWAd9jOOedcDHiH7ZxzzsWAd9jOOedcDHiH7XJO0jJJb0tqyLD+VyVtkbRZ0vK+js/1Tm/aU9KPJW0Ktz9J2pOLGF3v+D7aP8mvw3a5JulcYB9wn5lN6aHuycADwPlmtlvSMWb2di7idJnpTXt2ed584Cwzq+iz4Nwh8X20f/IjbJdzZvYosCu5TNJnJK2W9KykxyR9Ljz098C/mdnu8Fz/IOhnetmeycqBupwE6XrF99H+yTts118sBeab2VTgn4GfhPLPAp+V9Lik9ZIuzluErje6a08AJJ0ITATq8xCbOzS+j+bZoHwH4JykEcBfAP8hKVE8JPwcBJwMnAeMAx6VdJqZ+bnPfqqH9kyYBTxoZu25jM0dGt9H+wfvsF1/MADYY2ZnpnmsCXjKzA4A2yT9iejD4ZlcBuh65WDtmTALmJejeNzh8320H/AhcZd3ZvY+0Y5+JYAiZ4SHf030zR1JRxMNv72SjzhdZnpoT8K5z5HAk3kK0fWS76P9g3fYLuck1RF9WJ8iqUlSJXAVUCnpeWAzcFmo/gjwrqQtwFrgX8zs3XzE7dLrZXtCdHT9S/NLVPot30f7J7+sy7kiImkgsAHYYWZf6vLYEOA+YCrwLvA1M9ue8yCdc2n5EbZzxeV6oLGbxyqB3WZ2EvBj4I6cReWc61G/nnR29NFH24QJE/IdRlF79tln3zGz0dl6PW/T/GltbeWII45g79697wHr0lS5DPhO2H4QWCJJBxu69vbMP99HC093bdqvO+wJEyawYcOGfIdR1CS9ms3X8zbNnyuuuIKf//znlJaWvtVNlbHAawBm1ibpPeAo4J3kSpLmAnMBxo8f7+2ZZ76PFp7u2tSHxJ0rAqtWreKYY45h6tSph/1aZrbUzErNrHT06Kwd2DnneuAdtnNF4PHHH2flypWEoc5PA+dL+r9dqu0ATgCQNAj4FNHkM+dcP+AdtnNF4Pvf/z5NTU1s374domtk683sb7pUWwnMCdtXhDp+GYlz/US/PoftnOtbkm4FNpjZSqAW+IWkrUQLP8zKa3DOuRQZHWFL+sewzmmDpDpJQyVNlPSUpK2SVkgqCXWHhPtbw+MTkl7nxlD+kqSL+uYtOed6sDdxDbaZfTt01phZs5ldaWYnmdk0M/NsVc71Iz122JLGAt8ESsO6qAOJvnnfAfw4XLO5m+gaTujmWk5Jk8PzTgUuBn4SkjgUpLq6OqZMmcLAgQOZMmUKdXW+imCceXsWHm/TwlIU7WlmB73x0aUeo4iG0FcBFxFd6jEo1JkBPBK2HwFmhO1BoZ6AG4Ebk163s153t6lTp1ocLV++3CQZ0HmTZMuXL893aL1GNFza4/9Jprc4tuny5ctt4sSJVl9fb62trVZfX28TJ06MZXuaZbdN49ieZoXVpr6PFlZ7mnXfphk1IFF2pH3ATuB+4Ghga9LjJwANYbsBGJf02P+E+kuAv0kqrwWuSPO75hKlTtwwfvz4nP2BsmnAgAEpnXXiNmDAgHyH1mv+YWB26qmnWn19fUpZfX29nXrqqXmK6PB4h11Yber7aGG1p1n3bZrJkPhIogxIE4HjgeFEQ9p9wgrgGs+Ojo5elbv+rbGxkZkzZ6aUzZw5k8bG7jJ8uv7O27SwFEt7ZjLp7K+AbWa206L1Tv8L+AJwZLhWE6JFy3eE7e6u5ewsT/Mc5/qtSZMmsW5daibPdevWMWnSpDxF5A6Xt2lhKZb2zKTD/jNwjqRhkgRcACSWUbsi1JkD/CZsd3ct50pgVphFPpFogfOns/M2nOs7VVVVVFZWsnbtWg4cOMDatWuprKykqqoq36G5Q+RtWliKpT17vA7bzJ6S9CDwHNAGbASWAr8Ffinpe6GsNjwl7bWcZrZZ0gNEnX0bMM/M2rP8fpzLuvLycgDmz59PY2MjkyZNorq6urPcxY+3aWEplvbs1+thl5aWWhyT0EcDEen15793OpKeNbPSbL1eXNu0kGSzTb0988/30cLTXZt6alLnnHMuBrzDds4552LAO2znnHMuBrzDds4552LAO2znnHMuBrzDds4552LAO2znnHOxVwyrdfWYOMU555zrz+rq6qiqqqK2tpaZM2eybt06KiujFZ8LKXmKH2E7VwSam5uZNm0aZ5xxBsCpkm7pWkfS1ZJ2StoUbv8r95E613vV1dXU1tZSVlbG4MGDKSsro7a2lurq6nyHllV+hO1cERgyZAj19fWMGDECSVuAiyU9bGbru1RdYWbX5SNG5w6Vr9blnCsYkhgxYkTnXWAw0TrtzsWer9blnCso7e3tnHnmmQBnAGvM7Kk01S6X9IKkByWdkOZx5/odX63LFbXm5mbOPfdcgMmSNgMPmtnNyXUkDQHuA6YSrXn+NTPbnutYXWYGDhzIpk2bkPQCME3SFDNrSKry30CdmbVI+gfgXuD8rq8jaS4wF2D8+PG5CN25gyqW1br8CNullTjnSbQc6plE5zzP6VKtEthtZicBPwbuyG2U7hC1E61nf3FyoZm9a2Yt4e7PiL6IfYyZLTWzUjMrHT16dN9G6lyGysvLaWhooL29nYaGhoLrrME7bNeNLuc8B5P+nOdlREdhAA8CF+hga4u6vNm5cyd79uxJ3BXwReDF5DqSxiTd/TJQWDN2nIs577Bdt9rb2wEmA2+T/pznWOA1ADNrA94Djur6OpLmStogacPOnTv7NmiX1htvvEFZWRmnn346RG26xsxWSbpV0pdDtW9K2izpeeCbwNV5Ctc5l0aPHbakU5Kuy9wk6X1J35I0StIaSS+HnyNDfUm6S9LWMHnl7KTXmhPqvyxpTl++sXyZsOi3+Q4hawYOHAjRkPg4wjnPQ3kdH0LNv9NPP52NGzfywgsvAGw2s1sBzOzbZrYybN9oZqea2RlmVmZmLx7sNV3+vPbaa5SVlTF58mSIrqu/vmsdSedJei/ps/vbuY/UZVOPHbaZvWRmZ5rZmUTntD4AfgUsAn5vZicDvw/3AS4BTg63ucC/A0gaBdwMTAemATcnOvlCsv32v853CFlnZntIc84T2AGcACBpEPAposlnzrk+NGjQIH70ox+xZcsWiE5dzJM0OU3VxxKf34kvaS6+ejskfgHwP2b2KqnnL+8FvhK2LwPus8h64MhwbuwiomG4XWa2G1jDxzsA108kn/OU9AnSnPMEVgKJkZIrgHoz82t7netjY8aM4eyzOwcvO4g67bH5i8jlQm877FlAIqP6sWb2Rth+Ezg2bHee1wyaQll35SkK4Xxnd31WnPqyxDlPovOdz5D+nGctcJSkrcA/8dEoi3Mud0qAs4B019XPkPS8pIclnZrjuFyWZdxhSyohmjn6H10fC0dVWemNCuV8p5lhZpy4cFXndpwkznkCW8xsSjfnPJvN7EozO8nMppnZK/mM2blis2/fPoDPAN8ys/e7PPwccKKZnQHUAL/u7nUK4UCpGFbr6s0R9iXAc2b2Vrj/VuIykPDz7VDeeV4zGBfKuit3zjnXSwcOHODyyy8H2GVm/9X1cTN738z2he2HgMGSjk73WnE/UEqs1lVTU0NzczM1NTVUVVUVXKfdmw67nI+GwyH1/OUc4DdJ5X8XZoufA7wXhs4fAS6UNDJMNrswlDnnnOsFM6OysjKRK/utdHUkHZfIiyBpGtHnfUFOCvXVupJIGk406egfkopvBx6QVAm8Cnw1lD8EXApsJZpR/nUAM9sl6btE50MBbjWzXYf9Dpxzrsg8/vjj/OIXv+C0006DKH3wJuAmYDyAmf2UaCLotZLagA+BWYU6KbRYVuvKqMM2s/10SYhhZu8SzRrvWteAed28zjJgWe/DdM45lzBz5szOeTGStphZadc6ZrYEWJLr2PIhsVpXmCgL+GpdzjnnXL/jq3U555xzMVAsq3V5h+2ccy72ysvLC66D7sqHxJ1zzrkY8A7bOVeUiiHRRjEphvb0IXHnXNFJJNqora1l5syZrFu3jsrKSoCCH1YtRMXSnn6E7ZwrOsWSaKNYFEt7eoftnCs6xZJoo1gUS3t6h+2cKzqJRBvJCjHRRrEolvb0Dtu5ItDc3My0adM444wzAE6VdEvXOpKGSFohaaukpyRNyHWcuVIsiTaKRbG0p086c64IDBkyhPr6ekaMGIGkLcDFkh42s/VJ1SqB3WZ2kqRZwB3A1/IScB8rlkQbxaJY2tM7bOeKgCRGjBjReRcYzMfXsL8M+E7YfhBYIkmFumBEMSTaKCbF0J4+JO5ckWhvb+fMM88EOANYY2ZPdakyFngNwMzagPfosuiPcy5/vMN2rkgMHDiQTZs2AbwATJM05VBeR9JcSRskbdi5c2dWY3TOdc87bOeKTzuwFri4S/kO4AQASYOATwHvdn2ymS01s1IzKx09enRfx+qcC7zDdq4I7Ny5kz179iTuCvgi8GKXaiuBOWH7CqC+UM9fOxdHGXXYko6U9KCkFyU1SpohaZSkNZJeDj9HhrqSdFe4NOQFSWcnvc6cUP9lSXO6/40u31577bXEYvCnStos6fqudSSdJ+k9SZvC7du5j9Rl4o033qCsrIzTTz8dYDLROexVkm6V9OVQrRY4StJW4J+ARXkK1zmXRqazxO8EVpvZFZJKgGHATcDvzex2SYuIdu6FwCXAyeE2Hfh3YLqkUcDNQCnR7NRnJa00s91ZfUcuKwYNGsSPfvQjpk6duhkoI2qvNWa2pUvVx8zsS3kI0fXC6aefzsaNGwGQtNnMbgUws84vWWbWDFyZnwidcz3p8Qhb0qeAc4m+fWNmrWa2h+gSkHtDtXuBr4Tty4D7LLIeOFLSGOAiom/1u0InvYaPn0Nz/cSYMWM4++xocMTM9gKNRLOInXPO5UEmQ+ITgZ3AzyVtlPQzScOBY83sjVDnTeDYsN15aUjQFMq6K0/hM1D7n5Dx6iyg62VAADMkPS/pYUmndvN8b1PnnDtMmXTYg4CzgX83s7OA/XQ5txUmpmRlcorPQO13BgD/CXzLzN7v8thzwIlmdgZQA/w63Qt4mzrn3OHLpMNuApqSkiw8SNSBvxWGugk/3w6Pd14aEowLZd2Vu37qwIEDAJ8B7jez/+r6uJm9b2b7wvZDwGBJR+c2SuecKw49dthm9ibwmqRTQtEFwBZSLwGZA/wmbK8E/i7MFj8HeC8MnT8CXChpZJhRfmEoc/2QmSUWgG82s39NV0fScZIUtqcR/T997Lpd55xzhy/TWeLzgfvDDPFXgK8TfTg/IKkSeBX4aqj7EHApsBX4INTFzHZJ+i7wTKh3q5ntysq7cFn3+OOP84tf/ALgCEmbQvFNwHgAM/sp0bW610pqAz4EZvl1u8451zcy6rDNbBPR5VhdXZCmrgHzunmdZcCy3gTo8mPmzJmYGZK2mFm6tsfMlgBLchyac84VJc905pxzzsWAd9jOORdDGWYj7DbzpIsf77Cdcy6GEtkIgc3AOcA8SZO7VEvOPDmXKPOki6lMJ50555zrR8aMGcOYMWOAKBuhpEQ2wuT0wZ2ZJ4H1YV2IMUlJr1yM+BG2c87F3EGyEXqGyQLiHbZzzsXbwbIRZsSzEcaDd9jOORdTPWUjxDNMFhTvsJ1zLoYyyUZI95knXQz5pDPnnIuhDLMRps086eLJO2znnIuhDLMRdpt50sWPD4k7VwQSSTYmT54MUaKNdEk2zpP0nqRN4fbt3EfqnOuOH2E7VwQSSTbOPvtswvW68yStMbMtXao+ZmZfykeMzrmD8w7buSKQnGQD6ADSJdlwzvVjPiTuXPEpIX2SDYAZkp6X9LCkU9M92ZNsuP6orq6OKVOmMHDgQKZMmUJdXV2+Q8o6P8J2rojs27cPout2/zZNko3ngBPNbJ+kS4FfE+WgTmFmS4GlAKWlpb7+ucu7uro6qqqqqK2tZebMmaxbty5xyRvl5eV5ji57/AjbuSJx4MABLr/8coBd6ZJsmNn7ZrYvbD8EDJZ0dI7DdK7Xqqurqa2tpaysjMGDB1NWVkZtbS3V1dX5Di2rMuqwJW2X9Mcwc3RDKBslaY2kl8PPkaG82+XcJM0J9V+WNKdv3pJzrqtEko1JkyYBvJWujqTjJClsTyP6fHg3d1E6d2gaGxtpampKGRJvamqisbEx36FlVW+GxMvM7J2k+4uA35vZ7ZIWhfsLSV3ObTrRcm7TJY0CbgZKAQOelbTSzHZn4X045w4ikWTjtNNOA5gcEm10TbJxBXCtpDbgQ2BWuI7XuX7t+OOPZ8GCBSxfvrxzSHz27Nkcf/zx+Q4tqw7nHPZlwHlh+17gD0Qddtrl3ELdNWa2C0DSGuBioPBmBjjXzySSbADdJtowsyXAklzH5lw2NDc3U1FRwauvvsqJJ55Ic3MzI0aMyHdYWZXpOWwDfifpWUlzQ9mxSTlp3wSODdvdLefmy7w555zLuh07djB48GAAwlkdBg8ezI4dhbXOSaYd9kwzO5touHuepHOTHwxH01kZOvNl3pxzzvVGSUkJixYtYtu2bbS3t7Nt2zYWLVpESUlJvkPLqow6bDPbEX6+DfwKmAa8FYa6CT/fDtW7W87Nl3mLkUQqS6I0lpu7SWXZ7QRD55zLldbWVmpqali7di0HDhxg7dq11NTU0Nramu/QsqrHDlvScElHJLaBC4EGomXbEjO95wC/CdvdLef2CHChpJFhRvmFocz1Q4lUlsBm4ByikZXJXaolTzCcSzTB0Dnncmry5MlcddVVzJ8/n6FDhzJ//nyuuuqqRO78gpHJpLNjgV+F8wKDgOVmtlrSM8ADkiqBV4Gvhvppl3Mzs12Svgs8E+rdmpiA5vqf5FSWZrY35J/umsoy7QRDX2/XOZdLVVVVaROnFNp12D122Gb2CnBGmvJ3gQvSlHe7nJuZLQOW9T5Ml0+SJpA+lWV3EwlTOuwwUXEuwPjx4/sqTOdckUpkM5s/fz6NjY1MmjSJ6urqgspyBp6a1PVsAPCfwLfSpLLMiKeydM71tfLy8oLroLvy1KSuWwcOHIAo7/T96VJZ4hMJnXMuZ7zDdmklUlkCzWb2r91U626CoXPOuSzzDtullUhlCRwRcshvknSppGskXROqPQS8QjTB8G7gG3kKt88Vw9J9zrn+zc9hu7QSqSy7S2MJB59gWEiKZek+51z/5kfYzvWgWJbucy7OimEUzDts53pQLEv3ORdXiVGwmpoampubqampoaqqquA6be+wnevB8ccfz8KFC1M+DBYuXFhwS/c5F1fFMgrmHbZzGei6LLQvE+1c/9HY2MjMmTNTymbOnFlwo2DeYTvXg9dff53Fixen5ClevHgxr7/+er5Dc84BkyZN4pZbbkk5bXXLLbcwadKkfIeWVd5hO9eDSZMmMW7cOBoaGmhvb6ehoYFx48YV3IeBc3FVVlbGHXfcQUVFBXv37qWiooI77rgjseJgwfAO27keVFVVUVlZmbJ0X2VlJVVVVfkOLWOJ5VLD6kWn+nKp8VdRUcExxxwDcGq6xyWdJ+m9pDwK385thLmzdu1aFi5cyLJlyzjiiCNYtmwZCxcuZO3atfkOLav8OmznelAICwsklks9++yzCSuvzZO0xsySV19LXi51OtFyqdPzEK7LwNVXX811113H1KlTD1btMTP7Uq5iypfGxkY2btzI9773vc6yAwcO8P3vfz+PUWWfd9jOZSDuCwskL5cKdAC+XGrMnXvuuWzfvj3fYfQLkyZNYt26dSlD4OvWrSu401beYTtXfErw5VKLxQxJzwOvA/9sZpvTVYp7m1ZVVfG1r32N4cOH8+qrr3LiiSeyf/9+7rzzznyHllV+Dtu5IrJv3z6IVmA7rOVSzazUzEpHjx6d1fhcVj0HnGhmZwA1wK+7q1hIbSop3yH0mYw7bEkDJW2UtCrcnyjpqTBBZYWkklA+JNzfGh6fkPQaN4bylyRdlO0345zr3oEDB7j88ssBdvlyqYXPzN43s31h+yFgsKSj8xxWn6iurmbFihVs27aN9vZ2tm3bxooVK4o6ccr1ROe9Eu4AfmxmJwG7gcpQXgnsDuU/DvWQNBmYRTSj8WLgJ5IGHl74zrlMJJZLDef03uqmmi+XWkAkHadwuClpGtHn/bv5japveOKUJJLGAX8N/CzcF3A+8GCoci/wlbB9WbhPePyCUP8y4Jdm1mJm24iWZJyWjTfhnDu4xHKp9fX1AJOLfbnUQlBeXs6MGTMAhkhqklTZpT2vABrCOey7gFlWoCn6EpPOkhXzpLP/DSwAjgj3jwL2mFlbuJ+YnAJJE1fMrE3Se6H+WGB90msmP6dT3Cc/ONcfJZZLBbpdMrVYlktNqKuro7q6uvNSvaqqqlhdCZBY2ELSc9205xJgSa7jyofkSWd//vOfGT9+fHFOOpP0JeBtM3s2B/EU1OQH51z/VCyrOxWTlpYWduzYQUdHBzt27KClpSXfIWVdJkPiXwC+LGk78EuiofA7gSMlJY7QkyendE5cCY9/iui8iU9occ71C9XV1cyePTslP/zs2bMLbpJSsViwYAHDhg3jkUceobW1lUceeYRhw4axYMGCfIeWVT122GZ2o5mNM7MJRJPG6s3sKmAt0TkSgDnAb8L2ynCf8Hh9GGpbCcwKs8gnEmVTejpr78Q55zK0ZcsW7r///pQj7Pvvv58tW7b0/GTX7zQ1NXHfffelLK9533330dTUlO/QsupwrsNeCPyTpK1E56hrQ3ktcFQo/ydgEUC4YP8BosxKq4F5ZtZ+GL/fOecOSUlJCfPnz0/5gJ8/fz4lJSX5Ds25bvWqwzazPyTy0prZK2Y2zcxOMrMrzawllDeH+yeFx19Jen61mX3GzE4xs4ez+1ac6zt1dXUpS/f5uc54a21tZcmSJSkLuixZsoTW1tZ8h+YOwbhx45gzZ05Ke86ZM4dx48blO7Ss8kxnzvXAJygVnsmTJ6c9hx1WM3Mxs3jxYtra2qioqGDo0KFUVFTQ1tbG4sWL8x1aVnmH7dLypfs+Ul1dTW1tbcrwaW1trU9QirGqqiqWLl3K/v37MTP279/P0qVLY7VkqvtIeXk5d955J8OHDwdg+PDh3HnnnbG6TC8TvviHS8uX7vtIsWRRKlaFnHu6mMR9Rb1M+BG2S+vcc89l1KhR+Q6jXyiWLErFpFhyT7vC4h22OxwzJD0v6WFJaYfOIcpeJ2mDpA07d+7MZXxZUVVVRWVlZcqElsrKSh8+jTEfNXFx5EPi7lAllu7bJ+lSoqX7Tk5X0cyWAksBSktLY5fLODHMNn/+/M40ltXV1QU//FbIEqMmZWVlnWU+auL6Oz/CdoekmJbug6jTbmhooL29nYaGBu+sY85HTVwc+RG2OySSjgPeMjMr9KX7XOHxURMXR95hu7TKy8v5wx/+AGHpPuBmYDCAmf2UKO3stZLagA8p4KX7XGEqhlnFrrD4kLhLq66ujjfeeAPguZBLvtbMfho6a8xsiZmdamZnmNk5ZvZEfiPuW57pzDmXb36E7VwPEpnOamtrmTlzJuvWraOyshLAj9CccznjR9jO9cAznTnX/xXDKJh32M71oBCu2U2kmp0yZUrax4sp1WxCMXzAF4tiyffvHbZzPSiETGdXX301q1ev7qnaY2Z2Zrjdmou48qWuro7rr78+JZf49ddfX3Af8MWiWEbBvMN2rgeFcM2up5pNtWDBAgYOHMiyZctoaWlh2bJlDBw4kAULFuQ7NHcICmEULBM9dtiShkp6OqSg3CzpllA+UdJTkrZKWiGpJJQPCfe3hscnJL3WjaH8JUkX9dWbci6bysvLqa6uTlmKsUCv2S2KVLMATU1N3HfffSlHZPfddx9NTU35Ds0dgkIYBctEJkfYLcD5ZnYGcCZwsaRzgDuAH5vZScBuoDLUrwR2h/Ifh3pImgzMIlqu8WLgJ5IGZvPNONdXiiDTWSLV7BlADVGq2bTMbKmZlZpZ6ejRo3MWoHPdKYRRsEz02GFbZF+4OzjcDDgfeDCU3wt8JWxfFu4THr9A0fp1lwG/NLMWM9sGbAWmZeVdOOcOS7Glmh03bhxz5sxJ+YCfM2cO48aNy3do7hAUyyhYRuewJQ2UtAl4G1gD/A+wx8zaQpUmYGzYHgu8BhAefw84Krk8zXOcc3kk6bjwxZpiSDW7ePFi2traqKioYOjQoVRUVNDW1sbixYvzHZpz3coocYqZtQNnSjoS+BXwub4KSNJcYC7A+PHj++rXZNUZt/yO9z480O3jExb9Nm35pz4xmOdvvrCvwnKuUyLV7DvvvANwuqRKijjVbHl5OU888QR33303HR0dvPHGG/z93/99wR2RFYvErP/hw4enzPqHAktuZGa9ugHfBv4FeAcYFMpmAI+E7UeAGWF7UKgn4EbgxqTX6azX3W3q1KkWBycuXJXT5+USsMF6+T9ysFtc2rSQZbNN49qey5cvt4kTJ1p9fb21trZafX29TZw40ZYvX57v0DL29a9/3UaPHm3Ah5b+s1rAXUSnH18Azk5Xr+stjm06btw4O+6441La87jjjrNx48blO7RD0t0+msks8dHhyBpJnwC+CDQCa4m+lQPMAX4TtleG+4TH60MAK4FZYRb5RKK1k5/O/KuFc85lR3V1NbNnz0455zl79uxYXbebwbX1lxB9zp5MNGr577mIKx+ampq4+uqrU9rz6quvLrhZ/5kMiY8B7g0zugcAD5jZKklbgF9K+h6wEagN9WuBX0jaCuwimhmOmW2W9ACwBWgD5lk01O6cczm1ZcsW9u/fz7Jlyzrzw1dUVEqok8MAABeTSURBVPDqq6/mO7SMnXvuuWzfvv1gVS4D7gsHTOslHSlpjJm9kZMAc+znP/85dXV1ne1ZUEPhQSazxF8ws7PM7HQzm2IhA5KZvWJm08zsJDO70sxaQnlzuH9SePyVpNeqNrPPmNkpZvZw370t57LL01gWlpKSEr7whS+kHJF94QtfoKSkJN+hZVPRTPQdNGgQ+/fvp6KigiFDhlBRUcH+/fsZNKiw1rfyTGfO9aBY8hQXk5aWFlasWEFFRQV79+6loqKCFStW0NLSku/Q8iLuyXDa2tr44IMPaG5uRhLNzc188MEHtLW19fzkGPEO27keFML5TpdqyJAhTJ8+nZtuuonhw4dz0003MX36dIYMGZLv0LJpB3BC0v1xoexjLObJcIYMGcKMGTPYvXs3HR0d7N69mxkzZhRae3qH7VxPtmzZwv33359yhH3//fezZcuWfIfmDlFraytPPPEEI0eOZMCAAYwcOZInnniC1tbWfIeWTSuBv1PkHOC9Qj1/3dLSwlNPPcVtt93G/v37ue2223jqqacKbsSksAb4nesDJSUljB07lksuuYSWlhaGDBlCaWkpb7xRkJ99RWHgwCgr8ptvvtn5M27nOxPX1gNDJDUBN5N6bf1DwKVEl3V9AHw9P5H2vcQ+edNNN3HDDTd0jqBs2LAh36FllR9hO9eDlpYWHn/8cYYNGwbAsGHDePzxxwvu23sxaWtro62tjWuvvZY9e/Zw7bXXdpbFRV1dXeJL43NmNs7Mas3sp6GzTqSVnhcm+p5mZoXVeyVpaWnhySefTBkxefLJJwtuH/UO27kMDBgwgN27dwOwe/duBgzwXSfuzj//fB599FFGjRrFo48+yvnnn5/vkNwhGjRoEMOGDWPo0KGYGUOHDmXYsGGxGzXpiX/quLQqKio45phjIFpd7WPCebG7wnKpL0g6O7cR5lZHR0fK0VhHR0e+Q3KHqaGhIWVeQkNDQ75Dcoeora2N4cOHp6xvPnz48FiNmGTCO2yXlmdRSnXWWWelHI2dddZZ+Q7JHYZiuW63mEyfPp1LLrmEkpISLrnkEqZPn57vkLLOO2yX1rnnnsuoUaMOVqUzi5KZrQeOlDQmN9Hl3qZNm3jnnXcwM9555x02bdqU75DcYbjmmmv48MMP+fDDDwE6t6+55po8R+YOxahRo1i1alXKLPFVq1b19BkWO95hu0NVNFmUBgwY0NlRJ//089jxVVNTwze+8Q327NmDmbFnzx6+8Y1vUFNTk+/Q3CEYNmwYn/zkJ6mpqWHEiBHU1NTwyU9+snOiaKHwTxzX5+KeRenII49EEkcffXTKzyOPPDLfobnDkDh/bWad57FdPL3++uvcddddDB8+HEkMHz6cu+66i9dffz3foWWVd9juUBVNFqU9e/ZwzTXXpByNJe475/Jv0qRJvPTSSyllL730EpMmTcpTRH3DO2x3qIomi9KkSZO48sorU47GrrzyyoL7MHAursrKyrjtttt48cUX6ejo4MUXX+S2226jrKws36FllXfYLq3y8nJmzJgBIYuSpEpJ10hKzMp5CHiFKIvS3cA38hRqn6uqqqKyspK1a9dy4MAB1q5dS2VlJVVVVfkOzTkHLF++HCDltFVyeaHwDtul5VmUPlJeXk51dXXK4h/V1dWxWm83cV39lClT0j5ebNfVgy+ZWkh27drFrFmzUjrsWbNmsWvXrnyHllXeYTuXgfLychoaGmhvb6ehoSFWnTX4dfVd+ZKphWfVqlXs378fgP3797Nq1ao8R5R9PXbYkk6QtFbSFkmbJV0fykdJWiPp5fBzZCjv9pu6pDmh/suS5vTd23Iuu+J+NObX1aeqrq6mtraWsrIyBg8eTFlZGbW1tb5kaozt27eP+fPns3fvXubPn8++ffvyHVLWZXKE3QbcYGaTgXOAeZImA4uA35vZycDvw33o5pu6pFFEq8lMB6YBNyc6eef6syI5Gsv4uvq4X6YH0NjYSFNTU8qXsKamJhobG/MdmjtEZsYNN9zA8OHDueGGGzCzfIeUdT122Gb2hpk9F7b3Ao1EO/JlwL2h2r3AV8J2d9/ULwLWmNkuM9sNrAEuzuq7ca4PVFdXM3v27JRz2LNnzy7ao7G4X6YHcPzxx7Nw4cKUL2ELFy7k+OOPz3do7jAkkhkValKjXiXOlTQBOAt4Cjg26TKeN4Fjw3Z339Qz+gYvaS7RkTnjx4/vTXjO9YktW7bwwQcfUFtby8yZM1m3bh2VlZVs374936FlU8bX1ReKrkdghXhEVkwGDx7M2LFj+fOf/8z48ePZsWMHBw4cyHdYWZXx1xBJI4D/BL5lZu8nP2bRf3pW/tsL4du7KywlJSVcd911Kec7r7vuOkpKSvIdWjYVzXX1EGXGWrx4ccqoyeLFiwsuM1YxOXDgANu3b6ejo4Pt27cXXGcNGXbYkgYTddb3m9l/heK3EpNSws+3Q3l339SL7hu8Kwytra3U1NSkXIddU1NDa2trvkPLWOK6+pAN6vRivq4eiiczlissmcwSF1ALNJrZvyY9tBJIzPSeA/wmqTzdN/VHgAsljQyTzS4MZc71a5MnT+aqq65KORq76qqrmDx5cr5Dy1jiuvpw1PFCMV9XD1FmrDvuuIOKigr27t1LRUUFd9xxR8Flxio2JSUlSCq00a9OmRxhfwH4W+B8SZvC7VLgduCLkl4G/irch26+qZvZLuC7wDPhdmsoc65fq6qqYvny5SkTlJYvX+6ZzmJs7dq1LFy4kGXLlnHEEUewbNkyFi5cyNq1a/MdmjtEkmhtbcXMaG1tJTrWLCw9Tjozs3VAd+/8gjT1DZjXzWstA5b1JkDn8q28vJx77rmHCy64ADNDEl/84hdjlzzFfaSxsZGNGzfyve99r7PswIEDfP/7389jVO5wFMMkwsKc++5cFs2fP5/6+np++MMfsn//fn74wx9SX1/P/Pnz8x2aO0STJk3illtuSbkO+5ZbbvFz2K5f8w7buR7cfffdTJ8+nZtuuonhw4dz0003MX36dO6+++58h+YOUbGs7uQKi3fYzvWgpaWF9evXc9ttt7F//35uu+021q9fT0tLS75Dc4do+fLlaYdQC211J1dYvMN2LgMnnHBCyhH2CSec0POTXL+1a9cuRo4cyZo1a2htbWXNmjWMHDmy4FZ3coXFO2znMrB9+3ZKSkoYMGAAJSUlhZblrCgtWLAgJRnOggUL8h2ScwflHbZzGRg0aBDNzc10dHTQ3NzMoEG9yurr+qEf/OAHKclwfvCDH+Q7JOcOyjts5zLQ1tZGR0cHAB0dHbS1teU5Inc4Ro0axe7du5k9ezZDhw5l9uzZ7N69u6clSPuV1atXc8oppwBMkbSo6+OSrpa0Myl/xv/KfZQum7zDdi5D7e3tKT9dfC1ZsoQBAwbw5ptv0tHRwZtvvsmAAQNYsmRJvkPLSHt7O/PmzePhhx8G2AyUh2WPu1phZmeG289yG6XLNu+wncvQiBEjUn66+Lrnnntob29PWY6xvb2de+65J7+BZejpp5/mpJNO4tOf/jRECy/9kmhpY1fAvMN2LkP79u1L+eni63e/+x1AymmO5PL+bseOHV2vVEi7XDFwuaQXJD0oqdtLGyTNlbRB0oadO3dmO1yXJd5hO5ehxEQzn3DmYuK/gQlmdjqwBri3u4q+rHE8eIfturV69WqIJrRs9UktdE408wlnhSOupznGjh3La6+9llz0seWKzexdM0tk9/kZMDVH4bk+4h22SysxqQX4EzAZn9TiClBcT3N8/vOf5+WXX2bbtm0QLc40i2hp406SxiTd/TLQmLsIXV/wsb0sOGLSIk6792MHoBk8D+Cvsx5PNiQmtbzyyiutZtYqKTGpZUu+Y3Ou2A0aNIglS5Zw0UUXAZwKfNfMNku6FdhgZiuBb0r6MtAG7AKuzlvALiu8w86CvY23s/323ne8Exb9tg+iyY5uJrVMT1P1cknnEh2J/6OZvda1gqS5wFyA8ePH90G0zhWfSy+9lEsvvRRJDWZWDWBm3048bmY3AjfmLUCXdT4k7g5HRpNafEJL/+CJNpyLtx47bEnLJL0tqSGpbJSkNZJeDj9HhnJJuitMUnpB0tlJz5kT6r8saU7fvB2XLT6ppbB4og3n4i+TI+x7gIu7lC0Cfm9mJwO/D/cBLgFODre5wL9D1MEDNxMNqU4Dbk508q5/SkxqAUokleCTWmLNE204F389dthm9ijRhIVkl/HR8Oe9wFeSyu+zyHrgyPChfhGwxsx2mdluouHTrl8CXD+SmNQCfJaoI34gMaklTGSBaFLLZknPA9/EJ7X0W9lMtOFJNpzLj0OddHasmb0Rtt8Ejg3bY4HkcdTEh0J35R/jE5T6j0svvRSgwcxKE2U+qaWg/TdQZ2Ytkv6B6Mv4+V0rmdlSYClAaWmp5TZE54rXYU86MzMjGmLLCp+g5Fz2+ZwE5+LvUDvstxLnL8PPt0P5DiB5GC3xodBduXMuBzzRhnPxd6gd9kogMdN7DvCbpPK/C7PFzwHeC0PnjwAXShoZJptdGMqcczmQJtGGz0lwLmZ6PIctqQ44DzhaUhPRbO/bgQckVQKvAl8N1R8CLgW2Ah8AXwcws12Svgs8E+rdamZdJ7I55/qQJ9pwLt567LDNrLybhy5IU9eAed28zjJgWa+ic8455xzgmc6cc865WPAO2znnnIsB77Cdc865GPAO2znnnIsB77Cdc865GPAO2znnnIsB77Cdc865GPAO2znnnIsB77Cdc865GPAO2znnnIsB77Cdc865GPAO2znnnIsB77Cdc865GPAO2znnnIuBHpfXdJmZsOi3vX7Opz4xuA8icc45V4i8w86C7bf/dbePTVj024M+7pxzzmUi50Piki6W9JKkrZIW5fr3u8ytXr0aYEp3bSVpiKQV4fGnJE3IdYwuc6tXr+aUU06BqE29PQuA76PFJacdtqSBwL8BlwCTgXJJk3MZg8tMe3s78+bNA/gT3bdVJbDbzE4CfgzckdsoXaYS7fnwww8DbMbbM/Z8Hy0+uT7CngZsNbNXzKwV+CVwWY5jcBl4+umnOemkkwBaD9JWlwH3hu0HgQskKXdR5t+hzF3Ih0R7fvrTnwYwvD1jz/fRzMRlH81Ers9hjwVeS7rfBExPriBpLjAXYPz48bmLLEvS/XMkl8XlfPaOHTs44YQTkos+1lYktaeZtUl6DzgKeCe5Utza9LR7T0u5P+WeKQepvYjT7k0difzjnD/2QVSHx9sz1cHatGv9/tie4G2arDf7aH9tz0z0u0lnZrYUWApQWlpqeQ6n1+LSIedS3Nq06w59sAMSs37/drIu7u0J3qZdxb1Ni6U9cz0kvgNI/ko4LpS5fmbs2LG89lryYEjatupsT0mDgE8B7+YkwBzqboeP0weBt2fh8Tb9SCHso5nIdYf9DHCypImSSoBZwMocx+Ay8PnPf56XX34ZoOQgbbUSmBO2rwDqrdD2kMDMPnaLk0R7btu2DUB4e/aqvD/yfTRV3PfRTOS0wzazNuA64BGgEXjAzDbnMgaXmUGDBrFkyRKAz5LUVpJulfTlUK0WOErSVuCfAL9Mr59KtOdFF10EcCrenrH/gPd9tPioP/+TlpaW2oYNG/IdRlGT9KyZlWbr9bxN8y+bbertmX++jxae7trUc4k755xzMeAdtnPOORcD3mE755xzMeAdtnPOORcD/XrSmaSdwKv5juMwHU2XrEIxc6KZjc7WixVAm8a9PSGLbVoA7Qnxb1PfR1PFvT2hmzbt1x12IZC0IZszOF1+eXsWHm/TwlLI7elD4s4551wMeIftnHPOxYB32H1vab4DcFnl7Vl4vE0LS8G2p5/Dds4552LAj7Cdc865GPAO2znnnIsB77B7IOlISd/Idxzu0El6KLRjSltKOk/Sqgyen1G9bJG0XdLRufp9ceL7Y/GQ9B1J/5yD3/NE+DlB0uy+/n2Hwzvsnh0J9OkHRFhY3vURM7vUzPaQ5bb0dsuLXrehpIF9FEt3v8//L2LEzP4ibE4AvMOOuduBz0jaJOkHkv5F0jOSXpB0C3R+M2uUdLekzZJ+J+kT4bE/SCoN20dL2h62r5a0UlI98HtJwyUtk/S0pI2SLsvT+42d0CbfDNs/Dn9TJJ0v6f6kI9aUtgxPHyHpQUkvhroKz704lD0H/L9Jv+s7kn4h6XHgF6HtH5P0XLj9Raj3b4k1iSX9StKysF0hqTps/1rSs+F/Zm5O/ljxl9yGzySPfEhaIunqsL1d0h2h/a4M928JbfRHSZ8L9UaFdnhB0npJp0saEOofmfTaL0s6VtJoSf8Zfvczkr4QHk/5v8jlH6SQSKqS9CdJ64BTQtlnJK0O+8pjSW13j6SfStoQnvOlUD5U0s9DO2+UVBbKTw2fr5tCe58cyveFX3878Jfh8X/M+ZvPRLpF3P2WsqD9BKAhbF9IdMmAiL7srALODXXagDNDvQeAvwnbfwBKw/bRwPawfTXQBIwK929Les6RwJ+A4fl+/3G4AecA/xG2HwOeBgYDNwP/AGwPf/vOtgx1zwPeA8aF9nwSmAkMBV4DTg5t/QCwKjznO8CzwCfC/WHA0LB9MrAhbM8CfhC2nwbWh+2fAxeF7UTbfwJoAI4K97cDR+f779ofb132x/MS7RLuLwGuTvobLkh6bDswP2x/A/hZ2K4Bbg7b5wObwvadwNfD9nTg/wvby4GZYXs80Jju/8Jvh9S2U4E/hn3qk8BW4J+B3wMnJ7VFfdi+B1gd9t2TiT5PhwI3AMtCnc8Bfw7lNcBVobwkaR/el+7/qT/e/Ai7dy4Mt43Ac0T/DCeHx7aZ2aaw/SzRB0tP1pjZrqTXXiRpE1EnP5ToA8H17FlgqqRPAi1EHW8p8JdEHfjBPG1mTWbWAWwiarfPEbXnyxbtyf+3y3NWmtmHYXswcLekPwL/AUwO5Y8RfVufDGwB3pI0BpgBPBHqfFPS88B64AQ++l9y2bGiy/3/Cj+T98+ZhCNiM6sHjgr/RyuAr4U6s5Je66+AJWE/XQl8UtKI8Fjy/4Xrvb8EfmVmH5jZ+0R/36HAXwD/Ef7m/wcYk/ScB8ysw8xeBl4h2ndnEvZZM3uRKC/6Z4k+F26StJAoV3fs2srPtfSOgO+b2f9JKZQmEHUUCe1ER00QHXknvhgN7fJ6+7u89uVm9lK2gi0WZnZA0jaiUYsngBeAMuAkoLGHp3dtt0z2ieR2+0fgLeAMonZuDjHtCEOqFwOPAqOArxJ9m98r6TyiD/8ZZvaBpD/w8f8Pd3DJ+xYcfP+Cj9o6k3Z+EjhJ0mjgK8D3QvkA4Bwza06uHM6kdP197vANAPaY2ZndPN41kUi3iUXMbLmkp4C/Bh6S9A/hS1ps+BF2z/YCR4TtR4CKxDdqSWMlHdPD87cTDfUAXHGQeo8A85POoZ51yBEXp8eIhs8eDdvXABvDEXJCclsezIvABEmfCffLD1L3U8Ab4Qj9b4HkCU7rgW8lxfTPfHTE/ylgd+isP0c0rO96ltyGrwKTJQ0JX44uOITXewy4CqKrAYB3zOz98H/zK+BfiYa93w31fwfMTzxZUncdieu9R4GvSPqEpCOA/wf4ANgm6UoARc5Ies6VYc7BZ4BPAy+R2qafJRqpfEnSp4FXzOwu4DfA6V1+f6afD3njHXYPwo76uKQG4ItE57CeDEOgD9JzA/8QuFbSRqLzqN35LtHw6guSNof7LnOPEQ2VPWlmbxEd6aYMhye3pT6adPYx4ehpLvDbMGnp7YP83p8Ac8LQ9udIPcp6DBhkZluJTqGMSoppNTBIUiPRZJf1Gb/TItZlf/wm0fyChvBz4yG85HeITqe8QNQOc5IeWwH8DalD698ESsOkpS1EXwxdFpjZc0R/6+eBh4FnwkNXAZVhH9sMJE/I/TPRHJGHgWvCvvsTYED4jF5BNK+hhWiEqyEMrU8B7usSwgtAu6Tn++ukM09N6pxzLnYk3UM0SezBfMeSK36E7ZxzzsWAH2E755xzMeBH2M4551wMeIftnHPOxYB32M4551wMeIftnHPOxYB32M4551wM/P+ocRQjLcyHaAAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are lots of outliers for each input feature. After creating a benchmarking model, I will train a model for the datapoints where the outliers of tenure are removed. (outlier=3*std)"
      ],
      "metadata": {
        "id": "cpmp_9XCoSa8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Benchmark Model"
      ],
      "metadata": {
        "id": "0KJwJNNOgDvT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First model will be trained by using all the datapoints available in the dataset.\n",
        "\n",
        "*   4-layer NN was build by using fully connected layers. \n",
        "*   3 dense hidden layers with 128-64-32 neurons\n",
        "*   20,000 datapoints\n",
        "*   33% of the datapoints is kept as validation set.\n",
        "*   Input layer consists of 4 neurons: 'tenure', 'deposit', 'turnover', 'withdrawal'\n",
        "*   Activation functions were used to the layers: 'relu'\n",
        "*   Adam algorithm was used to update the NN weights.\n",
        "*   Mean Absolute Error (MAE) was chosen to be the loss function. Thus, during the training MAE is aimed to minimize.\n",
        "\n",
        "During the entire training, data will pass through the network many times. Each time it passes (1 epoch) the respective weight is updated. After each epoch we expect the loss function to decrease since the model will improve as the weights will be updated during the back-propagation.\n",
        "\n",
        "In regression problems, there are several evaluation metrics. For the current problem and the dataset, I chose to use mean absolute error because I didn't want large errors to create large biases on the evaluation. When calculating MAE, individual differences between the predicted and expected values have equal weight while in RMSE larger differences are penalized. Looking at the boxplots in the previous cell, it is seen that there are lots of outliers in our dataset. Thus, it will be more intutive to use a metric that is robust to outliers, like MAE.\n",
        "\n",
        "A very long epochs used in order to see the point after which the validation loss fluctuates with minor differences and become almost stable. The reason for this is that we aim to minimize the validation loss and achieve this in an optimal way by lowering the computational resources."
      ],
      "metadata": {
        "id": "RV3Lp-T9ohgU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reset_seeds()\n",
        "\n",
        "target = data.deposit_next\n",
        "input_features = data[['tenure', 'deposit', 'turnover', 'withdrawal']]\n",
        "\n",
        "scaler = StandardScaler()\n",
        "scaled = scaler.fit_transform(input_features)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(scaled, target, test_size=0.2, random_state=42)\n",
        "\n",
        "model_b = Sequential()\n",
        "model_b.add(Dense(128, input_shape=(4,), activation='relu'))\n",
        "model_b.add(Dropout(0.5)) \n",
        "model_b.add(Dense(64, activation='relu'))\n",
        "model_b.add(Dense(32, activation='relu'))\n",
        "model_b.add(Dense(1))\n",
        "model_b.compile(optimizer='adam', loss='mae', metrics='mae')\n",
        "\n",
        "csv_logger = CSVLogger('log.csv', append=True, separator=';')\n",
        "history=model_b.fit(X_train,y_train,epochs=800,batch_size=64,validation_data=[X_test,y_test],callbacks=[csv_logger])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WNbh79A7gIZU",
        "outputId": "39c5a7b6-428e-4588-abf4-e909ae4c5826"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 505.6315 - mae: 505.6315 - val_loss: 494.8646 - val_mae: 494.8646\n",
            "Epoch 2/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 493.2180 - mae: 493.2180 - val_loss: 485.6463 - val_mae: 485.6463\n",
            "Epoch 3/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 490.6558 - mae: 490.6558 - val_loss: 483.6958 - val_mae: 483.6958\n",
            "Epoch 4/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 489.1715 - mae: 489.1715 - val_loss: 482.4687 - val_mae: 482.4687\n",
            "Epoch 5/800\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 488.8389 - mae: 488.8389 - val_loss: 481.3282 - val_mae: 481.3282\n",
            "Epoch 6/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 487.4820 - mae: 487.4820 - val_loss: 480.5780 - val_mae: 480.5780\n",
            "Epoch 7/800\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 485.9341 - mae: 485.9341 - val_loss: 477.9800 - val_mae: 477.9800\n",
            "Epoch 8/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 484.3510 - mae: 484.3510 - val_loss: 476.4172 - val_mae: 476.4172\n",
            "Epoch 9/800\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 483.9414 - mae: 483.9414 - val_loss: 476.2113 - val_mae: 476.2113\n",
            "Epoch 10/800\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 483.3375 - mae: 483.3375 - val_loss: 476.8560 - val_mae: 476.8560\n",
            "Epoch 11/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 482.8802 - mae: 482.8802 - val_loss: 475.2643 - val_mae: 475.2643\n",
            "Epoch 12/800\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 481.0729 - mae: 481.0729 - val_loss: 473.8649 - val_mae: 473.8649\n",
            "Epoch 13/800\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 480.8364 - mae: 480.8364 - val_loss: 474.1180 - val_mae: 474.1180\n",
            "Epoch 14/800\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 480.9221 - mae: 480.9221 - val_loss: 473.9851 - val_mae: 473.9851\n",
            "Epoch 15/800\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 479.9477 - mae: 479.9477 - val_loss: 474.7882 - val_mae: 474.7882\n",
            "Epoch 16/800\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 480.4773 - mae: 480.4773 - val_loss: 474.5164 - val_mae: 474.5164\n",
            "Epoch 17/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 480.5112 - mae: 480.5112 - val_loss: 473.9994 - val_mae: 473.9994\n",
            "Epoch 18/800\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 479.5480 - mae: 479.5480 - val_loss: 473.0191 - val_mae: 473.0191\n",
            "Epoch 19/800\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 480.8021 - mae: 480.8021 - val_loss: 473.5476 - val_mae: 473.5476\n",
            "Epoch 20/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 479.5368 - mae: 479.5368 - val_loss: 472.7381 - val_mae: 472.7381\n",
            "Epoch 21/800\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 478.6965 - mae: 478.6965 - val_loss: 472.7349 - val_mae: 472.7349\n",
            "Epoch 22/800\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 478.5669 - mae: 478.5669 - val_loss: 472.9642 - val_mae: 472.9642\n",
            "Epoch 23/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 478.9609 - mae: 478.9609 - val_loss: 472.7246 - val_mae: 472.7246\n",
            "Epoch 24/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 479.1825 - mae: 479.1825 - val_loss: 472.1962 - val_mae: 472.1962\n",
            "Epoch 25/800\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 479.2416 - mae: 479.2416 - val_loss: 471.7995 - val_mae: 471.7995\n",
            "Epoch 26/800\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 477.0292 - mae: 477.0292 - val_loss: 471.6896 - val_mae: 471.6896\n",
            "Epoch 27/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 478.4864 - mae: 478.4864 - val_loss: 471.1199 - val_mae: 471.1199\n",
            "Epoch 28/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 478.1695 - mae: 478.1695 - val_loss: 471.4831 - val_mae: 471.4831\n",
            "Epoch 29/800\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 477.1918 - mae: 477.1918 - val_loss: 470.7233 - val_mae: 470.7233\n",
            "Epoch 30/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 477.0551 - mae: 477.0551 - val_loss: 470.8726 - val_mae: 470.8726\n",
            "Epoch 31/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 477.2317 - mae: 477.2317 - val_loss: 470.5347 - val_mae: 470.5347\n",
            "Epoch 32/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 476.9980 - mae: 476.9980 - val_loss: 470.3858 - val_mae: 470.3858\n",
            "Epoch 33/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 476.8196 - mae: 476.8196 - val_loss: 470.8057 - val_mae: 470.8057\n",
            "Epoch 34/800\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 477.0372 - mae: 477.0372 - val_loss: 470.8057 - val_mae: 470.8057\n",
            "Epoch 35/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 477.2247 - mae: 477.2247 - val_loss: 470.5668 - val_mae: 470.5668\n",
            "Epoch 36/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 476.9598 - mae: 476.9598 - val_loss: 470.4193 - val_mae: 470.4193\n",
            "Epoch 37/800\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 475.7108 - mae: 475.7108 - val_loss: 469.3438 - val_mae: 469.3438\n",
            "Epoch 38/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 476.8884 - mae: 476.8884 - val_loss: 469.6296 - val_mae: 469.6296\n",
            "Epoch 39/800\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 476.6221 - mae: 476.6221 - val_loss: 468.1081 - val_mae: 468.1081\n",
            "Epoch 40/800\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 476.5003 - mae: 476.5003 - val_loss: 468.9308 - val_mae: 468.9308\n",
            "Epoch 41/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 476.1010 - mae: 476.1010 - val_loss: 469.3260 - val_mae: 469.3260\n",
            "Epoch 42/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 474.8284 - mae: 474.8284 - val_loss: 468.9135 - val_mae: 468.9135\n",
            "Epoch 43/800\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 475.1745 - mae: 475.1745 - val_loss: 468.3478 - val_mae: 468.3478\n",
            "Epoch 44/800\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 474.8641 - mae: 474.8641 - val_loss: 468.4656 - val_mae: 468.4656\n",
            "Epoch 45/800\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 475.1818 - mae: 475.1818 - val_loss: 468.3110 - val_mae: 468.3110\n",
            "Epoch 46/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 474.1587 - mae: 474.1587 - val_loss: 469.3529 - val_mae: 469.3529\n",
            "Epoch 47/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 474.6170 - mae: 474.6170 - val_loss: 468.4347 - val_mae: 468.4347\n",
            "Epoch 48/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 475.2840 - mae: 475.2840 - val_loss: 468.0726 - val_mae: 468.0726\n",
            "Epoch 49/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 475.0276 - mae: 475.0276 - val_loss: 468.4018 - val_mae: 468.4018\n",
            "Epoch 50/800\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 474.6544 - mae: 474.6544 - val_loss: 468.0618 - val_mae: 468.0618\n",
            "Epoch 51/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 475.3446 - mae: 475.3446 - val_loss: 468.3891 - val_mae: 468.3891\n",
            "Epoch 52/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 475.1516 - mae: 475.1516 - val_loss: 467.9790 - val_mae: 467.9790\n",
            "Epoch 53/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 474.6910 - mae: 474.6910 - val_loss: 467.1306 - val_mae: 467.1306\n",
            "Epoch 54/800\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 474.4589 - mae: 474.4589 - val_loss: 467.0722 - val_mae: 467.0722\n",
            "Epoch 55/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 473.8490 - mae: 473.8490 - val_loss: 468.1649 - val_mae: 468.1649\n",
            "Epoch 56/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 474.2659 - mae: 474.2659 - val_loss: 466.9366 - val_mae: 466.9366\n",
            "Epoch 57/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 473.2810 - mae: 473.2810 - val_loss: 467.5803 - val_mae: 467.5803\n",
            "Epoch 58/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 474.9125 - mae: 474.9125 - val_loss: 467.8583 - val_mae: 467.8583\n",
            "Epoch 59/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 473.7369 - mae: 473.7369 - val_loss: 468.0858 - val_mae: 468.0858\n",
            "Epoch 60/800\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 473.7952 - mae: 473.7952 - val_loss: 466.1575 - val_mae: 466.1575\n",
            "Epoch 61/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 472.6795 - mae: 472.6795 - val_loss: 466.3026 - val_mae: 466.3026\n",
            "Epoch 62/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 473.8366 - mae: 473.8366 - val_loss: 466.7680 - val_mae: 466.7680\n",
            "Epoch 63/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 472.7589 - mae: 472.7589 - val_loss: 467.8099 - val_mae: 467.8099\n",
            "Epoch 64/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 473.2108 - mae: 473.2108 - val_loss: 466.7196 - val_mae: 466.7196\n",
            "Epoch 65/800\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 473.8231 - mae: 473.8231 - val_loss: 467.5049 - val_mae: 467.5049\n",
            "Epoch 66/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 471.5117 - mae: 471.5117 - val_loss: 467.2283 - val_mae: 467.2283\n",
            "Epoch 67/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 472.2626 - mae: 472.2626 - val_loss: 468.0443 - val_mae: 468.0443\n",
            "Epoch 68/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 473.1277 - mae: 473.1277 - val_loss: 467.0470 - val_mae: 467.0470\n",
            "Epoch 69/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 473.7909 - mae: 473.7909 - val_loss: 466.9466 - val_mae: 466.9466\n",
            "Epoch 70/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 472.7711 - mae: 472.7711 - val_loss: 466.9020 - val_mae: 466.9020\n",
            "Epoch 71/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 471.9086 - mae: 471.9086 - val_loss: 467.8336 - val_mae: 467.8336\n",
            "Epoch 72/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 473.2676 - mae: 473.2676 - val_loss: 468.1872 - val_mae: 468.1872\n",
            "Epoch 73/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 473.0975 - mae: 473.0975 - val_loss: 466.4265 - val_mae: 466.4265\n",
            "Epoch 74/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 473.5485 - mae: 473.5485 - val_loss: 466.0161 - val_mae: 466.0161\n",
            "Epoch 75/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 473.0129 - mae: 473.0129 - val_loss: 467.4231 - val_mae: 467.4231\n",
            "Epoch 76/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 473.1637 - mae: 473.1637 - val_loss: 466.7180 - val_mae: 466.7180\n",
            "Epoch 77/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 472.6081 - mae: 472.6081 - val_loss: 465.6445 - val_mae: 465.6445\n",
            "Epoch 78/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 472.3389 - mae: 472.3389 - val_loss: 465.2356 - val_mae: 465.2356\n",
            "Epoch 79/800\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 471.8196 - mae: 471.8196 - val_loss: 466.7508 - val_mae: 466.7508\n",
            "Epoch 80/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 473.5069 - mae: 473.5069 - val_loss: 466.6918 - val_mae: 466.6918\n",
            "Epoch 81/800\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 471.4878 - mae: 471.4878 - val_loss: 466.2244 - val_mae: 466.2244\n",
            "Epoch 82/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 471.9471 - mae: 471.9471 - val_loss: 466.2263 - val_mae: 466.2263\n",
            "Epoch 83/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 474.0118 - mae: 474.0118 - val_loss: 466.7986 - val_mae: 466.7986\n",
            "Epoch 84/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 472.5204 - mae: 472.5204 - val_loss: 465.8537 - val_mae: 465.8537\n",
            "Epoch 85/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 471.7284 - mae: 471.7284 - val_loss: 466.9116 - val_mae: 466.9116\n",
            "Epoch 86/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 472.3073 - mae: 472.3073 - val_loss: 466.3331 - val_mae: 466.3331\n",
            "Epoch 87/800\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 471.9811 - mae: 471.9811 - val_loss: 467.4292 - val_mae: 467.4292\n",
            "Epoch 88/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 471.5636 - mae: 471.5636 - val_loss: 465.7344 - val_mae: 465.7344\n",
            "Epoch 89/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 471.9747 - mae: 471.9747 - val_loss: 466.6383 - val_mae: 466.6383\n",
            "Epoch 90/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 470.9413 - mae: 470.9413 - val_loss: 465.4330 - val_mae: 465.4330\n",
            "Epoch 91/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 471.3367 - mae: 471.3367 - val_loss: 466.4376 - val_mae: 466.4376\n",
            "Epoch 92/800\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 472.2253 - mae: 472.2253 - val_loss: 466.8045 - val_mae: 466.8045\n",
            "Epoch 93/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 471.0114 - mae: 471.0114 - val_loss: 466.4001 - val_mae: 466.4001\n",
            "Epoch 94/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 472.0969 - mae: 472.0969 - val_loss: 466.7721 - val_mae: 466.7721\n",
            "Epoch 95/800\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 471.6735 - mae: 471.6735 - val_loss: 466.0909 - val_mae: 466.0909\n",
            "Epoch 96/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 472.6293 - mae: 472.6293 - val_loss: 466.1497 - val_mae: 466.1497\n",
            "Epoch 97/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 472.0626 - mae: 472.0626 - val_loss: 465.4314 - val_mae: 465.4314\n",
            "Epoch 98/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 471.9131 - mae: 471.9131 - val_loss: 466.9922 - val_mae: 466.9922\n",
            "Epoch 99/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 471.4877 - mae: 471.4877 - val_loss: 466.5785 - val_mae: 466.5785\n",
            "Epoch 100/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 471.1584 - mae: 471.1584 - val_loss: 466.8774 - val_mae: 466.8774\n",
            "Epoch 101/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 470.6344 - mae: 470.6344 - val_loss: 466.6179 - val_mae: 466.6179\n",
            "Epoch 102/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 472.5802 - mae: 472.5802 - val_loss: 465.9865 - val_mae: 465.9865\n",
            "Epoch 103/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 469.9106 - mae: 469.9106 - val_loss: 466.2258 - val_mae: 466.2258\n",
            "Epoch 104/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 470.7949 - mae: 470.7949 - val_loss: 466.7455 - val_mae: 466.7455\n",
            "Epoch 105/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 471.1200 - mae: 471.1200 - val_loss: 467.1177 - val_mae: 467.1177\n",
            "Epoch 106/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 470.7018 - mae: 470.7018 - val_loss: 465.9537 - val_mae: 465.9537\n",
            "Epoch 107/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 471.1023 - mae: 471.1023 - val_loss: 466.2214 - val_mae: 466.2214\n",
            "Epoch 108/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 471.9150 - mae: 471.9150 - val_loss: 465.7730 - val_mae: 465.7730\n",
            "Epoch 109/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 471.5132 - mae: 471.5132 - val_loss: 466.6725 - val_mae: 466.6725\n",
            "Epoch 110/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 470.6901 - mae: 470.6901 - val_loss: 466.9426 - val_mae: 466.9426\n",
            "Epoch 111/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 469.8703 - mae: 469.8703 - val_loss: 466.0134 - val_mae: 466.0134\n",
            "Epoch 112/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 469.9362 - mae: 469.9362 - val_loss: 466.7152 - val_mae: 466.7152\n",
            "Epoch 113/800\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 470.9872 - mae: 470.9872 - val_loss: 466.7288 - val_mae: 466.7288\n",
            "Epoch 114/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 471.3417 - mae: 471.3417 - val_loss: 465.6737 - val_mae: 465.6737\n",
            "Epoch 115/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 470.6320 - mae: 470.6320 - val_loss: 465.4548 - val_mae: 465.4548\n",
            "Epoch 116/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 472.1310 - mae: 472.1310 - val_loss: 466.1529 - val_mae: 466.1529\n",
            "Epoch 117/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 471.4162 - mae: 471.4162 - val_loss: 466.0535 - val_mae: 466.0535\n",
            "Epoch 118/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 470.5164 - mae: 470.5164 - val_loss: 465.9539 - val_mae: 465.9539\n",
            "Epoch 119/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 469.9698 - mae: 469.9698 - val_loss: 466.0707 - val_mae: 466.0707\n",
            "Epoch 120/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 471.5773 - mae: 471.5773 - val_loss: 466.3022 - val_mae: 466.3022\n",
            "Epoch 121/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 470.5757 - mae: 470.5757 - val_loss: 466.4521 - val_mae: 466.4521\n",
            "Epoch 122/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 471.0843 - mae: 471.0843 - val_loss: 466.3715 - val_mae: 466.3715\n",
            "Epoch 123/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 470.6253 - mae: 470.6253 - val_loss: 466.6909 - val_mae: 466.6909\n",
            "Epoch 124/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 470.8539 - mae: 470.8539 - val_loss: 465.6941 - val_mae: 465.6941\n",
            "Epoch 125/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 472.4666 - mae: 472.4666 - val_loss: 465.6564 - val_mae: 465.6564\n",
            "Epoch 126/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 469.9405 - mae: 469.9405 - val_loss: 465.4555 - val_mae: 465.4555\n",
            "Epoch 127/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 471.1954 - mae: 471.1954 - val_loss: 465.7159 - val_mae: 465.7159\n",
            "Epoch 128/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 470.4474 - mae: 470.4474 - val_loss: 465.9509 - val_mae: 465.9509\n",
            "Epoch 129/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 470.5181 - mae: 470.5181 - val_loss: 465.0302 - val_mae: 465.0302\n",
            "Epoch 130/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 470.4348 - mae: 470.4348 - val_loss: 464.6991 - val_mae: 464.6991\n",
            "Epoch 131/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 471.6996 - mae: 471.6996 - val_loss: 465.8075 - val_mae: 465.8075\n",
            "Epoch 132/800\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 469.8103 - mae: 469.8103 - val_loss: 465.4358 - val_mae: 465.4358\n",
            "Epoch 133/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 471.4676 - mae: 471.4676 - val_loss: 465.6165 - val_mae: 465.6165\n",
            "Epoch 134/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 470.0534 - mae: 470.0534 - val_loss: 464.5956 - val_mae: 464.5956\n",
            "Epoch 135/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 470.0841 - mae: 470.0841 - val_loss: 465.2783 - val_mae: 465.2783\n",
            "Epoch 136/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 468.4244 - mae: 468.4244 - val_loss: 463.2638 - val_mae: 463.2638\n",
            "Epoch 137/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 469.4135 - mae: 469.4135 - val_loss: 464.7737 - val_mae: 464.7737\n",
            "Epoch 138/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 471.4481 - mae: 471.4481 - val_loss: 465.0764 - val_mae: 465.0764\n",
            "Epoch 139/800\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 469.0190 - mae: 469.0190 - val_loss: 465.0702 - val_mae: 465.0702\n",
            "Epoch 140/800\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 469.4717 - mae: 469.4717 - val_loss: 464.7551 - val_mae: 464.7551\n",
            "Epoch 141/800\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 469.1696 - mae: 469.1696 - val_loss: 464.3327 - val_mae: 464.3327\n",
            "Epoch 142/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 471.6692 - mae: 471.6692 - val_loss: 465.2648 - val_mae: 465.2648\n",
            "Epoch 143/800\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 468.7582 - mae: 468.7582 - val_loss: 465.5497 - val_mae: 465.5497\n",
            "Epoch 144/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 470.1690 - mae: 470.1690 - val_loss: 464.4463 - val_mae: 464.4463\n",
            "Epoch 145/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 470.5156 - mae: 470.5156 - val_loss: 465.0651 - val_mae: 465.0651\n",
            "Epoch 146/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 470.1172 - mae: 470.1172 - val_loss: 465.3245 - val_mae: 465.3245\n",
            "Epoch 147/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 469.7476 - mae: 469.7476 - val_loss: 464.0031 - val_mae: 464.0031\n",
            "Epoch 148/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 470.2673 - mae: 470.2673 - val_loss: 464.8413 - val_mae: 464.8413\n",
            "Epoch 149/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 469.7170 - mae: 469.7170 - val_loss: 466.1331 - val_mae: 466.1331\n",
            "Epoch 150/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 468.7047 - mae: 468.7047 - val_loss: 464.3046 - val_mae: 464.3046\n",
            "Epoch 151/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 469.4803 - mae: 469.4803 - val_loss: 463.9417 - val_mae: 463.9417\n",
            "Epoch 152/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 469.4165 - mae: 469.4165 - val_loss: 464.7110 - val_mae: 464.7110\n",
            "Epoch 153/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 469.0262 - mae: 469.0262 - val_loss: 464.3343 - val_mae: 464.3343\n",
            "Epoch 154/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 468.9143 - mae: 468.9143 - val_loss: 465.5955 - val_mae: 465.5955\n",
            "Epoch 155/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 470.3771 - mae: 470.3771 - val_loss: 464.0991 - val_mae: 464.0991\n",
            "Epoch 156/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 470.6505 - mae: 470.6505 - val_loss: 464.9068 - val_mae: 464.9068\n",
            "Epoch 157/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 470.5005 - mae: 470.5005 - val_loss: 465.2791 - val_mae: 465.2791\n",
            "Epoch 158/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 469.9882 - mae: 469.9882 - val_loss: 465.6149 - val_mae: 465.6149\n",
            "Epoch 159/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 470.0623 - mae: 470.0623 - val_loss: 465.2605 - val_mae: 465.2605\n",
            "Epoch 160/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 468.6738 - mae: 468.6738 - val_loss: 464.0691 - val_mae: 464.0691\n",
            "Epoch 161/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 468.4261 - mae: 468.4261 - val_loss: 464.1671 - val_mae: 464.1671\n",
            "Epoch 162/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 468.4100 - mae: 468.4100 - val_loss: 465.4494 - val_mae: 465.4494\n",
            "Epoch 163/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 469.0778 - mae: 469.0778 - val_loss: 464.4514 - val_mae: 464.4514\n",
            "Epoch 164/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 469.4061 - mae: 469.4061 - val_loss: 465.9895 - val_mae: 465.9895\n",
            "Epoch 165/800\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 469.1099 - mae: 469.1099 - val_loss: 464.9874 - val_mae: 464.9874\n",
            "Epoch 166/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 470.4211 - mae: 470.4211 - val_loss: 464.0105 - val_mae: 464.0105\n",
            "Epoch 167/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 469.5664 - mae: 469.5664 - val_loss: 464.1198 - val_mae: 464.1198\n",
            "Epoch 168/800\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 468.3814 - mae: 468.3814 - val_loss: 463.7159 - val_mae: 463.7159\n",
            "Epoch 169/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 469.6387 - mae: 469.6387 - val_loss: 464.1360 - val_mae: 464.1360\n",
            "Epoch 170/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 468.3815 - mae: 468.3815 - val_loss: 462.9607 - val_mae: 462.9607\n",
            "Epoch 171/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 468.0568 - mae: 468.0568 - val_loss: 463.7345 - val_mae: 463.7345\n",
            "Epoch 172/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 468.2571 - mae: 468.2571 - val_loss: 464.5432 - val_mae: 464.5432\n",
            "Epoch 173/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 469.1400 - mae: 469.1400 - val_loss: 463.3904 - val_mae: 463.3904\n",
            "Epoch 174/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 468.2245 - mae: 468.2245 - val_loss: 466.5635 - val_mae: 466.5635\n",
            "Epoch 175/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 469.8087 - mae: 469.8087 - val_loss: 464.3870 - val_mae: 464.3870\n",
            "Epoch 176/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 468.9634 - mae: 468.9634 - val_loss: 464.2815 - val_mae: 464.2815\n",
            "Epoch 177/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 469.3663 - mae: 469.3663 - val_loss: 464.2770 - val_mae: 464.2770\n",
            "Epoch 178/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 468.4600 - mae: 468.4600 - val_loss: 462.8921 - val_mae: 462.8921\n",
            "Epoch 179/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 469.1845 - mae: 469.1845 - val_loss: 463.4586 - val_mae: 463.4586\n",
            "Epoch 180/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 469.5786 - mae: 469.5786 - val_loss: 464.4113 - val_mae: 464.4113\n",
            "Epoch 181/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 469.3025 - mae: 469.3025 - val_loss: 463.5775 - val_mae: 463.5775\n",
            "Epoch 182/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 467.3952 - mae: 467.3952 - val_loss: 463.8303 - val_mae: 463.8303\n",
            "Epoch 183/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 468.6357 - mae: 468.6357 - val_loss: 464.0455 - val_mae: 464.0455\n",
            "Epoch 184/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 468.9394 - mae: 468.9394 - val_loss: 463.5246 - val_mae: 463.5246\n",
            "Epoch 185/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 469.9986 - mae: 469.9986 - val_loss: 464.4335 - val_mae: 464.4335\n",
            "Epoch 186/800\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 468.4005 - mae: 468.4005 - val_loss: 463.9916 - val_mae: 463.9916\n",
            "Epoch 187/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 469.7415 - mae: 469.7415 - val_loss: 465.2682 - val_mae: 465.2682\n",
            "Epoch 188/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 466.8453 - mae: 466.8453 - val_loss: 463.2782 - val_mae: 463.2782\n",
            "Epoch 189/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 469.5066 - mae: 469.5066 - val_loss: 464.5094 - val_mae: 464.5094\n",
            "Epoch 190/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 468.8919 - mae: 468.8919 - val_loss: 463.7550 - val_mae: 463.7550\n",
            "Epoch 191/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 468.0511 - mae: 468.0511 - val_loss: 463.4832 - val_mae: 463.4832\n",
            "Epoch 192/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 467.7192 - mae: 467.7192 - val_loss: 463.8532 - val_mae: 463.8532\n",
            "Epoch 193/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 468.6154 - mae: 468.6154 - val_loss: 463.9366 - val_mae: 463.9366\n",
            "Epoch 194/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 468.9541 - mae: 468.9541 - val_loss: 463.9034 - val_mae: 463.9034\n",
            "Epoch 195/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 469.8528 - mae: 469.8528 - val_loss: 465.0497 - val_mae: 465.0497\n",
            "Epoch 196/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 468.0013 - mae: 468.0013 - val_loss: 464.1094 - val_mae: 464.1094\n",
            "Epoch 197/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 468.8704 - mae: 468.8704 - val_loss: 464.6859 - val_mae: 464.6859\n",
            "Epoch 198/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 467.5916 - mae: 467.5916 - val_loss: 464.7025 - val_mae: 464.7025\n",
            "Epoch 199/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 467.8172 - mae: 467.8172 - val_loss: 464.4348 - val_mae: 464.4348\n",
            "Epoch 200/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 468.2363 - mae: 468.2363 - val_loss: 463.0500 - val_mae: 463.0500\n",
            "Epoch 201/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 468.3592 - mae: 468.3592 - val_loss: 467.1711 - val_mae: 467.1711\n",
            "Epoch 202/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 466.8838 - mae: 466.8838 - val_loss: 463.6945 - val_mae: 463.6945\n",
            "Epoch 203/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 468.6816 - mae: 468.6816 - val_loss: 462.7762 - val_mae: 462.7762\n",
            "Epoch 204/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 467.7933 - mae: 467.7933 - val_loss: 463.7513 - val_mae: 463.7513\n",
            "Epoch 205/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 468.4626 - mae: 468.4626 - val_loss: 462.4745 - val_mae: 462.4745\n",
            "Epoch 206/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 467.7300 - mae: 467.7300 - val_loss: 463.3024 - val_mae: 463.3024\n",
            "Epoch 207/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 469.4130 - mae: 469.4130 - val_loss: 464.5398 - val_mae: 464.5398\n",
            "Epoch 208/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 468.2037 - mae: 468.2037 - val_loss: 463.6169 - val_mae: 463.6169\n",
            "Epoch 209/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 468.9591 - mae: 468.9591 - val_loss: 464.2220 - val_mae: 464.2220\n",
            "Epoch 210/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 469.0367 - mae: 469.0367 - val_loss: 462.9781 - val_mae: 462.9781\n",
            "Epoch 211/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 467.0356 - mae: 467.0356 - val_loss: 463.2978 - val_mae: 463.2978\n",
            "Epoch 212/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 466.8756 - mae: 466.8756 - val_loss: 462.8021 - val_mae: 462.8021\n",
            "Epoch 213/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 467.0829 - mae: 467.0829 - val_loss: 462.4457 - val_mae: 462.4457\n",
            "Epoch 214/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 468.7264 - mae: 468.7264 - val_loss: 463.5792 - val_mae: 463.5792\n",
            "Epoch 215/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 468.1532 - mae: 468.1532 - val_loss: 463.5852 - val_mae: 463.5852\n",
            "Epoch 216/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 467.5701 - mae: 467.5701 - val_loss: 464.0059 - val_mae: 464.0059\n",
            "Epoch 217/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 468.8183 - mae: 468.8183 - val_loss: 463.1415 - val_mae: 463.1415\n",
            "Epoch 218/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 468.1136 - mae: 468.1136 - val_loss: 464.7049 - val_mae: 464.7049\n",
            "Epoch 219/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 468.4220 - mae: 468.4220 - val_loss: 464.4753 - val_mae: 464.4753\n",
            "Epoch 220/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 467.3928 - mae: 467.3928 - val_loss: 463.8994 - val_mae: 463.8994\n",
            "Epoch 221/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 468.9659 - mae: 468.9659 - val_loss: 463.2311 - val_mae: 463.2311\n",
            "Epoch 222/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 467.7267 - mae: 467.7267 - val_loss: 463.3856 - val_mae: 463.3856\n",
            "Epoch 223/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 467.6828 - mae: 467.6828 - val_loss: 462.9381 - val_mae: 462.9381\n",
            "Epoch 224/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 466.9135 - mae: 466.9135 - val_loss: 462.5258 - val_mae: 462.5258\n",
            "Epoch 225/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 469.8073 - mae: 469.8073 - val_loss: 463.8479 - val_mae: 463.8479\n",
            "Epoch 226/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 468.6241 - mae: 468.6241 - val_loss: 464.9399 - val_mae: 464.9399\n",
            "Epoch 227/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 466.6566 - mae: 466.6566 - val_loss: 462.5679 - val_mae: 462.5679\n",
            "Epoch 228/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 468.0858 - mae: 468.0858 - val_loss: 464.8671 - val_mae: 464.8671\n",
            "Epoch 229/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 466.8893 - mae: 466.8893 - val_loss: 463.5862 - val_mae: 463.5862\n",
            "Epoch 230/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 467.9837 - mae: 467.9837 - val_loss: 462.3403 - val_mae: 462.3403\n",
            "Epoch 231/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 466.8000 - mae: 466.8000 - val_loss: 462.5493 - val_mae: 462.5493\n",
            "Epoch 232/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 468.4749 - mae: 468.4749 - val_loss: 462.8286 - val_mae: 462.8286\n",
            "Epoch 233/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 466.4810 - mae: 466.4810 - val_loss: 461.6888 - val_mae: 461.6888\n",
            "Epoch 234/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 466.8832 - mae: 466.8832 - val_loss: 463.1564 - val_mae: 463.1564\n",
            "Epoch 235/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 468.1114 - mae: 468.1114 - val_loss: 462.4393 - val_mae: 462.4393\n",
            "Epoch 236/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 467.8608 - mae: 467.8608 - val_loss: 462.1404 - val_mae: 462.1404\n",
            "Epoch 237/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 467.8239 - mae: 467.8239 - val_loss: 462.5552 - val_mae: 462.5552\n",
            "Epoch 238/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 467.5743 - mae: 467.5743 - val_loss: 463.0676 - val_mae: 463.0676\n",
            "Epoch 239/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 469.2906 - mae: 469.2906 - val_loss: 463.0950 - val_mae: 463.0950\n",
            "Epoch 240/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 466.9835 - mae: 466.9835 - val_loss: 463.8958 - val_mae: 463.8958\n",
            "Epoch 241/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 466.5049 - mae: 466.5049 - val_loss: 462.8573 - val_mae: 462.8573\n",
            "Epoch 242/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 466.9223 - mae: 466.9223 - val_loss: 463.8672 - val_mae: 463.8672\n",
            "Epoch 243/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 467.6048 - mae: 467.6048 - val_loss: 462.8158 - val_mae: 462.8158\n",
            "Epoch 244/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 467.9432 - mae: 467.9432 - val_loss: 461.7171 - val_mae: 461.7171\n",
            "Epoch 245/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 469.7435 - mae: 469.7435 - val_loss: 463.5095 - val_mae: 463.5095\n",
            "Epoch 246/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 467.7395 - mae: 467.7395 - val_loss: 463.5544 - val_mae: 463.5544\n",
            "Epoch 247/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 468.0443 - mae: 468.0443 - val_loss: 463.0251 - val_mae: 463.0251\n",
            "Epoch 248/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 467.5669 - mae: 467.5669 - val_loss: 462.3590 - val_mae: 462.3590\n",
            "Epoch 249/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 468.2060 - mae: 468.2060 - val_loss: 462.9955 - val_mae: 462.9955\n",
            "Epoch 250/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 466.9997 - mae: 466.9997 - val_loss: 463.1693 - val_mae: 463.1693\n",
            "Epoch 251/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 468.7190 - mae: 468.7190 - val_loss: 463.7432 - val_mae: 463.7432\n",
            "Epoch 252/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 467.9443 - mae: 467.9443 - val_loss: 464.0637 - val_mae: 464.0637\n",
            "Epoch 253/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 466.2225 - mae: 466.2225 - val_loss: 462.4670 - val_mae: 462.4670\n",
            "Epoch 254/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 468.7810 - mae: 468.7810 - val_loss: 463.2279 - val_mae: 463.2279\n",
            "Epoch 255/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 467.3627 - mae: 467.3627 - val_loss: 463.3238 - val_mae: 463.3238\n",
            "Epoch 256/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 466.6811 - mae: 466.6811 - val_loss: 463.2606 - val_mae: 463.2606\n",
            "Epoch 257/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 466.7616 - mae: 466.7616 - val_loss: 463.1303 - val_mae: 463.1303\n",
            "Epoch 258/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 466.9382 - mae: 466.9382 - val_loss: 462.9404 - val_mae: 462.9404\n",
            "Epoch 259/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 467.2224 - mae: 467.2224 - val_loss: 462.3600 - val_mae: 462.3600\n",
            "Epoch 260/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 466.3639 - mae: 466.3639 - val_loss: 463.9357 - val_mae: 463.9357\n",
            "Epoch 261/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 467.2522 - mae: 467.2522 - val_loss: 462.3761 - val_mae: 462.3761\n",
            "Epoch 262/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 466.5304 - mae: 466.5304 - val_loss: 463.4106 - val_mae: 463.4106\n",
            "Epoch 263/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 468.1735 - mae: 468.1735 - val_loss: 465.0662 - val_mae: 465.0662\n",
            "Epoch 264/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 467.4484 - mae: 467.4484 - val_loss: 462.8774 - val_mae: 462.8774\n",
            "Epoch 265/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 468.9915 - mae: 468.9915 - val_loss: 464.1062 - val_mae: 464.1062\n",
            "Epoch 266/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 467.9467 - mae: 467.9467 - val_loss: 462.9581 - val_mae: 462.9581\n",
            "Epoch 267/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 466.1619 - mae: 466.1619 - val_loss: 463.0361 - val_mae: 463.0361\n",
            "Epoch 268/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 467.6396 - mae: 467.6396 - val_loss: 462.5937 - val_mae: 462.5937\n",
            "Epoch 269/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 466.7885 - mae: 466.7885 - val_loss: 463.3423 - val_mae: 463.3423\n",
            "Epoch 270/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 467.5725 - mae: 467.5725 - val_loss: 464.7086 - val_mae: 464.7086\n",
            "Epoch 271/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 465.9800 - mae: 465.9800 - val_loss: 463.9658 - val_mae: 463.9658\n",
            "Epoch 272/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 467.0553 - mae: 467.0553 - val_loss: 463.5998 - val_mae: 463.5998\n",
            "Epoch 273/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 466.6612 - mae: 466.6612 - val_loss: 462.6061 - val_mae: 462.6061\n",
            "Epoch 274/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 467.6661 - mae: 467.6661 - val_loss: 463.3158 - val_mae: 463.3158\n",
            "Epoch 275/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 465.8284 - mae: 465.8284 - val_loss: 463.7693 - val_mae: 463.7693\n",
            "Epoch 276/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 467.0480 - mae: 467.0480 - val_loss: 463.2574 - val_mae: 463.2574\n",
            "Epoch 277/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 465.9569 - mae: 465.9569 - val_loss: 462.9410 - val_mae: 462.9410\n",
            "Epoch 278/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 467.5560 - mae: 467.5560 - val_loss: 463.0293 - val_mae: 463.0293\n",
            "Epoch 279/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 466.9415 - mae: 466.9415 - val_loss: 463.3114 - val_mae: 463.3114\n",
            "Epoch 280/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 466.3028 - mae: 466.3028 - val_loss: 462.4706 - val_mae: 462.4706\n",
            "Epoch 281/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 467.0360 - mae: 467.0360 - val_loss: 462.8940 - val_mae: 462.8940\n",
            "Epoch 282/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 466.0460 - mae: 466.0460 - val_loss: 462.8741 - val_mae: 462.8741\n",
            "Epoch 283/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 464.2020 - mae: 464.2020 - val_loss: 464.3148 - val_mae: 464.3148\n",
            "Epoch 284/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 467.2931 - mae: 467.2931 - val_loss: 463.7342 - val_mae: 463.7342\n",
            "Epoch 285/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 468.4764 - mae: 468.4764 - val_loss: 463.6275 - val_mae: 463.6275\n",
            "Epoch 286/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 466.5904 - mae: 466.5904 - val_loss: 464.8064 - val_mae: 464.8064\n",
            "Epoch 287/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 465.0408 - mae: 465.0408 - val_loss: 463.5433 - val_mae: 463.5433\n",
            "Epoch 288/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 466.4759 - mae: 466.4759 - val_loss: 463.5488 - val_mae: 463.5488\n",
            "Epoch 289/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 465.4382 - mae: 465.4382 - val_loss: 463.6353 - val_mae: 463.6353\n",
            "Epoch 290/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 468.8015 - mae: 468.8015 - val_loss: 463.1486 - val_mae: 463.1486\n",
            "Epoch 291/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 465.9657 - mae: 465.9657 - val_loss: 464.3739 - val_mae: 464.3739\n",
            "Epoch 292/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 467.8056 - mae: 467.8056 - val_loss: 464.2714 - val_mae: 464.2714\n",
            "Epoch 293/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 466.8224 - mae: 466.8224 - val_loss: 464.2715 - val_mae: 464.2715\n",
            "Epoch 294/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 466.5133 - mae: 466.5133 - val_loss: 463.5914 - val_mae: 463.5914\n",
            "Epoch 295/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 464.9964 - mae: 464.9964 - val_loss: 463.2787 - val_mae: 463.2787\n",
            "Epoch 296/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 466.8104 - mae: 466.8104 - val_loss: 464.6361 - val_mae: 464.6361\n",
            "Epoch 297/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 467.2820 - mae: 467.2820 - val_loss: 464.1726 - val_mae: 464.1726\n",
            "Epoch 298/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 465.9935 - mae: 465.9935 - val_loss: 463.2562 - val_mae: 463.2562\n",
            "Epoch 299/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 468.2308 - mae: 468.2308 - val_loss: 464.8827 - val_mae: 464.8827\n",
            "Epoch 300/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 468.4873 - mae: 468.4873 - val_loss: 463.9331 - val_mae: 463.9331\n",
            "Epoch 301/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 467.5269 - mae: 467.5269 - val_loss: 463.4764 - val_mae: 463.4764\n",
            "Epoch 302/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 466.7197 - mae: 466.7197 - val_loss: 464.8901 - val_mae: 464.8901\n",
            "Epoch 303/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 468.5049 - mae: 468.5049 - val_loss: 463.5320 - val_mae: 463.5320\n",
            "Epoch 304/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 465.7014 - mae: 465.7014 - val_loss: 462.7112 - val_mae: 462.7112\n",
            "Epoch 305/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 467.6995 - mae: 467.6995 - val_loss: 462.6684 - val_mae: 462.6684\n",
            "Epoch 306/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 466.2206 - mae: 466.2206 - val_loss: 463.7021 - val_mae: 463.7021\n",
            "Epoch 307/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 465.2473 - mae: 465.2473 - val_loss: 464.0384 - val_mae: 464.0384\n",
            "Epoch 308/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 466.4436 - mae: 466.4436 - val_loss: 463.5705 - val_mae: 463.5705\n",
            "Epoch 309/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 465.2579 - mae: 465.2579 - val_loss: 463.4776 - val_mae: 463.4776\n",
            "Epoch 310/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 465.6585 - mae: 465.6585 - val_loss: 463.5155 - val_mae: 463.5155\n",
            "Epoch 311/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 464.9903 - mae: 464.9903 - val_loss: 462.9207 - val_mae: 462.9207\n",
            "Epoch 312/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 466.9075 - mae: 466.9075 - val_loss: 465.0110 - val_mae: 465.0110\n",
            "Epoch 313/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 467.3895 - mae: 467.3895 - val_loss: 464.0065 - val_mae: 464.0065\n",
            "Epoch 314/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 466.4766 - mae: 466.4766 - val_loss: 464.1473 - val_mae: 464.1473\n",
            "Epoch 315/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 465.4107 - mae: 465.4107 - val_loss: 463.3853 - val_mae: 463.3853\n",
            "Epoch 316/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 466.7540 - mae: 466.7540 - val_loss: 462.9688 - val_mae: 462.9688\n",
            "Epoch 317/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 465.6245 - mae: 465.6245 - val_loss: 463.5993 - val_mae: 463.5993\n",
            "Epoch 318/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 465.5980 - mae: 465.5980 - val_loss: 464.2939 - val_mae: 464.2939\n",
            "Epoch 319/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 466.7774 - mae: 466.7774 - val_loss: 463.4003 - val_mae: 463.4003\n",
            "Epoch 320/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 466.4127 - mae: 466.4127 - val_loss: 462.7369 - val_mae: 462.7369\n",
            "Epoch 321/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 466.6615 - mae: 466.6615 - val_loss: 463.8239 - val_mae: 463.8239\n",
            "Epoch 322/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 466.9990 - mae: 466.9990 - val_loss: 463.8994 - val_mae: 463.8994\n",
            "Epoch 323/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 467.1765 - mae: 467.1765 - val_loss: 463.8784 - val_mae: 463.8784\n",
            "Epoch 324/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 466.4904 - mae: 466.4904 - val_loss: 463.6805 - val_mae: 463.6805\n",
            "Epoch 325/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 464.2946 - mae: 464.2946 - val_loss: 464.0802 - val_mae: 464.0802\n",
            "Epoch 326/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 466.9829 - mae: 466.9829 - val_loss: 463.6490 - val_mae: 463.6490\n",
            "Epoch 327/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 465.6321 - mae: 465.6321 - val_loss: 463.5766 - val_mae: 463.5766\n",
            "Epoch 328/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 465.2083 - mae: 465.2083 - val_loss: 464.2263 - val_mae: 464.2263\n",
            "Epoch 329/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 464.7181 - mae: 464.7181 - val_loss: 462.1766 - val_mae: 462.1766\n",
            "Epoch 330/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 466.6811 - mae: 466.6811 - val_loss: 462.9866 - val_mae: 462.9866\n",
            "Epoch 331/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 465.8962 - mae: 465.8962 - val_loss: 462.5301 - val_mae: 462.5301\n",
            "Epoch 332/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 466.6320 - mae: 466.6320 - val_loss: 462.1323 - val_mae: 462.1323\n",
            "Epoch 333/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 465.3985 - mae: 465.3985 - val_loss: 462.9484 - val_mae: 462.9484\n",
            "Epoch 334/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 466.6392 - mae: 466.6392 - val_loss: 463.6759 - val_mae: 463.6759\n",
            "Epoch 335/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 467.0815 - mae: 467.0815 - val_loss: 463.8315 - val_mae: 463.8315\n",
            "Epoch 336/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 465.2203 - mae: 465.2203 - val_loss: 463.9426 - val_mae: 463.9426\n",
            "Epoch 337/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 466.1778 - mae: 466.1778 - val_loss: 463.5741 - val_mae: 463.5741\n",
            "Epoch 338/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 466.2247 - mae: 466.2247 - val_loss: 462.9789 - val_mae: 462.9789\n",
            "Epoch 339/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 464.9240 - mae: 464.9240 - val_loss: 463.1113 - val_mae: 463.1113\n",
            "Epoch 340/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 466.4962 - mae: 466.4962 - val_loss: 463.3859 - val_mae: 463.3859\n",
            "Epoch 341/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 466.6221 - mae: 466.6221 - val_loss: 464.1758 - val_mae: 464.1758\n",
            "Epoch 342/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 466.4677 - mae: 466.4677 - val_loss: 463.1765 - val_mae: 463.1765\n",
            "Epoch 343/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 466.2165 - mae: 466.2165 - val_loss: 462.8586 - val_mae: 462.8586\n",
            "Epoch 344/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 465.7961 - mae: 465.7961 - val_loss: 463.1201 - val_mae: 463.1201\n",
            "Epoch 345/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 466.2026 - mae: 466.2026 - val_loss: 463.0474 - val_mae: 463.0474\n",
            "Epoch 346/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 466.0609 - mae: 466.0609 - val_loss: 462.7055 - val_mae: 462.7055\n",
            "Epoch 347/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 464.3395 - mae: 464.3395 - val_loss: 462.9953 - val_mae: 462.9953\n",
            "Epoch 348/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 465.3618 - mae: 465.3618 - val_loss: 462.7997 - val_mae: 462.7997\n",
            "Epoch 349/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 465.1638 - mae: 465.1638 - val_loss: 462.7432 - val_mae: 462.7432\n",
            "Epoch 350/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 467.0417 - mae: 467.0417 - val_loss: 462.5990 - val_mae: 462.5990\n",
            "Epoch 351/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 465.1680 - mae: 465.1680 - val_loss: 462.4189 - val_mae: 462.4189\n",
            "Epoch 352/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 464.6343 - mae: 464.6343 - val_loss: 463.6097 - val_mae: 463.6097\n",
            "Epoch 353/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 465.7696 - mae: 465.7696 - val_loss: 462.6734 - val_mae: 462.6734\n",
            "Epoch 354/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 465.7418 - mae: 465.7418 - val_loss: 462.5939 - val_mae: 462.5939\n",
            "Epoch 355/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 465.1342 - mae: 465.1342 - val_loss: 463.5646 - val_mae: 463.5646\n",
            "Epoch 356/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 466.0993 - mae: 466.0993 - val_loss: 463.6429 - val_mae: 463.6429\n",
            "Epoch 357/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 466.4861 - mae: 466.4861 - val_loss: 463.6198 - val_mae: 463.6198\n",
            "Epoch 358/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 465.0998 - mae: 465.0998 - val_loss: 463.0532 - val_mae: 463.0532\n",
            "Epoch 359/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 465.8126 - mae: 465.8126 - val_loss: 464.5018 - val_mae: 464.5018\n",
            "Epoch 360/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 464.8073 - mae: 464.8073 - val_loss: 463.3444 - val_mae: 463.3444\n",
            "Epoch 361/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 466.9746 - mae: 466.9746 - val_loss: 463.1866 - val_mae: 463.1866\n",
            "Epoch 362/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 465.7645 - mae: 465.7645 - val_loss: 464.5595 - val_mae: 464.5595\n",
            "Epoch 363/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 466.0309 - mae: 466.0309 - val_loss: 462.6201 - val_mae: 462.6201\n",
            "Epoch 364/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 467.7003 - mae: 467.7003 - val_loss: 461.9384 - val_mae: 461.9384\n",
            "Epoch 365/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 464.8340 - mae: 464.8340 - val_loss: 461.9268 - val_mae: 461.9268\n",
            "Epoch 366/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 464.9924 - mae: 464.9924 - val_loss: 462.5773 - val_mae: 462.5773\n",
            "Epoch 367/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 465.0452 - mae: 465.0452 - val_loss: 462.3256 - val_mae: 462.3256\n",
            "Epoch 368/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 464.4956 - mae: 464.4956 - val_loss: 462.0773 - val_mae: 462.0773\n",
            "Epoch 369/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 466.6451 - mae: 466.6451 - val_loss: 462.8280 - val_mae: 462.8280\n",
            "Epoch 370/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 465.5923 - mae: 465.5923 - val_loss: 463.3253 - val_mae: 463.3253\n",
            "Epoch 371/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 465.0497 - mae: 465.0497 - val_loss: 462.0111 - val_mae: 462.0111\n",
            "Epoch 372/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 463.8516 - mae: 463.8516 - val_loss: 461.8394 - val_mae: 461.8394\n",
            "Epoch 373/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 465.3250 - mae: 465.3250 - val_loss: 461.8970 - val_mae: 461.8970\n",
            "Epoch 374/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 465.2576 - mae: 465.2576 - val_loss: 464.0980 - val_mae: 464.0980\n",
            "Epoch 375/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 466.2065 - mae: 466.2065 - val_loss: 462.8851 - val_mae: 462.8851\n",
            "Epoch 376/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 463.5135 - mae: 463.5135 - val_loss: 461.6236 - val_mae: 461.6236\n",
            "Epoch 377/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 465.2528 - mae: 465.2528 - val_loss: 461.5343 - val_mae: 461.5343\n",
            "Epoch 378/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 466.8680 - mae: 466.8680 - val_loss: 461.8521 - val_mae: 461.8521\n",
            "Epoch 379/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 467.0078 - mae: 467.0078 - val_loss: 462.8241 - val_mae: 462.8241\n",
            "Epoch 380/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 464.9307 - mae: 464.9307 - val_loss: 463.2060 - val_mae: 463.2060\n",
            "Epoch 381/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 465.1121 - mae: 465.1121 - val_loss: 462.0860 - val_mae: 462.0860\n",
            "Epoch 382/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 467.1006 - mae: 467.1006 - val_loss: 461.8828 - val_mae: 461.8828\n",
            "Epoch 383/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 463.8389 - mae: 463.8389 - val_loss: 462.2260 - val_mae: 462.2260\n",
            "Epoch 384/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 466.2054 - mae: 466.2054 - val_loss: 462.2201 - val_mae: 462.2201\n",
            "Epoch 385/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 464.2721 - mae: 464.2721 - val_loss: 461.5145 - val_mae: 461.5145\n",
            "Epoch 386/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 466.2375 - mae: 466.2375 - val_loss: 462.2814 - val_mae: 462.2814\n",
            "Epoch 387/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 464.0493 - mae: 464.0493 - val_loss: 462.2883 - val_mae: 462.2883\n",
            "Epoch 388/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 465.6675 - mae: 465.6675 - val_loss: 462.6068 - val_mae: 462.6068\n",
            "Epoch 389/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 464.3627 - mae: 464.3627 - val_loss: 463.0204 - val_mae: 463.0204\n",
            "Epoch 390/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 463.6730 - mae: 463.6730 - val_loss: 463.3300 - val_mae: 463.3300\n",
            "Epoch 391/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 465.3188 - mae: 465.3188 - val_loss: 462.6685 - val_mae: 462.6685\n",
            "Epoch 392/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 465.6013 - mae: 465.6013 - val_loss: 462.9623 - val_mae: 462.9623\n",
            "Epoch 393/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 465.8923 - mae: 465.8923 - val_loss: 462.4748 - val_mae: 462.4748\n",
            "Epoch 394/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 466.3683 - mae: 466.3683 - val_loss: 462.7812 - val_mae: 462.7812\n",
            "Epoch 395/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 467.0222 - mae: 467.0222 - val_loss: 462.0266 - val_mae: 462.0266\n",
            "Epoch 396/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 465.1063 - mae: 465.1063 - val_loss: 462.8993 - val_mae: 462.8993\n",
            "Epoch 397/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 465.5305 - mae: 465.5305 - val_loss: 462.9767 - val_mae: 462.9767\n",
            "Epoch 398/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 465.8011 - mae: 465.8011 - val_loss: 462.3047 - val_mae: 462.3047\n",
            "Epoch 399/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 464.0959 - mae: 464.0959 - val_loss: 462.5190 - val_mae: 462.5190\n",
            "Epoch 400/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 464.8919 - mae: 464.8919 - val_loss: 463.2092 - val_mae: 463.2092\n",
            "Epoch 401/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 464.5430 - mae: 464.5430 - val_loss: 463.1389 - val_mae: 463.1389\n",
            "Epoch 402/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 465.3662 - mae: 465.3662 - val_loss: 462.1288 - val_mae: 462.1288\n",
            "Epoch 403/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 464.9968 - mae: 464.9968 - val_loss: 463.8227 - val_mae: 463.8227\n",
            "Epoch 404/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 464.5869 - mae: 464.5869 - val_loss: 462.3465 - val_mae: 462.3465\n",
            "Epoch 405/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 465.8081 - mae: 465.8081 - val_loss: 463.1497 - val_mae: 463.1497\n",
            "Epoch 406/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 464.1155 - mae: 464.1155 - val_loss: 463.3642 - val_mae: 463.3642\n",
            "Epoch 407/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 465.8091 - mae: 465.8091 - val_loss: 463.2018 - val_mae: 463.2018\n",
            "Epoch 408/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 462.1130 - mae: 462.1130 - val_loss: 462.6488 - val_mae: 462.6488\n",
            "Epoch 409/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 464.5211 - mae: 464.5211 - val_loss: 462.0500 - val_mae: 462.0500\n",
            "Epoch 410/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 464.9091 - mae: 464.9091 - val_loss: 462.5387 - val_mae: 462.5387\n",
            "Epoch 411/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 466.3033 - mae: 466.3033 - val_loss: 461.7015 - val_mae: 461.7015\n",
            "Epoch 412/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 464.7142 - mae: 464.7142 - val_loss: 462.3303 - val_mae: 462.3303\n",
            "Epoch 413/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 466.0022 - mae: 466.0022 - val_loss: 462.7568 - val_mae: 462.7568\n",
            "Epoch 414/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 464.7389 - mae: 464.7389 - val_loss: 461.3377 - val_mae: 461.3377\n",
            "Epoch 415/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 463.7410 - mae: 463.7410 - val_loss: 462.3252 - val_mae: 462.3252\n",
            "Epoch 416/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 465.5269 - mae: 465.5269 - val_loss: 462.5157 - val_mae: 462.5157\n",
            "Epoch 417/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 464.7425 - mae: 464.7425 - val_loss: 463.3056 - val_mae: 463.3056\n",
            "Epoch 418/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 464.6675 - mae: 464.6675 - val_loss: 462.5193 - val_mae: 462.5193\n",
            "Epoch 419/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 465.5216 - mae: 465.5216 - val_loss: 463.1692 - val_mae: 463.1692\n",
            "Epoch 420/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 465.1544 - mae: 465.1544 - val_loss: 463.3907 - val_mae: 463.3907\n",
            "Epoch 421/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 464.9934 - mae: 464.9934 - val_loss: 463.0086 - val_mae: 463.0086\n",
            "Epoch 422/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 464.4319 - mae: 464.4319 - val_loss: 461.8369 - val_mae: 461.8369\n",
            "Epoch 423/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 464.7782 - mae: 464.7782 - val_loss: 462.0062 - val_mae: 462.0062\n",
            "Epoch 424/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 463.6600 - mae: 463.6600 - val_loss: 462.3914 - val_mae: 462.3914\n",
            "Epoch 425/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 463.4769 - mae: 463.4769 - val_loss: 461.2722 - val_mae: 461.2722\n",
            "Epoch 426/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 466.7617 - mae: 466.7617 - val_loss: 462.0062 - val_mae: 462.0062\n",
            "Epoch 427/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 464.6196 - mae: 464.6196 - val_loss: 462.1842 - val_mae: 462.1842\n",
            "Epoch 428/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 465.1853 - mae: 465.1853 - val_loss: 463.1551 - val_mae: 463.1551\n",
            "Epoch 429/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 464.6615 - mae: 464.6615 - val_loss: 463.5532 - val_mae: 463.5532\n",
            "Epoch 430/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 466.8712 - mae: 466.8712 - val_loss: 463.1967 - val_mae: 463.1967\n",
            "Epoch 431/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 463.5801 - mae: 463.5801 - val_loss: 463.0135 - val_mae: 463.0135\n",
            "Epoch 432/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 464.6640 - mae: 464.6640 - val_loss: 463.1587 - val_mae: 463.1587\n",
            "Epoch 433/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 464.5887 - mae: 464.5887 - val_loss: 463.2697 - val_mae: 463.2697\n",
            "Epoch 434/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 464.2389 - mae: 464.2389 - val_loss: 463.9467 - val_mae: 463.9467\n",
            "Epoch 435/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 462.6822 - mae: 462.6822 - val_loss: 463.4977 - val_mae: 463.4977\n",
            "Epoch 436/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 464.4895 - mae: 464.4895 - val_loss: 464.0295 - val_mae: 464.0295\n",
            "Epoch 437/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 466.0544 - mae: 466.0544 - val_loss: 463.2886 - val_mae: 463.2886\n",
            "Epoch 438/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 465.2863 - mae: 465.2863 - val_loss: 463.3696 - val_mae: 463.3696\n",
            "Epoch 439/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 462.8101 - mae: 462.8101 - val_loss: 463.3576 - val_mae: 463.3576\n",
            "Epoch 440/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 463.7635 - mae: 463.7635 - val_loss: 462.8229 - val_mae: 462.8229\n",
            "Epoch 441/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 464.6149 - mae: 464.6149 - val_loss: 462.8972 - val_mae: 462.8972\n",
            "Epoch 442/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 465.1406 - mae: 465.1406 - val_loss: 463.6767 - val_mae: 463.6767\n",
            "Epoch 443/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 463.7990 - mae: 463.7990 - val_loss: 463.6766 - val_mae: 463.6766\n",
            "Epoch 444/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 464.4939 - mae: 464.4939 - val_loss: 462.2466 - val_mae: 462.2466\n",
            "Epoch 445/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 466.9780 - mae: 466.9780 - val_loss: 462.6579 - val_mae: 462.6579\n",
            "Epoch 446/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 463.5976 - mae: 463.5976 - val_loss: 463.2356 - val_mae: 463.2356\n",
            "Epoch 447/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 464.0506 - mae: 464.0506 - val_loss: 463.7041 - val_mae: 463.7041\n",
            "Epoch 448/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 464.4101 - mae: 464.4101 - val_loss: 463.2550 - val_mae: 463.2550\n",
            "Epoch 449/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 464.8249 - mae: 464.8249 - val_loss: 463.8700 - val_mae: 463.8700\n",
            "Epoch 450/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 465.3715 - mae: 465.3715 - val_loss: 463.2488 - val_mae: 463.2488\n",
            "Epoch 451/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 464.7200 - mae: 464.7200 - val_loss: 462.5933 - val_mae: 462.5933\n",
            "Epoch 452/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 464.7348 - mae: 464.7348 - val_loss: 464.0496 - val_mae: 464.0496\n",
            "Epoch 453/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 465.6341 - mae: 465.6341 - val_loss: 463.3101 - val_mae: 463.3101\n",
            "Epoch 454/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 462.3781 - mae: 462.3781 - val_loss: 463.1982 - val_mae: 463.1982\n",
            "Epoch 455/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 462.8377 - mae: 462.8377 - val_loss: 462.7124 - val_mae: 462.7124\n",
            "Epoch 456/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 464.9393 - mae: 464.9393 - val_loss: 463.5038 - val_mae: 463.5038\n",
            "Epoch 457/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 463.4359 - mae: 463.4359 - val_loss: 463.5851 - val_mae: 463.5851\n",
            "Epoch 458/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 462.7530 - mae: 462.7530 - val_loss: 463.5818 - val_mae: 463.5818\n",
            "Epoch 459/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 464.2701 - mae: 464.2701 - val_loss: 462.6295 - val_mae: 462.6295\n",
            "Epoch 460/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 462.4595 - mae: 462.4595 - val_loss: 463.2788 - val_mae: 463.2788\n",
            "Epoch 461/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 463.6726 - mae: 463.6726 - val_loss: 462.4317 - val_mae: 462.4317\n",
            "Epoch 462/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 464.1418 - mae: 464.1418 - val_loss: 462.5436 - val_mae: 462.5436\n",
            "Epoch 463/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 463.5908 - mae: 463.5908 - val_loss: 463.0517 - val_mae: 463.0517\n",
            "Epoch 464/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 462.6696 - mae: 462.6696 - val_loss: 462.9586 - val_mae: 462.9586\n",
            "Epoch 465/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 464.8661 - mae: 464.8661 - val_loss: 462.7822 - val_mae: 462.7822\n",
            "Epoch 466/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 466.2380 - mae: 466.2380 - val_loss: 463.3805 - val_mae: 463.3805\n",
            "Epoch 467/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 463.6461 - mae: 463.6461 - val_loss: 463.4623 - val_mae: 463.4623\n",
            "Epoch 468/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 466.0974 - mae: 466.0974 - val_loss: 463.5182 - val_mae: 463.5182\n",
            "Epoch 469/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 464.2441 - mae: 464.2441 - val_loss: 463.9087 - val_mae: 463.9087\n",
            "Epoch 470/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 463.8514 - mae: 463.8514 - val_loss: 463.5917 - val_mae: 463.5917\n",
            "Epoch 471/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 465.9669 - mae: 465.9669 - val_loss: 463.0445 - val_mae: 463.0445\n",
            "Epoch 472/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 465.2538 - mae: 465.2538 - val_loss: 462.7071 - val_mae: 462.7071\n",
            "Epoch 473/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 464.7842 - mae: 464.7842 - val_loss: 463.2803 - val_mae: 463.2803\n",
            "Epoch 474/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 464.8100 - mae: 464.8100 - val_loss: 462.5220 - val_mae: 462.5220\n",
            "Epoch 475/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 462.3857 - mae: 462.3857 - val_loss: 463.8652 - val_mae: 463.8652\n",
            "Epoch 476/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 464.4143 - mae: 464.4143 - val_loss: 464.4319 - val_mae: 464.4319\n",
            "Epoch 477/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 463.8308 - mae: 463.8308 - val_loss: 463.5698 - val_mae: 463.5698\n",
            "Epoch 478/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 462.0961 - mae: 462.0961 - val_loss: 463.3839 - val_mae: 463.3839\n",
            "Epoch 479/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 464.7545 - mae: 464.7545 - val_loss: 463.0486 - val_mae: 463.0486\n",
            "Epoch 480/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 465.7062 - mae: 465.7062 - val_loss: 464.2470 - val_mae: 464.2470\n",
            "Epoch 481/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 463.6795 - mae: 463.6795 - val_loss: 463.8090 - val_mae: 463.8090\n",
            "Epoch 482/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 463.3200 - mae: 463.3200 - val_loss: 463.0455 - val_mae: 463.0455\n",
            "Epoch 483/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 462.6096 - mae: 462.6096 - val_loss: 463.0312 - val_mae: 463.0312\n",
            "Epoch 484/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 463.1693 - mae: 463.1693 - val_loss: 463.5949 - val_mae: 463.5949\n",
            "Epoch 485/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 464.1443 - mae: 464.1443 - val_loss: 462.9320 - val_mae: 462.9320\n",
            "Epoch 486/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 463.7528 - mae: 463.7528 - val_loss: 463.3739 - val_mae: 463.3739\n",
            "Epoch 487/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 463.7633 - mae: 463.7633 - val_loss: 462.7845 - val_mae: 462.7845\n",
            "Epoch 488/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 462.9920 - mae: 462.9920 - val_loss: 461.8099 - val_mae: 461.8099\n",
            "Epoch 489/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 461.8120 - mae: 461.8120 - val_loss: 462.2180 - val_mae: 462.2180\n",
            "Epoch 490/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 462.9749 - mae: 462.9749 - val_loss: 462.7914 - val_mae: 462.7914\n",
            "Epoch 491/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 464.2319 - mae: 464.2319 - val_loss: 462.6230 - val_mae: 462.6230\n",
            "Epoch 492/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 462.3021 - mae: 462.3021 - val_loss: 462.4118 - val_mae: 462.4118\n",
            "Epoch 493/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 465.2317 - mae: 465.2317 - val_loss: 462.2220 - val_mae: 462.2220\n",
            "Epoch 494/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 463.7719 - mae: 463.7719 - val_loss: 463.2853 - val_mae: 463.2853\n",
            "Epoch 495/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 461.8985 - mae: 461.8985 - val_loss: 462.2551 - val_mae: 462.2551\n",
            "Epoch 496/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 464.3839 - mae: 464.3839 - val_loss: 463.8704 - val_mae: 463.8704\n",
            "Epoch 497/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 463.6206 - mae: 463.6206 - val_loss: 462.7121 - val_mae: 462.7121\n",
            "Epoch 498/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 464.4784 - mae: 464.4784 - val_loss: 464.1013 - val_mae: 464.1013\n",
            "Epoch 499/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 465.5573 - mae: 465.5573 - val_loss: 464.5202 - val_mae: 464.5202\n",
            "Epoch 500/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 464.3486 - mae: 464.3486 - val_loss: 462.8427 - val_mae: 462.8427\n",
            "Epoch 501/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 464.1451 - mae: 464.1451 - val_loss: 463.2933 - val_mae: 463.2933\n",
            "Epoch 502/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 464.9738 - mae: 464.9738 - val_loss: 463.2458 - val_mae: 463.2458\n",
            "Epoch 503/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 464.0826 - mae: 464.0826 - val_loss: 463.2991 - val_mae: 463.2991\n",
            "Epoch 504/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 463.9451 - mae: 463.9451 - val_loss: 462.6472 - val_mae: 462.6472\n",
            "Epoch 505/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 462.5377 - mae: 462.5377 - val_loss: 463.8975 - val_mae: 463.8975\n",
            "Epoch 506/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 462.8048 - mae: 462.8048 - val_loss: 464.2711 - val_mae: 464.2711\n",
            "Epoch 507/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 462.7623 - mae: 462.7623 - val_loss: 463.5653 - val_mae: 463.5653\n",
            "Epoch 508/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 464.0370 - mae: 464.0370 - val_loss: 463.5123 - val_mae: 463.5123\n",
            "Epoch 509/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 462.9124 - mae: 462.9124 - val_loss: 463.4059 - val_mae: 463.4059\n",
            "Epoch 510/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 463.5326 - mae: 463.5326 - val_loss: 463.6835 - val_mae: 463.6835\n",
            "Epoch 511/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 461.8263 - mae: 461.8263 - val_loss: 463.0731 - val_mae: 463.0731\n",
            "Epoch 512/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 464.2264 - mae: 464.2264 - val_loss: 462.6559 - val_mae: 462.6559\n",
            "Epoch 513/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 462.6068 - mae: 462.6068 - val_loss: 462.5195 - val_mae: 462.5195\n",
            "Epoch 514/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 464.0959 - mae: 464.0959 - val_loss: 462.6700 - val_mae: 462.6700\n",
            "Epoch 515/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 463.2324 - mae: 463.2324 - val_loss: 462.8071 - val_mae: 462.8071\n",
            "Epoch 516/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 463.6408 - mae: 463.6408 - val_loss: 463.5529 - val_mae: 463.5529\n",
            "Epoch 517/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 463.0127 - mae: 463.0127 - val_loss: 463.0667 - val_mae: 463.0667\n",
            "Epoch 518/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 461.4793 - mae: 461.4793 - val_loss: 462.7861 - val_mae: 462.7861\n",
            "Epoch 519/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 463.1260 - mae: 463.1260 - val_loss: 463.1440 - val_mae: 463.1440\n",
            "Epoch 520/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 463.9106 - mae: 463.9106 - val_loss: 462.8196 - val_mae: 462.8196\n",
            "Epoch 521/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 464.6221 - mae: 464.6221 - val_loss: 462.5847 - val_mae: 462.5847\n",
            "Epoch 522/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 463.3564 - mae: 463.3564 - val_loss: 463.3016 - val_mae: 463.3016\n",
            "Epoch 523/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 462.5826 - mae: 462.5826 - val_loss: 463.3841 - val_mae: 463.3841\n",
            "Epoch 524/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 464.5550 - mae: 464.5550 - val_loss: 464.1909 - val_mae: 464.1909\n",
            "Epoch 525/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 463.6011 - mae: 463.6011 - val_loss: 462.5973 - val_mae: 462.5973\n",
            "Epoch 526/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 462.8057 - mae: 462.8057 - val_loss: 462.6740 - val_mae: 462.6740\n",
            "Epoch 527/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 464.0456 - mae: 464.0456 - val_loss: 463.5624 - val_mae: 463.5624\n",
            "Epoch 528/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 465.4411 - mae: 465.4411 - val_loss: 463.4778 - val_mae: 463.4778\n",
            "Epoch 529/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 462.6624 - mae: 462.6624 - val_loss: 464.1032 - val_mae: 464.1032\n",
            "Epoch 530/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 463.3402 - mae: 463.3402 - val_loss: 464.0130 - val_mae: 464.0130\n",
            "Epoch 531/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 461.8728 - mae: 461.8728 - val_loss: 463.8627 - val_mae: 463.8627\n",
            "Epoch 532/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 460.8694 - mae: 460.8694 - val_loss: 464.1544 - val_mae: 464.1544\n",
            "Epoch 533/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 462.5516 - mae: 462.5516 - val_loss: 463.3999 - val_mae: 463.3999\n",
            "Epoch 534/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 464.8846 - mae: 464.8846 - val_loss: 465.2664 - val_mae: 465.2664\n",
            "Epoch 535/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 464.2140 - mae: 464.2140 - val_loss: 464.7550 - val_mae: 464.7550\n",
            "Epoch 536/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 462.6762 - mae: 462.6762 - val_loss: 464.8403 - val_mae: 464.8403\n",
            "Epoch 537/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 464.2182 - mae: 464.2182 - val_loss: 464.7964 - val_mae: 464.7964\n",
            "Epoch 538/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 463.7006 - mae: 463.7006 - val_loss: 463.7488 - val_mae: 463.7488\n",
            "Epoch 539/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 463.7792 - mae: 463.7792 - val_loss: 464.4217 - val_mae: 464.4217\n",
            "Epoch 540/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 462.5032 - mae: 462.5032 - val_loss: 463.8593 - val_mae: 463.8593\n",
            "Epoch 541/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 461.5032 - mae: 461.5032 - val_loss: 464.0107 - val_mae: 464.0107\n",
            "Epoch 542/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 464.3227 - mae: 464.3227 - val_loss: 463.9066 - val_mae: 463.9066\n",
            "Epoch 543/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 463.2885 - mae: 463.2885 - val_loss: 463.8271 - val_mae: 463.8271\n",
            "Epoch 544/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 462.5679 - mae: 462.5679 - val_loss: 462.7682 - val_mae: 462.7682\n",
            "Epoch 545/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 463.1951 - mae: 463.1951 - val_loss: 462.2907 - val_mae: 462.2907\n",
            "Epoch 546/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 464.1016 - mae: 464.1016 - val_loss: 462.4031 - val_mae: 462.4031\n",
            "Epoch 547/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 464.3635 - mae: 464.3635 - val_loss: 462.0528 - val_mae: 462.0528\n",
            "Epoch 548/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 460.3378 - mae: 460.3378 - val_loss: 462.5326 - val_mae: 462.5326\n",
            "Epoch 549/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 462.0796 - mae: 462.0796 - val_loss: 462.9498 - val_mae: 462.9498\n",
            "Epoch 550/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 462.3555 - mae: 462.3555 - val_loss: 462.9376 - val_mae: 462.9376\n",
            "Epoch 551/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 463.4518 - mae: 463.4518 - val_loss: 462.7475 - val_mae: 462.7475\n",
            "Epoch 552/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 461.0174 - mae: 461.0174 - val_loss: 462.9884 - val_mae: 462.9884\n",
            "Epoch 553/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 463.6227 - mae: 463.6227 - val_loss: 462.7359 - val_mae: 462.7359\n",
            "Epoch 554/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 463.2973 - mae: 463.2973 - val_loss: 464.0975 - val_mae: 464.0975\n",
            "Epoch 555/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 461.4724 - mae: 461.4724 - val_loss: 463.0269 - val_mae: 463.0269\n",
            "Epoch 556/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 464.3984 - mae: 464.3984 - val_loss: 463.6754 - val_mae: 463.6754\n",
            "Epoch 557/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 462.7054 - mae: 462.7054 - val_loss: 463.4588 - val_mae: 463.4588\n",
            "Epoch 558/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 462.2745 - mae: 462.2745 - val_loss: 464.5218 - val_mae: 464.5218\n",
            "Epoch 559/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 465.1880 - mae: 465.1880 - val_loss: 463.8002 - val_mae: 463.8002\n",
            "Epoch 560/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 460.3956 - mae: 460.3956 - val_loss: 463.3873 - val_mae: 463.3873\n",
            "Epoch 561/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 463.8705 - mae: 463.8705 - val_loss: 464.0653 - val_mae: 464.0653\n",
            "Epoch 562/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 462.6670 - mae: 462.6670 - val_loss: 463.1748 - val_mae: 463.1748\n",
            "Epoch 563/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 462.8795 - mae: 462.8795 - val_loss: 463.9430 - val_mae: 463.9430\n",
            "Epoch 564/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 462.4287 - mae: 462.4287 - val_loss: 464.1846 - val_mae: 464.1846\n",
            "Epoch 565/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 461.6741 - mae: 461.6741 - val_loss: 463.2044 - val_mae: 463.2044\n",
            "Epoch 566/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 461.3527 - mae: 461.3527 - val_loss: 463.5273 - val_mae: 463.5273\n",
            "Epoch 567/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 463.8112 - mae: 463.8112 - val_loss: 463.7730 - val_mae: 463.7730\n",
            "Epoch 568/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 461.7884 - mae: 461.7884 - val_loss: 463.7232 - val_mae: 463.7232\n",
            "Epoch 569/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 463.3022 - mae: 463.3022 - val_loss: 463.8305 - val_mae: 463.8305\n",
            "Epoch 570/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 462.3397 - mae: 462.3397 - val_loss: 464.4730 - val_mae: 464.4730\n",
            "Epoch 571/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 463.2102 - mae: 463.2102 - val_loss: 462.4790 - val_mae: 462.4790\n",
            "Epoch 572/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 463.4394 - mae: 463.4394 - val_loss: 463.5331 - val_mae: 463.5331\n",
            "Epoch 573/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 463.2111 - mae: 463.2111 - val_loss: 463.4779 - val_mae: 463.4779\n",
            "Epoch 574/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 462.8541 - mae: 462.8541 - val_loss: 464.3882 - val_mae: 464.3882\n",
            "Epoch 575/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 464.2389 - mae: 464.2389 - val_loss: 463.9086 - val_mae: 463.9086\n",
            "Epoch 576/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 462.4841 - mae: 462.4841 - val_loss: 464.5661 - val_mae: 464.5661\n",
            "Epoch 577/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 462.2910 - mae: 462.2910 - val_loss: 464.0669 - val_mae: 464.0669\n",
            "Epoch 578/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 461.1397 - mae: 461.1397 - val_loss: 465.5822 - val_mae: 465.5822\n",
            "Epoch 579/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 461.8684 - mae: 461.8684 - val_loss: 463.1673 - val_mae: 463.1673\n",
            "Epoch 580/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 463.1652 - mae: 463.1652 - val_loss: 463.4865 - val_mae: 463.4865\n",
            "Epoch 581/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 462.8566 - mae: 462.8566 - val_loss: 463.2755 - val_mae: 463.2755\n",
            "Epoch 582/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 462.8463 - mae: 462.8463 - val_loss: 463.7957 - val_mae: 463.7957\n",
            "Epoch 583/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 461.0764 - mae: 461.0764 - val_loss: 464.2127 - val_mae: 464.2127\n",
            "Epoch 584/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 461.4834 - mae: 461.4834 - val_loss: 463.9019 - val_mae: 463.9019\n",
            "Epoch 585/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 461.2003 - mae: 461.2003 - val_loss: 463.6532 - val_mae: 463.6532\n",
            "Epoch 586/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 462.4223 - mae: 462.4223 - val_loss: 462.7047 - val_mae: 462.7047\n",
            "Epoch 587/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 463.6251 - mae: 463.6251 - val_loss: 462.8612 - val_mae: 462.8612\n",
            "Epoch 588/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 462.4543 - mae: 462.4543 - val_loss: 463.2971 - val_mae: 463.2971\n",
            "Epoch 589/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 463.8549 - mae: 463.8549 - val_loss: 465.0291 - val_mae: 465.0291\n",
            "Epoch 590/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 464.3962 - mae: 464.3962 - val_loss: 464.1065 - val_mae: 464.1065\n",
            "Epoch 591/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 463.0490 - mae: 463.0490 - val_loss: 463.7885 - val_mae: 463.7885\n",
            "Epoch 592/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 463.7711 - mae: 463.7711 - val_loss: 463.1750 - val_mae: 463.1750\n",
            "Epoch 593/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 462.3527 - mae: 462.3527 - val_loss: 463.1375 - val_mae: 463.1375\n",
            "Epoch 594/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 460.7115 - mae: 460.7115 - val_loss: 464.7953 - val_mae: 464.7953\n",
            "Epoch 595/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 461.6704 - mae: 461.6704 - val_loss: 462.9028 - val_mae: 462.9028\n",
            "Epoch 596/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 463.1826 - mae: 463.1826 - val_loss: 463.1495 - val_mae: 463.1495\n",
            "Epoch 597/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 462.4146 - mae: 462.4146 - val_loss: 465.1971 - val_mae: 465.1971\n",
            "Epoch 598/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 462.1819 - mae: 462.1819 - val_loss: 463.9073 - val_mae: 463.9073\n",
            "Epoch 599/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 463.6504 - mae: 463.6504 - val_loss: 463.9185 - val_mae: 463.9185\n",
            "Epoch 600/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 461.9066 - mae: 461.9066 - val_loss: 464.2739 - val_mae: 464.2739\n",
            "Epoch 601/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 463.8473 - mae: 463.8473 - val_loss: 463.5054 - val_mae: 463.5054\n",
            "Epoch 602/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 462.2770 - mae: 462.2770 - val_loss: 464.5249 - val_mae: 464.5249\n",
            "Epoch 603/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 460.5924 - mae: 460.5924 - val_loss: 464.3925 - val_mae: 464.3925\n",
            "Epoch 604/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 462.2872 - mae: 462.2872 - val_loss: 463.6688 - val_mae: 463.6688\n",
            "Epoch 605/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 461.2698 - mae: 461.2698 - val_loss: 463.7705 - val_mae: 463.7705\n",
            "Epoch 606/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 459.7017 - mae: 459.7017 - val_loss: 464.2241 - val_mae: 464.2241\n",
            "Epoch 607/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 463.8717 - mae: 463.8717 - val_loss: 462.8566 - val_mae: 462.8566\n",
            "Epoch 608/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 462.7957 - mae: 462.7957 - val_loss: 463.1586 - val_mae: 463.1586\n",
            "Epoch 609/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 463.8087 - mae: 463.8087 - val_loss: 463.2797 - val_mae: 463.2797\n",
            "Epoch 610/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 463.6224 - mae: 463.6224 - val_loss: 462.8663 - val_mae: 462.8663\n",
            "Epoch 611/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 461.2491 - mae: 461.2491 - val_loss: 462.0178 - val_mae: 462.0178\n",
            "Epoch 612/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 463.1436 - mae: 463.1436 - val_loss: 462.8446 - val_mae: 462.8446\n",
            "Epoch 613/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 463.7320 - mae: 463.7320 - val_loss: 463.8797 - val_mae: 463.8797\n",
            "Epoch 614/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 462.7456 - mae: 462.7456 - val_loss: 463.2126 - val_mae: 463.2126\n",
            "Epoch 615/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 461.9249 - mae: 461.9249 - val_loss: 463.2551 - val_mae: 463.2551\n",
            "Epoch 616/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 461.8327 - mae: 461.8327 - val_loss: 463.7715 - val_mae: 463.7715\n",
            "Epoch 617/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 462.7334 - mae: 462.7334 - val_loss: 463.5086 - val_mae: 463.5086\n",
            "Epoch 618/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 461.7090 - mae: 461.7090 - val_loss: 463.2033 - val_mae: 463.2033\n",
            "Epoch 619/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 462.9830 - mae: 462.9830 - val_loss: 464.9412 - val_mae: 464.9412\n",
            "Epoch 620/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 463.4123 - mae: 463.4123 - val_loss: 463.2627 - val_mae: 463.2627\n",
            "Epoch 621/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 463.0461 - mae: 463.0461 - val_loss: 463.1346 - val_mae: 463.1346\n",
            "Epoch 622/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 460.9699 - mae: 460.9699 - val_loss: 464.0023 - val_mae: 464.0023\n",
            "Epoch 623/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 461.6158 - mae: 461.6158 - val_loss: 464.1621 - val_mae: 464.1621\n",
            "Epoch 624/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 461.9039 - mae: 461.9039 - val_loss: 463.6169 - val_mae: 463.6169\n",
            "Epoch 625/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 464.7422 - mae: 464.7422 - val_loss: 464.0299 - val_mae: 464.0299\n",
            "Epoch 626/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 462.7384 - mae: 462.7384 - val_loss: 463.2638 - val_mae: 463.2638\n",
            "Epoch 627/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 461.1548 - mae: 461.1548 - val_loss: 463.8132 - val_mae: 463.8132\n",
            "Epoch 628/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 463.3327 - mae: 463.3327 - val_loss: 463.8192 - val_mae: 463.8192\n",
            "Epoch 629/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 462.1600 - mae: 462.1600 - val_loss: 463.5179 - val_mae: 463.5179\n",
            "Epoch 630/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 460.5018 - mae: 460.5018 - val_loss: 464.6010 - val_mae: 464.6010\n",
            "Epoch 631/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 461.7850 - mae: 461.7850 - val_loss: 463.6422 - val_mae: 463.6422\n",
            "Epoch 632/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 464.2098 - mae: 464.2098 - val_loss: 464.3098 - val_mae: 464.3098\n",
            "Epoch 633/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 462.9120 - mae: 462.9120 - val_loss: 463.2396 - val_mae: 463.2396\n",
            "Epoch 634/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 462.4469 - mae: 462.4469 - val_loss: 465.0642 - val_mae: 465.0642\n",
            "Epoch 635/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 460.5539 - mae: 460.5539 - val_loss: 463.0797 - val_mae: 463.0797\n",
            "Epoch 636/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 462.4974 - mae: 462.4974 - val_loss: 464.0249 - val_mae: 464.0249\n",
            "Epoch 637/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 463.0595 - mae: 463.0595 - val_loss: 464.2651 - val_mae: 464.2651\n",
            "Epoch 638/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 463.0330 - mae: 463.0330 - val_loss: 464.5988 - val_mae: 464.5988\n",
            "Epoch 639/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 458.7787 - mae: 458.7787 - val_loss: 463.3651 - val_mae: 463.3651\n",
            "Epoch 640/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 464.0169 - mae: 464.0169 - val_loss: 463.3676 - val_mae: 463.3676\n",
            "Epoch 641/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 461.6410 - mae: 461.6410 - val_loss: 463.1005 - val_mae: 463.1005\n",
            "Epoch 642/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 462.0779 - mae: 462.0779 - val_loss: 462.4948 - val_mae: 462.4948\n",
            "Epoch 643/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 462.3266 - mae: 462.3266 - val_loss: 463.6025 - val_mae: 463.6025\n",
            "Epoch 644/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 462.7769 - mae: 462.7769 - val_loss: 463.3641 - val_mae: 463.3641\n",
            "Epoch 645/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 460.6798 - mae: 460.6798 - val_loss: 462.9696 - val_mae: 462.9696\n",
            "Epoch 646/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 462.0772 - mae: 462.0772 - val_loss: 463.1028 - val_mae: 463.1028\n",
            "Epoch 647/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 461.3373 - mae: 461.3373 - val_loss: 462.6160 - val_mae: 462.6160\n",
            "Epoch 648/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 462.7713 - mae: 462.7713 - val_loss: 463.9331 - val_mae: 463.9331\n",
            "Epoch 649/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 460.2964 - mae: 460.2964 - val_loss: 462.2820 - val_mae: 462.2820\n",
            "Epoch 650/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 460.7762 - mae: 460.7762 - val_loss: 464.0941 - val_mae: 464.0941\n",
            "Epoch 651/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 460.1835 - mae: 460.1835 - val_loss: 462.4869 - val_mae: 462.4869\n",
            "Epoch 652/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 461.8494 - mae: 461.8494 - val_loss: 463.7922 - val_mae: 463.7922\n",
            "Epoch 653/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 461.4803 - mae: 461.4803 - val_loss: 463.4539 - val_mae: 463.4539\n",
            "Epoch 654/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 461.7947 - mae: 461.7947 - val_loss: 462.1955 - val_mae: 462.1955\n",
            "Epoch 655/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 460.7791 - mae: 460.7791 - val_loss: 462.1140 - val_mae: 462.1140\n",
            "Epoch 656/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 459.8304 - mae: 459.8304 - val_loss: 463.8807 - val_mae: 463.8807\n",
            "Epoch 657/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 462.9462 - mae: 462.9462 - val_loss: 463.4474 - val_mae: 463.4474\n",
            "Epoch 658/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 463.6420 - mae: 463.6420 - val_loss: 463.9897 - val_mae: 463.9897\n",
            "Epoch 659/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 463.1093 - mae: 463.1093 - val_loss: 463.6067 - val_mae: 463.6067\n",
            "Epoch 660/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 461.5777 - mae: 461.5777 - val_loss: 462.8228 - val_mae: 462.8228\n",
            "Epoch 661/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 460.8279 - mae: 460.8279 - val_loss: 461.9974 - val_mae: 461.9974\n",
            "Epoch 662/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 459.9395 - mae: 459.9395 - val_loss: 462.1253 - val_mae: 462.1253\n",
            "Epoch 663/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 461.8297 - mae: 461.8297 - val_loss: 463.3664 - val_mae: 463.3664\n",
            "Epoch 664/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 460.9321 - mae: 460.9321 - val_loss: 463.6576 - val_mae: 463.6576\n",
            "Epoch 665/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 462.4201 - mae: 462.4201 - val_loss: 462.6930 - val_mae: 462.6930\n",
            "Epoch 666/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 460.5368 - mae: 460.5368 - val_loss: 463.5584 - val_mae: 463.5584\n",
            "Epoch 667/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 459.6433 - mae: 459.6433 - val_loss: 463.5569 - val_mae: 463.5569\n",
            "Epoch 668/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 462.1975 - mae: 462.1975 - val_loss: 462.4152 - val_mae: 462.4152\n",
            "Epoch 669/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 463.3523 - mae: 463.3523 - val_loss: 462.5172 - val_mae: 462.5172\n",
            "Epoch 670/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 461.3144 - mae: 461.3144 - val_loss: 462.6186 - val_mae: 462.6186\n",
            "Epoch 671/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 461.6855 - mae: 461.6855 - val_loss: 462.9389 - val_mae: 462.9389\n",
            "Epoch 672/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 460.6736 - mae: 460.6736 - val_loss: 463.6995 - val_mae: 463.6995\n",
            "Epoch 673/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 461.1487 - mae: 461.1487 - val_loss: 462.0036 - val_mae: 462.0036\n",
            "Epoch 674/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 459.6089 - mae: 459.6089 - val_loss: 462.1245 - val_mae: 462.1245\n",
            "Epoch 675/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 463.7805 - mae: 463.7805 - val_loss: 463.0946 - val_mae: 463.0946\n",
            "Epoch 676/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 463.5951 - mae: 463.5951 - val_loss: 461.7204 - val_mae: 461.7204\n",
            "Epoch 677/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 461.5107 - mae: 461.5107 - val_loss: 462.4656 - val_mae: 462.4656\n",
            "Epoch 678/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 461.2454 - mae: 461.2454 - val_loss: 463.2721 - val_mae: 463.2721\n",
            "Epoch 679/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 461.9337 - mae: 461.9337 - val_loss: 462.0326 - val_mae: 462.0326\n",
            "Epoch 680/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 462.1726 - mae: 462.1726 - val_loss: 463.3437 - val_mae: 463.3437\n",
            "Epoch 681/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 461.1627 - mae: 461.1627 - val_loss: 463.0313 - val_mae: 463.0313\n",
            "Epoch 682/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 461.9694 - mae: 461.9694 - val_loss: 463.9818 - val_mae: 463.9818\n",
            "Epoch 683/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 462.7166 - mae: 462.7166 - val_loss: 462.8582 - val_mae: 462.8582\n",
            "Epoch 684/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 460.4664 - mae: 460.4664 - val_loss: 462.5907 - val_mae: 462.5907\n",
            "Epoch 685/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 460.5195 - mae: 460.5195 - val_loss: 462.3545 - val_mae: 462.3545\n",
            "Epoch 686/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 460.5878 - mae: 460.5878 - val_loss: 463.3857 - val_mae: 463.3857\n",
            "Epoch 687/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 461.1046 - mae: 461.1046 - val_loss: 463.1326 - val_mae: 463.1326\n",
            "Epoch 688/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 461.6021 - mae: 461.6021 - val_loss: 462.9216 - val_mae: 462.9216\n",
            "Epoch 689/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 461.8146 - mae: 461.8146 - val_loss: 462.8604 - val_mae: 462.8604\n",
            "Epoch 690/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 462.5728 - mae: 462.5728 - val_loss: 463.3882 - val_mae: 463.3882\n",
            "Epoch 691/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 462.4406 - mae: 462.4406 - val_loss: 462.8876 - val_mae: 462.8876\n",
            "Epoch 692/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 460.1584 - mae: 460.1584 - val_loss: 463.8919 - val_mae: 463.8919\n",
            "Epoch 693/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 460.9410 - mae: 460.9410 - val_loss: 463.2744 - val_mae: 463.2744\n",
            "Epoch 694/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 461.4945 - mae: 461.4945 - val_loss: 464.2650 - val_mae: 464.2650\n",
            "Epoch 695/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 462.1853 - mae: 462.1853 - val_loss: 463.0981 - val_mae: 463.0981\n",
            "Epoch 696/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 460.9016 - mae: 460.9016 - val_loss: 462.7421 - val_mae: 462.7421\n",
            "Epoch 697/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 461.1400 - mae: 461.1400 - val_loss: 462.4742 - val_mae: 462.4742\n",
            "Epoch 698/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 461.3784 - mae: 461.3784 - val_loss: 462.3629 - val_mae: 462.3629\n",
            "Epoch 699/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 460.9123 - mae: 460.9123 - val_loss: 463.0067 - val_mae: 463.0067\n",
            "Epoch 700/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 464.1487 - mae: 464.1487 - val_loss: 463.0455 - val_mae: 463.0455\n",
            "Epoch 701/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 462.1649 - mae: 462.1649 - val_loss: 464.8844 - val_mae: 464.8844\n",
            "Epoch 702/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 460.9440 - mae: 460.9440 - val_loss: 463.1578 - val_mae: 463.1578\n",
            "Epoch 703/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 462.4547 - mae: 462.4547 - val_loss: 462.6588 - val_mae: 462.6588\n",
            "Epoch 704/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 461.6465 - mae: 461.6465 - val_loss: 463.3875 - val_mae: 463.3875\n",
            "Epoch 705/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 462.0757 - mae: 462.0757 - val_loss: 462.2172 - val_mae: 462.2172\n",
            "Epoch 706/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 458.8710 - mae: 458.8710 - val_loss: 462.3867 - val_mae: 462.3867\n",
            "Epoch 707/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 462.9548 - mae: 462.9548 - val_loss: 464.1547 - val_mae: 464.1547\n",
            "Epoch 708/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 460.9484 - mae: 460.9484 - val_loss: 464.5864 - val_mae: 464.5864\n",
            "Epoch 709/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 460.0170 - mae: 460.0170 - val_loss: 463.3604 - val_mae: 463.3604\n",
            "Epoch 710/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 461.0278 - mae: 461.0278 - val_loss: 463.7088 - val_mae: 463.7088\n",
            "Epoch 711/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 461.3820 - mae: 461.3820 - val_loss: 462.8795 - val_mae: 462.8795\n",
            "Epoch 712/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 459.4892 - mae: 459.4892 - val_loss: 462.7360 - val_mae: 462.7360\n",
            "Epoch 713/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 460.4150 - mae: 460.4150 - val_loss: 462.3783 - val_mae: 462.3783\n",
            "Epoch 714/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 461.8476 - mae: 461.8476 - val_loss: 463.3187 - val_mae: 463.3187\n",
            "Epoch 715/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 460.9696 - mae: 460.9696 - val_loss: 463.1311 - val_mae: 463.1311\n",
            "Epoch 716/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 461.1296 - mae: 461.1296 - val_loss: 463.4344 - val_mae: 463.4344\n",
            "Epoch 717/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 461.8773 - mae: 461.8773 - val_loss: 462.8382 - val_mae: 462.8382\n",
            "Epoch 718/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 461.0068 - mae: 461.0068 - val_loss: 463.7849 - val_mae: 463.7849\n",
            "Epoch 719/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 462.3680 - mae: 462.3680 - val_loss: 462.9171 - val_mae: 462.9171\n",
            "Epoch 720/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 461.5929 - mae: 461.5929 - val_loss: 462.8432 - val_mae: 462.8432\n",
            "Epoch 721/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 460.8849 - mae: 460.8849 - val_loss: 463.7000 - val_mae: 463.7000\n",
            "Epoch 722/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 462.8297 - mae: 462.8297 - val_loss: 462.7257 - val_mae: 462.7257\n",
            "Epoch 723/800\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 459.9113 - mae: 459.9113 - val_loss: 462.8213 - val_mae: 462.8213\n",
            "Epoch 724/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 458.7911 - mae: 458.7911 - val_loss: 464.0986 - val_mae: 464.0986\n",
            "Epoch 725/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 461.1380 - mae: 461.1380 - val_loss: 463.9917 - val_mae: 463.9917\n",
            "Epoch 726/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 460.1989 - mae: 460.1989 - val_loss: 463.9607 - val_mae: 463.9607\n",
            "Epoch 727/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 460.7791 - mae: 460.7791 - val_loss: 463.3115 - val_mae: 463.3115\n",
            "Epoch 728/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 460.5632 - mae: 460.5632 - val_loss: 462.0991 - val_mae: 462.0991\n",
            "Epoch 729/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 462.9417 - mae: 462.9417 - val_loss: 462.6271 - val_mae: 462.6271\n",
            "Epoch 730/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 458.7527 - mae: 458.7527 - val_loss: 462.4585 - val_mae: 462.4585\n",
            "Epoch 731/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 459.5437 - mae: 459.5437 - val_loss: 462.9669 - val_mae: 462.9669\n",
            "Epoch 732/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 462.0768 - mae: 462.0768 - val_loss: 462.3044 - val_mae: 462.3044\n",
            "Epoch 733/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 461.4780 - mae: 461.4780 - val_loss: 462.5491 - val_mae: 462.5491\n",
            "Epoch 734/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 459.5664 - mae: 459.5664 - val_loss: 462.6553 - val_mae: 462.6553\n",
            "Epoch 735/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 462.6374 - mae: 462.6374 - val_loss: 462.9492 - val_mae: 462.9492\n",
            "Epoch 736/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 458.9925 - mae: 458.9925 - val_loss: 462.5030 - val_mae: 462.5030\n",
            "Epoch 737/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 460.5623 - mae: 460.5623 - val_loss: 462.2943 - val_mae: 462.2943\n",
            "Epoch 738/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 462.8723 - mae: 462.8723 - val_loss: 462.7041 - val_mae: 462.7041\n",
            "Epoch 739/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 460.5628 - mae: 460.5628 - val_loss: 461.8941 - val_mae: 461.8941\n",
            "Epoch 740/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 460.3906 - mae: 460.3906 - val_loss: 462.6904 - val_mae: 462.6904\n",
            "Epoch 741/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 461.6656 - mae: 461.6656 - val_loss: 463.1349 - val_mae: 463.1349\n",
            "Epoch 742/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 460.8437 - mae: 460.8437 - val_loss: 462.6836 - val_mae: 462.6836\n",
            "Epoch 743/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 460.3546 - mae: 460.3546 - val_loss: 462.3916 - val_mae: 462.3916\n",
            "Epoch 744/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 462.2451 - mae: 462.2451 - val_loss: 462.5437 - val_mae: 462.5437\n",
            "Epoch 745/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 460.6636 - mae: 460.6636 - val_loss: 464.6871 - val_mae: 464.6871\n",
            "Epoch 746/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 460.9197 - mae: 460.9197 - val_loss: 463.6121 - val_mae: 463.6121\n",
            "Epoch 747/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 459.5128 - mae: 459.5128 - val_loss: 463.6974 - val_mae: 463.6974\n",
            "Epoch 748/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 461.9261 - mae: 461.9261 - val_loss: 463.3096 - val_mae: 463.3096\n",
            "Epoch 749/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 461.3762 - mae: 461.3762 - val_loss: 464.0119 - val_mae: 464.0119\n",
            "Epoch 750/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 460.0229 - mae: 460.0229 - val_loss: 462.9142 - val_mae: 462.9142\n",
            "Epoch 751/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 461.7032 - mae: 461.7032 - val_loss: 463.8108 - val_mae: 463.8108\n",
            "Epoch 752/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 461.2013 - mae: 461.2013 - val_loss: 462.3205 - val_mae: 462.3205\n",
            "Epoch 753/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 461.0045 - mae: 461.0045 - val_loss: 462.4920 - val_mae: 462.4920\n",
            "Epoch 754/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 459.1912 - mae: 459.1912 - val_loss: 463.5643 - val_mae: 463.5643\n",
            "Epoch 755/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 460.9418 - mae: 460.9418 - val_loss: 462.3021 - val_mae: 462.3021\n",
            "Epoch 756/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 460.4071 - mae: 460.4071 - val_loss: 464.3778 - val_mae: 464.3778\n",
            "Epoch 757/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 461.5457 - mae: 461.5457 - val_loss: 463.1646 - val_mae: 463.1646\n",
            "Epoch 758/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 459.7182 - mae: 459.7182 - val_loss: 463.3784 - val_mae: 463.3784\n",
            "Epoch 759/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 462.9521 - mae: 462.9521 - val_loss: 462.9580 - val_mae: 462.9580\n",
            "Epoch 760/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 460.7344 - mae: 460.7344 - val_loss: 463.2055 - val_mae: 463.2055\n",
            "Epoch 761/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 461.5508 - mae: 461.5508 - val_loss: 463.6227 - val_mae: 463.6227\n",
            "Epoch 762/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 460.7158 - mae: 460.7158 - val_loss: 463.4840 - val_mae: 463.4840\n",
            "Epoch 763/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 458.6656 - mae: 458.6656 - val_loss: 462.7561 - val_mae: 462.7561\n",
            "Epoch 764/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 458.9247 - mae: 458.9247 - val_loss: 462.4649 - val_mae: 462.4649\n",
            "Epoch 765/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 460.4482 - mae: 460.4482 - val_loss: 462.8654 - val_mae: 462.8654\n",
            "Epoch 766/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 461.8731 - mae: 461.8731 - val_loss: 463.2830 - val_mae: 463.2830\n",
            "Epoch 767/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 461.1872 - mae: 461.1872 - val_loss: 463.3098 - val_mae: 463.3098\n",
            "Epoch 768/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 460.0235 - mae: 460.0235 - val_loss: 462.7583 - val_mae: 462.7583\n",
            "Epoch 769/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 459.4627 - mae: 459.4627 - val_loss: 462.8278 - val_mae: 462.8278\n",
            "Epoch 770/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 460.7702 - mae: 460.7702 - val_loss: 463.0794 - val_mae: 463.0794\n",
            "Epoch 771/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 461.8418 - mae: 461.8418 - val_loss: 463.0930 - val_mae: 463.0930\n",
            "Epoch 772/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 461.7835 - mae: 461.7835 - val_loss: 462.2566 - val_mae: 462.2566\n",
            "Epoch 773/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 460.6328 - mae: 460.6328 - val_loss: 462.4671 - val_mae: 462.4671\n",
            "Epoch 774/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 459.4625 - mae: 459.4625 - val_loss: 462.1157 - val_mae: 462.1157\n",
            "Epoch 775/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 460.7182 - mae: 460.7182 - val_loss: 462.2883 - val_mae: 462.2883\n",
            "Epoch 776/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 459.1786 - mae: 459.1786 - val_loss: 463.3508 - val_mae: 463.3508\n",
            "Epoch 777/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 460.7504 - mae: 460.7504 - val_loss: 463.7210 - val_mae: 463.7210\n",
            "Epoch 778/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 458.7547 - mae: 458.7547 - val_loss: 464.6948 - val_mae: 464.6948\n",
            "Epoch 779/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 460.5013 - mae: 460.5013 - val_loss: 462.6637 - val_mae: 462.6637\n",
            "Epoch 780/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 459.9056 - mae: 459.9056 - val_loss: 462.5276 - val_mae: 462.5276\n",
            "Epoch 781/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 459.3297 - mae: 459.3297 - val_loss: 462.8549 - val_mae: 462.8549\n",
            "Epoch 782/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 459.4633 - mae: 459.4633 - val_loss: 462.8250 - val_mae: 462.8250\n",
            "Epoch 783/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 459.2711 - mae: 459.2711 - val_loss: 463.1443 - val_mae: 463.1443\n",
            "Epoch 784/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 459.7178 - mae: 459.7178 - val_loss: 463.4052 - val_mae: 463.4052\n",
            "Epoch 785/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 461.1725 - mae: 461.1725 - val_loss: 463.2566 - val_mae: 463.2566\n",
            "Epoch 786/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 460.4082 - mae: 460.4082 - val_loss: 463.3700 - val_mae: 463.3700\n",
            "Epoch 787/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 460.1397 - mae: 460.1397 - val_loss: 465.0273 - val_mae: 465.0273\n",
            "Epoch 788/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 460.4787 - mae: 460.4787 - val_loss: 463.0854 - val_mae: 463.0854\n",
            "Epoch 789/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 461.6235 - mae: 461.6235 - val_loss: 462.6852 - val_mae: 462.6852\n",
            "Epoch 790/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 460.5956 - mae: 460.5956 - val_loss: 463.8373 - val_mae: 463.8373\n",
            "Epoch 791/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 462.3758 - mae: 462.3758 - val_loss: 462.5379 - val_mae: 462.5379\n",
            "Epoch 792/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 461.7274 - mae: 461.7274 - val_loss: 463.8097 - val_mae: 463.8097\n",
            "Epoch 793/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 460.1223 - mae: 460.1223 - val_loss: 463.1108 - val_mae: 463.1108\n",
            "Epoch 794/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 461.2957 - mae: 461.2957 - val_loss: 463.3699 - val_mae: 463.3699\n",
            "Epoch 795/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 460.7891 - mae: 460.7891 - val_loss: 463.8756 - val_mae: 463.8756\n",
            "Epoch 796/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 460.0354 - mae: 460.0354 - val_loss: 463.4914 - val_mae: 463.4914\n",
            "Epoch 797/800\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 461.0282 - mae: 461.0282 - val_loss: 462.9965 - val_mae: 462.9965\n",
            "Epoch 798/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 460.4663 - mae: 460.4663 - val_loss: 463.2276 - val_mae: 463.2276\n",
            "Epoch 799/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 460.5796 - mae: 460.5796 - val_loss: 463.0774 - val_mae: 463.0774\n",
            "Epoch 800/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 458.8372 - mae: 458.8372 - val_loss: 462.3143 - val_mae: 462.3143\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Visualizing epoch vs loss during the training:**"
      ],
      "metadata": {
        "id": "wkSetrjVb3Ag"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "loss = pd.read_csv('log.csv',  sep=';')\n",
        "print(loss.head())\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(5,4))\n",
        "ax = sns.lineplot(data=loss, x='epoch', y='mae', label='training')\n",
        "ax = sns.lineplot(data=loss, x='epoch', y='val_mae', label='validation')\n",
        "ax.grid()\n",
        "ax.set_title('Benchmark Model')\n",
        "ax.legend()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 420
        },
        "id": "Z8Thku8sgJ5S",
        "outputId": "da45aa2a-7c93-4037-8260-73073c0abb46"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   epoch        loss         mae    val_loss     val_mae\n",
            "0      0  506.314636  506.314636  498.196625  498.196625\n",
            "1      1  494.400757  494.400757  485.890991  485.890991\n",
            "2      2  491.378876  491.378876  483.960602  483.960602\n",
            "3      3  489.634583  489.634583  482.813721  482.813721\n",
            "4      4  489.358185  489.358185  481.912537  481.912537\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fb11e4cb8d0>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 360x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Around epochs=230 we can stop the training since the validation loss reaches the minimum. If we train the model more than necessary there is the risk of overfitting as the model won't be able to generalize."
      ],
      "metadata": {
        "id": "baczy9hIxtTl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_b.fit(X_train,y_train,epochs=230,batch_size=64,validation_data=[X_test,y_test])\n",
        "print('Final MAE of validation: %f' %(model_b.evaluate(X_test, y_test)[1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v1hrPk9siemC",
        "outputId": "9b072c2f-47b3-4f28-e338-881f8acb4e8a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 460.2432 - mae: 460.2432 - val_loss: 463.4721 - val_mae: 463.4721\n",
            "Epoch 2/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 460.5812 - mae: 460.5812 - val_loss: 464.0488 - val_mae: 464.0488\n",
            "Epoch 3/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 459.9514 - mae: 459.9514 - val_loss: 463.3882 - val_mae: 463.3882\n",
            "Epoch 4/230\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 457.8713 - mae: 457.8713 - val_loss: 463.2037 - val_mae: 463.2037\n",
            "Epoch 5/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 459.0720 - mae: 459.0720 - val_loss: 463.1073 - val_mae: 463.1073\n",
            "Epoch 6/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 459.8507 - mae: 459.8507 - val_loss: 463.5528 - val_mae: 463.5528\n",
            "Epoch 7/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 458.6690 - mae: 458.6690 - val_loss: 461.8622 - val_mae: 461.8622\n",
            "Epoch 8/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 459.4239 - mae: 459.4239 - val_loss: 462.7763 - val_mae: 462.7763\n",
            "Epoch 9/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 459.1497 - mae: 459.1497 - val_loss: 461.6419 - val_mae: 461.6419\n",
            "Epoch 10/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 459.7184 - mae: 459.7184 - val_loss: 463.4691 - val_mae: 463.4691\n",
            "Epoch 11/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 459.5060 - mae: 459.5060 - val_loss: 463.1742 - val_mae: 463.1742\n",
            "Epoch 12/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 459.1547 - mae: 459.1547 - val_loss: 462.6396 - val_mae: 462.6396\n",
            "Epoch 13/230\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 460.6871 - mae: 460.6871 - val_loss: 462.5985 - val_mae: 462.5985\n",
            "Epoch 14/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 460.3016 - mae: 460.3016 - val_loss: 462.2339 - val_mae: 462.2339\n",
            "Epoch 15/230\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 459.0538 - mae: 459.0538 - val_loss: 462.4417 - val_mae: 462.4417\n",
            "Epoch 16/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 460.1751 - mae: 460.1751 - val_loss: 462.4386 - val_mae: 462.4386\n",
            "Epoch 17/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 460.0172 - mae: 460.0172 - val_loss: 461.2011 - val_mae: 461.2011\n",
            "Epoch 18/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 459.6397 - mae: 459.6397 - val_loss: 462.3743 - val_mae: 462.3743\n",
            "Epoch 19/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 458.7546 - mae: 458.7546 - val_loss: 462.4459 - val_mae: 462.4459\n",
            "Epoch 20/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 457.8029 - mae: 457.8029 - val_loss: 464.0197 - val_mae: 464.0197\n",
            "Epoch 21/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 460.9911 - mae: 460.9911 - val_loss: 464.2908 - val_mae: 464.2908\n",
            "Epoch 22/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 458.7076 - mae: 458.7076 - val_loss: 464.9110 - val_mae: 464.9110\n",
            "Epoch 23/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 460.2925 - mae: 460.2925 - val_loss: 463.7444 - val_mae: 463.7444\n",
            "Epoch 24/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 459.5654 - mae: 459.5654 - val_loss: 463.4717 - val_mae: 463.4717\n",
            "Epoch 25/230\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 461.9697 - mae: 461.9697 - val_loss: 464.0049 - val_mae: 464.0049\n",
            "Epoch 26/230\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 460.0022 - mae: 460.0022 - val_loss: 463.1089 - val_mae: 463.1089\n",
            "Epoch 27/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 460.4742 - mae: 460.4742 - val_loss: 464.0190 - val_mae: 464.0190\n",
            "Epoch 28/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 458.3321 - mae: 458.3321 - val_loss: 464.7808 - val_mae: 464.7808\n",
            "Epoch 29/230\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 460.8142 - mae: 460.8142 - val_loss: 463.0270 - val_mae: 463.0270\n",
            "Epoch 30/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 460.2261 - mae: 460.2261 - val_loss: 463.0045 - val_mae: 463.0045\n",
            "Epoch 31/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 458.8763 - mae: 458.8763 - val_loss: 462.5315 - val_mae: 462.5315\n",
            "Epoch 32/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 460.9585 - mae: 460.9585 - val_loss: 463.4891 - val_mae: 463.4891\n",
            "Epoch 33/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 459.2222 - mae: 459.2222 - val_loss: 462.4032 - val_mae: 462.4032\n",
            "Epoch 34/230\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 459.4178 - mae: 459.4178 - val_loss: 462.6594 - val_mae: 462.6594\n",
            "Epoch 35/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 459.4418 - mae: 459.4418 - val_loss: 462.7801 - val_mae: 462.7801\n",
            "Epoch 36/230\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 459.9739 - mae: 459.9739 - val_loss: 462.8835 - val_mae: 462.8835\n",
            "Epoch 37/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 461.1957 - mae: 461.1957 - val_loss: 462.8460 - val_mae: 462.8460\n",
            "Epoch 38/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 461.6803 - mae: 461.6803 - val_loss: 463.3286 - val_mae: 463.3286\n",
            "Epoch 39/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 461.0523 - mae: 461.0523 - val_loss: 464.0382 - val_mae: 464.0382\n",
            "Epoch 40/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 460.1252 - mae: 460.1252 - val_loss: 463.3622 - val_mae: 463.3622\n",
            "Epoch 41/230\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 459.1141 - mae: 459.1141 - val_loss: 462.5344 - val_mae: 462.5344\n",
            "Epoch 42/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 460.3958 - mae: 460.3958 - val_loss: 463.0491 - val_mae: 463.0491\n",
            "Epoch 43/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 461.6287 - mae: 461.6287 - val_loss: 464.0616 - val_mae: 464.0616\n",
            "Epoch 44/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 459.2449 - mae: 459.2449 - val_loss: 462.2459 - val_mae: 462.2459\n",
            "Epoch 45/230\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 459.5811 - mae: 459.5811 - val_loss: 463.9440 - val_mae: 463.9440\n",
            "Epoch 46/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 461.5563 - mae: 461.5563 - val_loss: 462.0166 - val_mae: 462.0166\n",
            "Epoch 47/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 459.0329 - mae: 459.0329 - val_loss: 462.1393 - val_mae: 462.1393\n",
            "Epoch 48/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 459.7008 - mae: 459.7008 - val_loss: 463.0551 - val_mae: 463.0551\n",
            "Epoch 49/230\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 460.1157 - mae: 460.1157 - val_loss: 462.1861 - val_mae: 462.1861\n",
            "Epoch 50/230\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 460.2260 - mae: 460.2260 - val_loss: 462.2136 - val_mae: 462.2136\n",
            "Epoch 51/230\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 458.3080 - mae: 458.3080 - val_loss: 462.9682 - val_mae: 462.9682\n",
            "Epoch 52/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 459.7228 - mae: 459.7228 - val_loss: 462.8758 - val_mae: 462.8758\n",
            "Epoch 53/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 461.1444 - mae: 461.1444 - val_loss: 462.2698 - val_mae: 462.2698\n",
            "Epoch 54/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 461.1353 - mae: 461.1353 - val_loss: 463.0259 - val_mae: 463.0259\n",
            "Epoch 55/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 459.1553 - mae: 459.1553 - val_loss: 462.9641 - val_mae: 462.9641\n",
            "Epoch 56/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 459.8898 - mae: 459.8898 - val_loss: 463.4445 - val_mae: 463.4445\n",
            "Epoch 57/230\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 460.2267 - mae: 460.2267 - val_loss: 463.9140 - val_mae: 463.9140\n",
            "Epoch 58/230\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 459.4103 - mae: 459.4103 - val_loss: 464.4485 - val_mae: 464.4485\n",
            "Epoch 59/230\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 458.3738 - mae: 458.3738 - val_loss: 464.1648 - val_mae: 464.1648\n",
            "Epoch 60/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 457.2036 - mae: 457.2036 - val_loss: 463.5083 - val_mae: 463.5083\n",
            "Epoch 61/230\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 461.1322 - mae: 461.1322 - val_loss: 463.1779 - val_mae: 463.1779\n",
            "Epoch 62/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 460.2046 - mae: 460.2046 - val_loss: 463.3427 - val_mae: 463.3427\n",
            "Epoch 63/230\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 458.9252 - mae: 458.9252 - val_loss: 463.1182 - val_mae: 463.1182\n",
            "Epoch 64/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 459.3579 - mae: 459.3579 - val_loss: 462.5407 - val_mae: 462.5407\n",
            "Epoch 65/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 457.1197 - mae: 457.1197 - val_loss: 462.7928 - val_mae: 462.7928\n",
            "Epoch 66/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 459.3235 - mae: 459.3235 - val_loss: 463.3528 - val_mae: 463.3528\n",
            "Epoch 67/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 461.7090 - mae: 461.7090 - val_loss: 463.0225 - val_mae: 463.0225\n",
            "Epoch 68/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 458.8567 - mae: 458.8567 - val_loss: 462.5403 - val_mae: 462.5403\n",
            "Epoch 69/230\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 458.3025 - mae: 458.3025 - val_loss: 462.1117 - val_mae: 462.1117\n",
            "Epoch 70/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 459.7802 - mae: 459.7802 - val_loss: 463.5622 - val_mae: 463.5622\n",
            "Epoch 71/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 458.9841 - mae: 458.9841 - val_loss: 463.2607 - val_mae: 463.2607\n",
            "Epoch 72/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 458.3811 - mae: 458.3811 - val_loss: 463.2933 - val_mae: 463.2933\n",
            "Epoch 73/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 458.9453 - mae: 458.9453 - val_loss: 463.7271 - val_mae: 463.7271\n",
            "Epoch 74/230\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 457.0449 - mae: 457.0449 - val_loss: 463.1573 - val_mae: 463.1573\n",
            "Epoch 75/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 459.9310 - mae: 459.9310 - val_loss: 463.5701 - val_mae: 463.5701\n",
            "Epoch 76/230\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 458.5480 - mae: 458.5480 - val_loss: 462.9012 - val_mae: 462.9012\n",
            "Epoch 77/230\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 457.6617 - mae: 457.6617 - val_loss: 464.5492 - val_mae: 464.5492\n",
            "Epoch 78/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 456.8518 - mae: 456.8518 - val_loss: 463.2505 - val_mae: 463.2505\n",
            "Epoch 79/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 460.7657 - mae: 460.7657 - val_loss: 463.0912 - val_mae: 463.0912\n",
            "Epoch 80/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 458.8953 - mae: 458.8953 - val_loss: 462.8610 - val_mae: 462.8610\n",
            "Epoch 81/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 460.2212 - mae: 460.2212 - val_loss: 463.8420 - val_mae: 463.8420\n",
            "Epoch 82/230\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 459.8807 - mae: 459.8807 - val_loss: 463.4749 - val_mae: 463.4749\n",
            "Epoch 83/230\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 459.1485 - mae: 459.1485 - val_loss: 464.3546 - val_mae: 464.3546\n",
            "Epoch 84/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 458.9001 - mae: 458.9001 - val_loss: 464.8177 - val_mae: 464.8177\n",
            "Epoch 85/230\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 459.1725 - mae: 459.1725 - val_loss: 464.1811 - val_mae: 464.1811\n",
            "Epoch 86/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 457.9699 - mae: 457.9699 - val_loss: 464.3464 - val_mae: 464.3464\n",
            "Epoch 87/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 458.4255 - mae: 458.4255 - val_loss: 463.6422 - val_mae: 463.6422\n",
            "Epoch 88/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 457.8723 - mae: 457.8723 - val_loss: 464.4702 - val_mae: 464.4702\n",
            "Epoch 89/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 458.7373 - mae: 458.7373 - val_loss: 463.6334 - val_mae: 463.6334\n",
            "Epoch 90/230\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 459.3489 - mae: 459.3489 - val_loss: 463.3287 - val_mae: 463.3287\n",
            "Epoch 91/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 458.9547 - mae: 458.9547 - val_loss: 463.8608 - val_mae: 463.8608\n",
            "Epoch 92/230\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 455.8356 - mae: 455.8356 - val_loss: 464.4098 - val_mae: 464.4098\n",
            "Epoch 93/230\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 458.5995 - mae: 458.5995 - val_loss: 463.3794 - val_mae: 463.3794\n",
            "Epoch 94/230\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 457.4838 - mae: 457.4838 - val_loss: 462.9367 - val_mae: 462.9367\n",
            "Epoch 95/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 458.3059 - mae: 458.3059 - val_loss: 463.2216 - val_mae: 463.2216\n",
            "Epoch 96/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 460.5197 - mae: 460.5197 - val_loss: 463.9570 - val_mae: 463.9570\n",
            "Epoch 97/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 459.3229 - mae: 459.3229 - val_loss: 463.8190 - val_mae: 463.8190\n",
            "Epoch 98/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 460.0746 - mae: 460.0746 - val_loss: 463.7451 - val_mae: 463.7451\n",
            "Epoch 99/230\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 462.1236 - mae: 462.1236 - val_loss: 463.7547 - val_mae: 463.7547\n",
            "Epoch 100/230\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 458.3450 - mae: 458.3450 - val_loss: 464.6123 - val_mae: 464.6123\n",
            "Epoch 101/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 460.1998 - mae: 460.1998 - val_loss: 464.6018 - val_mae: 464.6018\n",
            "Epoch 102/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 458.9326 - mae: 458.9326 - val_loss: 463.7041 - val_mae: 463.7041\n",
            "Epoch 103/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 460.1942 - mae: 460.1942 - val_loss: 463.7326 - val_mae: 463.7326\n",
            "Epoch 104/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 461.0718 - mae: 461.0718 - val_loss: 463.9889 - val_mae: 463.9889\n",
            "Epoch 105/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 458.9650 - mae: 458.9650 - val_loss: 464.6727 - val_mae: 464.6727\n",
            "Epoch 106/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 460.5040 - mae: 460.5040 - val_loss: 464.5138 - val_mae: 464.5138\n",
            "Epoch 107/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 457.6027 - mae: 457.6027 - val_loss: 464.0606 - val_mae: 464.0606\n",
            "Epoch 108/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 460.7812 - mae: 460.7812 - val_loss: 464.2786 - val_mae: 464.2786\n",
            "Epoch 109/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 458.5678 - mae: 458.5678 - val_loss: 464.2761 - val_mae: 464.2761\n",
            "Epoch 110/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 458.4141 - mae: 458.4141 - val_loss: 462.9723 - val_mae: 462.9723\n",
            "Epoch 111/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 459.3000 - mae: 459.3000 - val_loss: 463.8257 - val_mae: 463.8257\n",
            "Epoch 112/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 457.4882 - mae: 457.4882 - val_loss: 465.0813 - val_mae: 465.0813\n",
            "Epoch 113/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 458.5563 - mae: 458.5563 - val_loss: 464.5760 - val_mae: 464.5760\n",
            "Epoch 114/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 458.6684 - mae: 458.6684 - val_loss: 464.7584 - val_mae: 464.7584\n",
            "Epoch 115/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 458.6164 - mae: 458.6164 - val_loss: 463.7234 - val_mae: 463.7234\n",
            "Epoch 116/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 457.2805 - mae: 457.2805 - val_loss: 463.9385 - val_mae: 463.9385\n",
            "Epoch 117/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 459.2995 - mae: 459.2995 - val_loss: 463.9043 - val_mae: 463.9043\n",
            "Epoch 118/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 457.4382 - mae: 457.4382 - val_loss: 463.9323 - val_mae: 463.9323\n",
            "Epoch 119/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 458.0865 - mae: 458.0865 - val_loss: 464.4491 - val_mae: 464.4491\n",
            "Epoch 120/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 459.7788 - mae: 459.7788 - val_loss: 463.7130 - val_mae: 463.7130\n",
            "Epoch 121/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 458.2559 - mae: 458.2559 - val_loss: 464.1308 - val_mae: 464.1308\n",
            "Epoch 122/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 460.3969 - mae: 460.3969 - val_loss: 464.3495 - val_mae: 464.3495\n",
            "Epoch 123/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 457.9360 - mae: 457.9360 - val_loss: 465.1503 - val_mae: 465.1503\n",
            "Epoch 124/230\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 458.0260 - mae: 458.0260 - val_loss: 464.3294 - val_mae: 464.3294\n",
            "Epoch 125/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 458.0598 - mae: 458.0598 - val_loss: 464.1960 - val_mae: 464.1960\n",
            "Epoch 126/230\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 459.1601 - mae: 459.1601 - val_loss: 464.9147 - val_mae: 464.9147\n",
            "Epoch 127/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 460.7368 - mae: 460.7368 - val_loss: 464.0269 - val_mae: 464.0269\n",
            "Epoch 128/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 459.9968 - mae: 459.9968 - val_loss: 464.6424 - val_mae: 464.6424\n",
            "Epoch 129/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 458.9066 - mae: 458.9066 - val_loss: 463.9189 - val_mae: 463.9189\n",
            "Epoch 130/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 458.2824 - mae: 458.2824 - val_loss: 463.5250 - val_mae: 463.5250\n",
            "Epoch 131/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 456.4317 - mae: 456.4317 - val_loss: 463.4956 - val_mae: 463.4956\n",
            "Epoch 132/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 458.8460 - mae: 458.8460 - val_loss: 464.0232 - val_mae: 464.0232\n",
            "Epoch 133/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 459.1319 - mae: 459.1319 - val_loss: 464.3451 - val_mae: 464.3451\n",
            "Epoch 134/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 459.1617 - mae: 459.1617 - val_loss: 464.8986 - val_mae: 464.8986\n",
            "Epoch 135/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 458.8269 - mae: 458.8269 - val_loss: 464.6383 - val_mae: 464.6383\n",
            "Epoch 136/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 458.9245 - mae: 458.9245 - val_loss: 464.3205 - val_mae: 464.3205\n",
            "Epoch 137/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 459.6466 - mae: 459.6466 - val_loss: 464.5567 - val_mae: 464.5567\n",
            "Epoch 138/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 461.5694 - mae: 461.5694 - val_loss: 465.7322 - val_mae: 465.7322\n",
            "Epoch 139/230\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 459.0091 - mae: 459.0091 - val_loss: 463.5408 - val_mae: 463.5408\n",
            "Epoch 140/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 458.3760 - mae: 458.3760 - val_loss: 464.4482 - val_mae: 464.4482\n",
            "Epoch 141/230\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 457.6435 - mae: 457.6435 - val_loss: 463.2949 - val_mae: 463.2949\n",
            "Epoch 142/230\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 456.3471 - mae: 456.3471 - val_loss: 462.4754 - val_mae: 462.4754\n",
            "Epoch 143/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 458.3364 - mae: 458.3364 - val_loss: 462.9590 - val_mae: 462.9590\n",
            "Epoch 144/230\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 459.5795 - mae: 459.5795 - val_loss: 463.3152 - val_mae: 463.3152\n",
            "Epoch 145/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 457.5487 - mae: 457.5487 - val_loss: 463.1910 - val_mae: 463.1910\n",
            "Epoch 146/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 457.0643 - mae: 457.0643 - val_loss: 463.4757 - val_mae: 463.4757\n",
            "Epoch 147/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 459.7307 - mae: 459.7307 - val_loss: 463.6432 - val_mae: 463.6432\n",
            "Epoch 148/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 459.4552 - mae: 459.4552 - val_loss: 464.7251 - val_mae: 464.7251\n",
            "Epoch 149/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 456.4109 - mae: 456.4109 - val_loss: 463.7407 - val_mae: 463.7407\n",
            "Epoch 150/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 458.0180 - mae: 458.0180 - val_loss: 464.5174 - val_mae: 464.5174\n",
            "Epoch 151/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 457.2022 - mae: 457.2022 - val_loss: 464.5428 - val_mae: 464.5428\n",
            "Epoch 152/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 457.1314 - mae: 457.1314 - val_loss: 465.4345 - val_mae: 465.4345\n",
            "Epoch 153/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 459.5318 - mae: 459.5318 - val_loss: 464.6807 - val_mae: 464.6807\n",
            "Epoch 154/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 458.6756 - mae: 458.6756 - val_loss: 465.4174 - val_mae: 465.4174\n",
            "Epoch 155/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 460.1249 - mae: 460.1249 - val_loss: 465.0335 - val_mae: 465.0335\n",
            "Epoch 156/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 457.5662 - mae: 457.5662 - val_loss: 463.9125 - val_mae: 463.9125\n",
            "Epoch 157/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 458.1064 - mae: 458.1064 - val_loss: 465.6660 - val_mae: 465.6660\n",
            "Epoch 158/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 457.7486 - mae: 457.7486 - val_loss: 464.4307 - val_mae: 464.4307\n",
            "Epoch 159/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 458.1945 - mae: 458.1945 - val_loss: 464.3018 - val_mae: 464.3018\n",
            "Epoch 160/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 458.2986 - mae: 458.2986 - val_loss: 463.5310 - val_mae: 463.5310\n",
            "Epoch 161/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 460.2243 - mae: 460.2243 - val_loss: 464.0756 - val_mae: 464.0756\n",
            "Epoch 162/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 458.2586 - mae: 458.2586 - val_loss: 464.4701 - val_mae: 464.4701\n",
            "Epoch 163/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 458.1051 - mae: 458.1051 - val_loss: 464.3498 - val_mae: 464.3498\n",
            "Epoch 164/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 457.5280 - mae: 457.5280 - val_loss: 464.0887 - val_mae: 464.0887\n",
            "Epoch 165/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 457.2356 - mae: 457.2356 - val_loss: 464.0198 - val_mae: 464.0198\n",
            "Epoch 166/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 457.4142 - mae: 457.4142 - val_loss: 465.2218 - val_mae: 465.2218\n",
            "Epoch 167/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 459.6084 - mae: 459.6084 - val_loss: 465.1893 - val_mae: 465.1893\n",
            "Epoch 168/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 457.8931 - mae: 457.8931 - val_loss: 464.2891 - val_mae: 464.2891\n",
            "Epoch 169/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 457.6813 - mae: 457.6813 - val_loss: 464.0378 - val_mae: 464.0378\n",
            "Epoch 170/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 458.3602 - mae: 458.3602 - val_loss: 464.8231 - val_mae: 464.8231\n",
            "Epoch 171/230\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 460.9211 - mae: 460.9211 - val_loss: 464.1095 - val_mae: 464.1095\n",
            "Epoch 172/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 457.9687 - mae: 457.9687 - val_loss: 464.1014 - val_mae: 464.1014\n",
            "Epoch 173/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 458.3623 - mae: 458.3623 - val_loss: 463.1652 - val_mae: 463.1652\n",
            "Epoch 174/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 457.1680 - mae: 457.1680 - val_loss: 464.0604 - val_mae: 464.0604\n",
            "Epoch 175/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 458.4288 - mae: 458.4288 - val_loss: 463.8659 - val_mae: 463.8659\n",
            "Epoch 176/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 455.5513 - mae: 455.5513 - val_loss: 464.1401 - val_mae: 464.1401\n",
            "Epoch 177/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 456.9654 - mae: 456.9654 - val_loss: 463.5657 - val_mae: 463.5657\n",
            "Epoch 178/230\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 457.3498 - mae: 457.3498 - val_loss: 463.6337 - val_mae: 463.6337\n",
            "Epoch 179/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 456.9985 - mae: 456.9985 - val_loss: 464.6700 - val_mae: 464.6700\n",
            "Epoch 180/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 459.8631 - mae: 459.8631 - val_loss: 464.7642 - val_mae: 464.7642\n",
            "Epoch 181/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 457.8684 - mae: 457.8684 - val_loss: 463.8239 - val_mae: 463.8239\n",
            "Epoch 182/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 457.7839 - mae: 457.7839 - val_loss: 462.8849 - val_mae: 462.8849\n",
            "Epoch 183/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 459.7377 - mae: 459.7377 - val_loss: 464.0412 - val_mae: 464.0412\n",
            "Epoch 184/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 458.6902 - mae: 458.6902 - val_loss: 464.9970 - val_mae: 464.9970\n",
            "Epoch 185/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 455.8568 - mae: 455.8568 - val_loss: 465.1272 - val_mae: 465.1272\n",
            "Epoch 186/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 457.2854 - mae: 457.2854 - val_loss: 465.1336 - val_mae: 465.1336\n",
            "Epoch 187/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 457.0583 - mae: 457.0583 - val_loss: 465.6798 - val_mae: 465.6798\n",
            "Epoch 188/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 456.7930 - mae: 456.7930 - val_loss: 462.6177 - val_mae: 462.6177\n",
            "Epoch 189/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 456.7053 - mae: 456.7053 - val_loss: 462.8645 - val_mae: 462.8645\n",
            "Epoch 190/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 457.4859 - mae: 457.4859 - val_loss: 464.2245 - val_mae: 464.2245\n",
            "Epoch 191/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 457.0038 - mae: 457.0038 - val_loss: 465.2145 - val_mae: 465.2145\n",
            "Epoch 192/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 459.7631 - mae: 459.7631 - val_loss: 465.1331 - val_mae: 465.1331\n",
            "Epoch 193/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 457.5534 - mae: 457.5534 - val_loss: 465.2160 - val_mae: 465.2160\n",
            "Epoch 194/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 455.8629 - mae: 455.8629 - val_loss: 464.3927 - val_mae: 464.3927\n",
            "Epoch 195/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 458.3634 - mae: 458.3634 - val_loss: 463.9452 - val_mae: 463.9452\n",
            "Epoch 196/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 456.3730 - mae: 456.3730 - val_loss: 464.2133 - val_mae: 464.2133\n",
            "Epoch 197/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 457.6540 - mae: 457.6540 - val_loss: 463.9259 - val_mae: 463.9259\n",
            "Epoch 198/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 456.9056 - mae: 456.9056 - val_loss: 463.9445 - val_mae: 463.9445\n",
            "Epoch 199/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 457.2731 - mae: 457.2731 - val_loss: 463.6968 - val_mae: 463.6968\n",
            "Epoch 200/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 458.4618 - mae: 458.4618 - val_loss: 464.2820 - val_mae: 464.2820\n",
            "Epoch 201/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 456.1278 - mae: 456.1278 - val_loss: 464.8152 - val_mae: 464.8152\n",
            "Epoch 202/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 457.0967 - mae: 457.0967 - val_loss: 463.2393 - val_mae: 463.2393\n",
            "Epoch 203/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 458.7486 - mae: 458.7486 - val_loss: 464.5829 - val_mae: 464.5829\n",
            "Epoch 204/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 459.1639 - mae: 459.1639 - val_loss: 465.3101 - val_mae: 465.3101\n",
            "Epoch 205/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 457.1253 - mae: 457.1253 - val_loss: 464.9012 - val_mae: 464.9012\n",
            "Epoch 206/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 459.9680 - mae: 459.9680 - val_loss: 465.5659 - val_mae: 465.5659\n",
            "Epoch 207/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 457.3814 - mae: 457.3814 - val_loss: 466.0782 - val_mae: 466.0782\n",
            "Epoch 208/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 454.9513 - mae: 454.9513 - val_loss: 465.7054 - val_mae: 465.7054\n",
            "Epoch 209/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 456.5558 - mae: 456.5558 - val_loss: 464.5815 - val_mae: 464.5815\n",
            "Epoch 210/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 457.4017 - mae: 457.4017 - val_loss: 465.6154 - val_mae: 465.6154\n",
            "Epoch 211/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 458.0339 - mae: 458.0339 - val_loss: 464.7200 - val_mae: 464.7200\n",
            "Epoch 212/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 457.5831 - mae: 457.5831 - val_loss: 464.9124 - val_mae: 464.9124\n",
            "Epoch 213/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 456.7079 - mae: 456.7079 - val_loss: 465.1559 - val_mae: 465.1559\n",
            "Epoch 214/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 457.6823 - mae: 457.6823 - val_loss: 466.3364 - val_mae: 466.3364\n",
            "Epoch 215/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 456.8714 - mae: 456.8714 - val_loss: 466.3862 - val_mae: 466.3862\n",
            "Epoch 216/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 458.3713 - mae: 458.3713 - val_loss: 466.8045 - val_mae: 466.8045\n",
            "Epoch 217/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 455.6649 - mae: 455.6649 - val_loss: 467.2585 - val_mae: 467.2585\n",
            "Epoch 218/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 459.6294 - mae: 459.6294 - val_loss: 466.6006 - val_mae: 466.6006\n",
            "Epoch 219/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 457.0790 - mae: 457.0790 - val_loss: 467.1805 - val_mae: 467.1805\n",
            "Epoch 220/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 456.9582 - mae: 456.9582 - val_loss: 468.1699 - val_mae: 468.1699\n",
            "Epoch 221/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 457.0180 - mae: 457.0180 - val_loss: 465.4776 - val_mae: 465.4776\n",
            "Epoch 222/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 461.0598 - mae: 461.0598 - val_loss: 465.7336 - val_mae: 465.7336\n",
            "Epoch 223/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 456.8297 - mae: 456.8297 - val_loss: 465.2336 - val_mae: 465.2336\n",
            "Epoch 224/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 458.4512 - mae: 458.4512 - val_loss: 466.0323 - val_mae: 466.0323\n",
            "Epoch 225/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 459.5695 - mae: 459.5695 - val_loss: 466.1241 - val_mae: 466.1241\n",
            "Epoch 226/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 457.1730 - mae: 457.1730 - val_loss: 466.6611 - val_mae: 466.6611\n",
            "Epoch 227/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 456.2321 - mae: 456.2321 - val_loss: 466.8443 - val_mae: 466.8443\n",
            "Epoch 228/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 459.3731 - mae: 459.3731 - val_loss: 466.7114 - val_mae: 466.7114\n",
            "Epoch 229/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 459.0470 - mae: 459.0470 - val_loss: 465.0552 - val_mae: 465.0552\n",
            "Epoch 230/230\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 456.8407 - mae: 456.8407 - val_loss: 464.7641 - val_mae: 464.7641\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 464.7640 - mae: 464.7640\n",
            "Final MAE of validation: 464.764038\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "pzsxgtHtIEs2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Engineering"
      ],
      "metadata": {
        "id": "22yZchs_J55V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "By using the features that we have, one can create new features. By comparing the deposit and deposit_next of the users, we can find out which users decided to put more money in their account than before or which users simply didn't invest more in the next 30 days. \n",
        "\n",
        "Another information we can get would be if a user changed their mind to play online gambling. These people withdraw all the money they put in their first activity (tenure=0) without spending any (turnover=0) and not investing in the next 30 days (deposit_next=0). These people might not be essential for the training, however, I chose to keep them for now."
      ],
      "metadata": {
        "id": "gxImRGdDe6xk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_label(deposit_next, deposit):\n",
        "    if deposit_next==0:\n",
        "        return 'no invest'\n",
        "    elif deposit_next>deposit: \n",
        "        return 'go bigger' \n",
        "    elif deposit_next<deposit:\n",
        "        return 'go easy'\n",
        "    \n",
        "def get_level(tenure):\n",
        "    if tenure<=90:\n",
        "        return 'beginner'\n",
        "    elif tenure>90 and tenure<=180: \n",
        "        return 'preinter' \n",
        "    elif tenure>180 and tenure<=365:\n",
        "        return 'inter'\n",
        "    elif tenure>365:\n",
        "        return 'advanced'\n",
        "\n",
        "def changed_decision(deposit, turnover, withdrawal, deposit_next):\n",
        "    if deposit == withdrawal and turnover==0 and deposit_next==0:\n",
        "        return 'yes'\n",
        "    else:\n",
        "        return 'no'\n",
        "\n",
        "def did_win(deposit, turnover):\n",
        "    if deposit < turnover:\n",
        "        return 'yes'\n",
        "    else:\n",
        "        return 'no' \n",
        "    \n",
        "data['next_decision'] = data.apply(lambda x: get_label(x.deposit_next, x.deposit), axis=1)\n",
        "data['changed_decision'] = data.apply(lambda x: changed_decision(x.deposit, x.turnover, x.withdrawal, x.deposit_next), axis=1)\n",
        "data['won_min_once'] = data.apply(lambda x: did_win(x.deposit, x.turnover), axis=1)\n",
        "data['level'] = data.apply(lambda x: get_level(x.tenure), axis=1)\n"
      ],
      "metadata": {
        "id": "C4iKUsSZaOa-"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "I can use only 'won_min_once' and 'level' as a new input feature since the other two new columns were created by using the target.\n"
      ],
      "metadata": {
        "id": "u4mh-4ONgYc3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "8eZfmF9DUhZl",
        "outputId": "ecdf751b-9737-43ba-f40a-57613df18b2e"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   tenure  deposit  turnover  withdrawal  deposit_next next_decision  \\\n",
              "0      10   762.27   1677.18     1476.24       2815.66     go bigger   \n",
              "1    1473    69.99    279.16        0.00          0.00     no invest   \n",
              "2     297    34.35     81.99        0.00          0.00     no invest   \n",
              "3    3829  4347.15  41290.29        0.00          0.00     no invest   \n",
              "4    1258  3593.85  13883.59     8825.21          0.00     no invest   \n",
              "\n",
              "  changed_decision won_min_once     level  \n",
              "0               no          yes  beginner  \n",
              "1               no          yes  advanced  \n",
              "2               no          yes     inter  \n",
              "3               no          yes  advanced  \n",
              "4               no          yes  advanced  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c0586815-9a87-4cf8-a909-d60a675c73bc\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tenure</th>\n",
              "      <th>deposit</th>\n",
              "      <th>turnover</th>\n",
              "      <th>withdrawal</th>\n",
              "      <th>deposit_next</th>\n",
              "      <th>next_decision</th>\n",
              "      <th>changed_decision</th>\n",
              "      <th>won_min_once</th>\n",
              "      <th>level</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10</td>\n",
              "      <td>762.27</td>\n",
              "      <td>1677.18</td>\n",
              "      <td>1476.24</td>\n",
              "      <td>2815.66</td>\n",
              "      <td>go bigger</td>\n",
              "      <td>no</td>\n",
              "      <td>yes</td>\n",
              "      <td>beginner</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1473</td>\n",
              "      <td>69.99</td>\n",
              "      <td>279.16</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>no invest</td>\n",
              "      <td>no</td>\n",
              "      <td>yes</td>\n",
              "      <td>advanced</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>297</td>\n",
              "      <td>34.35</td>\n",
              "      <td>81.99</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>no invest</td>\n",
              "      <td>no</td>\n",
              "      <td>yes</td>\n",
              "      <td>inter</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3829</td>\n",
              "      <td>4347.15</td>\n",
              "      <td>41290.29</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>no invest</td>\n",
              "      <td>no</td>\n",
              "      <td>yes</td>\n",
              "      <td>advanced</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1258</td>\n",
              "      <td>3593.85</td>\n",
              "      <td>13883.59</td>\n",
              "      <td>8825.21</td>\n",
              "      <td>0.00</td>\n",
              "      <td>no invest</td>\n",
              "      <td>no</td>\n",
              "      <td>yes</td>\n",
              "      <td>advanced</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c0586815-9a87-4cf8-a909-d60a675c73bc')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c0586815-9a87-4cf8-a909-d60a675c73bc button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c0586815-9a87-4cf8-a909-d60a675c73bc');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Label Encoding:"
      ],
      "metadata": {
        "id": "2kV2oNemLRPX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since the new feature is a categorical feature, I will use label encoding to include its effect on the output.\n",
        "\n",
        "I create a copy of the dataframe 'data' since I would like to keep it for legacy."
      ],
      "metadata": {
        "id": "LcLxInWBN0u_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_enc = data.copy()\n",
        "data_enc['won_min_once'] = LabelEncoder().fit_transform(data_enc['won_min_once']) \n",
        "data_enc['level'] = LabelEncoder().fit_transform(data_enc['level']) \n",
        "data_enc.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "00pKcOZLcCKK",
        "outputId": "37be2c2e-83f4-4c32-83e4-d24c15b35b49"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   tenure  deposit  turnover  withdrawal  deposit_next next_decision  \\\n",
              "0      10   762.27   1677.18     1476.24       2815.66     go bigger   \n",
              "1    1473    69.99    279.16        0.00          0.00     no invest   \n",
              "2     297    34.35     81.99        0.00          0.00     no invest   \n",
              "3    3829  4347.15  41290.29        0.00          0.00     no invest   \n",
              "4    1258  3593.85  13883.59     8825.21          0.00     no invest   \n",
              "\n",
              "  changed_decision  won_min_once  level  \n",
              "0               no             1      1  \n",
              "1               no             1      0  \n",
              "2               no             1      2  \n",
              "3               no             1      0  \n",
              "4               no             1      0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-feae56e4-175c-46d8-9ec0-6a42e8831801\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tenure</th>\n",
              "      <th>deposit</th>\n",
              "      <th>turnover</th>\n",
              "      <th>withdrawal</th>\n",
              "      <th>deposit_next</th>\n",
              "      <th>next_decision</th>\n",
              "      <th>changed_decision</th>\n",
              "      <th>won_min_once</th>\n",
              "      <th>level</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10</td>\n",
              "      <td>762.27</td>\n",
              "      <td>1677.18</td>\n",
              "      <td>1476.24</td>\n",
              "      <td>2815.66</td>\n",
              "      <td>go bigger</td>\n",
              "      <td>no</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1473</td>\n",
              "      <td>69.99</td>\n",
              "      <td>279.16</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>no invest</td>\n",
              "      <td>no</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>297</td>\n",
              "      <td>34.35</td>\n",
              "      <td>81.99</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>no invest</td>\n",
              "      <td>no</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3829</td>\n",
              "      <td>4347.15</td>\n",
              "      <td>41290.29</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>no invest</td>\n",
              "      <td>no</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1258</td>\n",
              "      <td>3593.85</td>\n",
              "      <td>13883.59</td>\n",
              "      <td>8825.21</td>\n",
              "      <td>0.00</td>\n",
              "      <td>no invest</td>\n",
              "      <td>no</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-feae56e4-175c-46d8-9ec0-6a42e8831801')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-feae56e4-175c-46d8-9ec0-6a42e8831801 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-feae56e4-175c-46d8-9ec0-6a42e8831801');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now I will train a new model by including the new feature that was encoded. Note that input layer will have **6 neurons** this time."
      ],
      "metadata": {
        "id": "dBYsDXyjNji-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "target = data_enc.deposit_next\n",
        "input_features = data_enc[['tenure', 'deposit', 'turnover', 'withdrawal', 'won_min_once', 'level']]\n",
        "\n",
        "scaled = scaler.fit_transform(input_features)\n",
        "X_train, X_test, y_train, y_test = train_test_split(scaled, target, test_size=0.2, random_state=42)\n",
        "\n",
        "model1 = Sequential()\n",
        "model1.add(Dense(128, input_shape=(6,), activation='relu'))\n",
        "model1.add(Dropout(0.5)) \n",
        "model1.add(Dense(64, activation='relu'))\n",
        "model1.add(Dense(32, activation='relu'))\n",
        "model1.add(Dense(1))\n",
        "model1.compile(optimizer='adam', loss='mae', metrics='mae')\n",
        "\n",
        "csv_logger = CSVLogger('log_enc.csv', append=True, separator=';')\n",
        "history=model1.fit(X_train,y_train,epochs=800,batch_size=64,validation_data=[X_test,y_test],callbacks=[csv_logger])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bX0Qzni1cMKE",
        "outputId": "3902e270-de30-4249-bf86-d10f77748dc7"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 506.1546 - mae: 506.1546 - val_loss: 496.4311 - val_mae: 496.4311\n",
            "Epoch 2/800\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 493.9015 - mae: 493.9015 - val_loss: 485.5354 - val_mae: 485.5354\n",
            "Epoch 3/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 491.0835 - mae: 491.0835 - val_loss: 483.3463 - val_mae: 483.3463\n",
            "Epoch 4/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 489.1265 - mae: 489.1265 - val_loss: 481.8950 - val_mae: 481.8950\n",
            "Epoch 5/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 488.4158 - mae: 488.4158 - val_loss: 480.8520 - val_mae: 480.8520\n",
            "Epoch 6/800\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 487.7822 - mae: 487.7822 - val_loss: 480.4446 - val_mae: 480.4446\n",
            "Epoch 7/800\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 485.3670 - mae: 485.3670 - val_loss: 477.1235 - val_mae: 477.1235\n",
            "Epoch 8/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 484.6721 - mae: 484.6721 - val_loss: 475.5747 - val_mae: 475.5747\n",
            "Epoch 9/800\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 483.3216 - mae: 483.3216 - val_loss: 474.2628 - val_mae: 474.2628\n",
            "Epoch 10/800\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 482.4196 - mae: 482.4196 - val_loss: 475.0316 - val_mae: 475.0316\n",
            "Epoch 11/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 482.1886 - mae: 482.1886 - val_loss: 473.2964 - val_mae: 473.2964\n",
            "Epoch 12/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 480.4398 - mae: 480.4398 - val_loss: 472.5391 - val_mae: 472.5391\n",
            "Epoch 13/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 481.3025 - mae: 481.3025 - val_loss: 473.1808 - val_mae: 473.1808\n",
            "Epoch 14/800\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 479.9026 - mae: 479.9026 - val_loss: 472.9497 - val_mae: 472.9497\n",
            "Epoch 15/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 479.9643 - mae: 479.9643 - val_loss: 471.8773 - val_mae: 471.8773\n",
            "Epoch 16/800\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 479.2616 - mae: 479.2616 - val_loss: 471.2662 - val_mae: 471.2662\n",
            "Epoch 17/800\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 479.2665 - mae: 479.2665 - val_loss: 470.5886 - val_mae: 470.5886\n",
            "Epoch 18/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 478.3155 - mae: 478.3155 - val_loss: 470.0928 - val_mae: 470.0928\n",
            "Epoch 19/800\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 478.6831 - mae: 478.6831 - val_loss: 470.6909 - val_mae: 470.6909\n",
            "Epoch 20/800\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 477.8821 - mae: 477.8821 - val_loss: 470.5789 - val_mae: 470.5789\n",
            "Epoch 21/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 476.8560 - mae: 476.8560 - val_loss: 469.2379 - val_mae: 469.2379\n",
            "Epoch 22/800\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 478.0880 - mae: 478.0880 - val_loss: 470.5385 - val_mae: 470.5385\n",
            "Epoch 23/800\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 476.9426 - mae: 476.9426 - val_loss: 468.5874 - val_mae: 468.5874\n",
            "Epoch 24/800\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 477.5402 - mae: 477.5402 - val_loss: 470.0937 - val_mae: 470.0937\n",
            "Epoch 25/800\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 476.4768 - mae: 476.4768 - val_loss: 467.4252 - val_mae: 467.4252\n",
            "Epoch 26/800\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 475.0771 - mae: 475.0771 - val_loss: 468.2500 - val_mae: 468.2500\n",
            "Epoch 27/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 476.0318 - mae: 476.0318 - val_loss: 466.2048 - val_mae: 466.2048\n",
            "Epoch 28/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 475.9325 - mae: 475.9325 - val_loss: 467.5576 - val_mae: 467.5576\n",
            "Epoch 29/800\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 475.8716 - mae: 475.8716 - val_loss: 465.7408 - val_mae: 465.7408\n",
            "Epoch 30/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 474.7376 - mae: 474.7376 - val_loss: 466.4036 - val_mae: 466.4036\n",
            "Epoch 31/800\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 476.3650 - mae: 476.3650 - val_loss: 465.5750 - val_mae: 465.5750\n",
            "Epoch 32/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 474.8872 - mae: 474.8872 - val_loss: 465.9324 - val_mae: 465.9324\n",
            "Epoch 33/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 473.6867 - mae: 473.6867 - val_loss: 465.9914 - val_mae: 465.9914\n",
            "Epoch 34/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 475.6291 - mae: 475.6291 - val_loss: 466.9112 - val_mae: 466.9112\n",
            "Epoch 35/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 474.0200 - mae: 474.0200 - val_loss: 465.0274 - val_mae: 465.0274\n",
            "Epoch 36/800\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 473.7342 - mae: 473.7342 - val_loss: 466.2494 - val_mae: 466.2494\n",
            "Epoch 37/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 473.9313 - mae: 473.9313 - val_loss: 465.7833 - val_mae: 465.7833\n",
            "Epoch 38/800\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 473.0260 - mae: 473.0260 - val_loss: 465.8734 - val_mae: 465.8734\n",
            "Epoch 39/800\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 472.7738 - mae: 472.7738 - val_loss: 464.0392 - val_mae: 464.0392\n",
            "Epoch 40/800\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 472.7135 - mae: 472.7135 - val_loss: 464.6968 - val_mae: 464.6968\n",
            "Epoch 41/800\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 471.8396 - mae: 471.8396 - val_loss: 465.1747 - val_mae: 465.1747\n",
            "Epoch 42/800\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 472.3240 - mae: 472.3240 - val_loss: 465.7812 - val_mae: 465.7812\n",
            "Epoch 43/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 472.9057 - mae: 472.9057 - val_loss: 464.9970 - val_mae: 464.9970\n",
            "Epoch 44/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 473.8866 - mae: 473.8866 - val_loss: 465.0485 - val_mae: 465.0485\n",
            "Epoch 45/800\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 474.6381 - mae: 474.6381 - val_loss: 464.9823 - val_mae: 464.9823\n",
            "Epoch 46/800\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 474.5381 - mae: 474.5381 - val_loss: 465.4879 - val_mae: 465.4879\n",
            "Epoch 47/800\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 471.0856 - mae: 471.0856 - val_loss: 467.0598 - val_mae: 467.0598\n",
            "Epoch 48/800\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 473.9174 - mae: 473.9174 - val_loss: 465.3159 - val_mae: 465.3159\n",
            "Epoch 49/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 472.6014 - mae: 472.6014 - val_loss: 466.2760 - val_mae: 466.2760\n",
            "Epoch 50/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 473.5245 - mae: 473.5245 - val_loss: 466.0766 - val_mae: 466.0766\n",
            "Epoch 51/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 473.3637 - mae: 473.3637 - val_loss: 465.6595 - val_mae: 465.6595\n",
            "Epoch 52/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 473.3830 - mae: 473.3830 - val_loss: 465.5554 - val_mae: 465.5554\n",
            "Epoch 53/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 470.4637 - mae: 470.4637 - val_loss: 464.4125 - val_mae: 464.4125\n",
            "Epoch 54/800\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 473.2974 - mae: 473.2974 - val_loss: 465.2318 - val_mae: 465.2318\n",
            "Epoch 55/800\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 472.3135 - mae: 472.3135 - val_loss: 464.6391 - val_mae: 464.6391\n",
            "Epoch 56/800\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 471.7250 - mae: 471.7250 - val_loss: 464.9780 - val_mae: 464.9780\n",
            "Epoch 57/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 471.9207 - mae: 471.9207 - val_loss: 465.2884 - val_mae: 465.2884\n",
            "Epoch 58/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 472.6317 - mae: 472.6317 - val_loss: 464.7299 - val_mae: 464.7299\n",
            "Epoch 59/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 471.1118 - mae: 471.1118 - val_loss: 465.4229 - val_mae: 465.4229\n",
            "Epoch 60/800\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 471.5767 - mae: 471.5767 - val_loss: 464.0515 - val_mae: 464.0515\n",
            "Epoch 61/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 471.7911 - mae: 471.7911 - val_loss: 464.5809 - val_mae: 464.5809\n",
            "Epoch 62/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 471.3673 - mae: 471.3673 - val_loss: 465.2092 - val_mae: 465.2092\n",
            "Epoch 63/800\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 471.9815 - mae: 471.9815 - val_loss: 465.9662 - val_mae: 465.9662\n",
            "Epoch 64/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 470.0009 - mae: 470.0009 - val_loss: 464.3289 - val_mae: 464.3289\n",
            "Epoch 65/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 473.5107 - mae: 473.5107 - val_loss: 465.1862 - val_mae: 465.1862\n",
            "Epoch 66/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 470.6456 - mae: 470.6456 - val_loss: 464.8037 - val_mae: 464.8037\n",
            "Epoch 67/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 471.2788 - mae: 471.2788 - val_loss: 464.5994 - val_mae: 464.5994\n",
            "Epoch 68/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 471.6926 - mae: 471.6926 - val_loss: 465.6623 - val_mae: 465.6623\n",
            "Epoch 69/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 471.7981 - mae: 471.7981 - val_loss: 466.1171 - val_mae: 466.1171\n",
            "Epoch 70/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 471.0724 - mae: 471.0724 - val_loss: 466.0210 - val_mae: 466.0210\n",
            "Epoch 71/800\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 473.6190 - mae: 473.6190 - val_loss: 466.2609 - val_mae: 466.2609\n",
            "Epoch 72/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 472.5007 - mae: 472.5007 - val_loss: 466.9493 - val_mae: 466.9493\n",
            "Epoch 73/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 472.2747 - mae: 472.2747 - val_loss: 465.9370 - val_mae: 465.9370\n",
            "Epoch 74/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 471.0602 - mae: 471.0602 - val_loss: 464.9320 - val_mae: 464.9320\n",
            "Epoch 75/800\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 471.3921 - mae: 471.3921 - val_loss: 465.1809 - val_mae: 465.1809\n",
            "Epoch 76/800\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 471.4440 - mae: 471.4440 - val_loss: 465.9969 - val_mae: 465.9969\n",
            "Epoch 77/800\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 470.3404 - mae: 470.3404 - val_loss: 465.3690 - val_mae: 465.3690\n",
            "Epoch 78/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 471.9087 - mae: 471.9087 - val_loss: 463.8839 - val_mae: 463.8839\n",
            "Epoch 79/800\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 471.3524 - mae: 471.3524 - val_loss: 465.6176 - val_mae: 465.6176\n",
            "Epoch 80/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 471.3488 - mae: 471.3488 - val_loss: 465.0816 - val_mae: 465.0816\n",
            "Epoch 81/800\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 470.2723 - mae: 470.2723 - val_loss: 465.2783 - val_mae: 465.2783\n",
            "Epoch 82/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 470.2603 - mae: 470.2603 - val_loss: 464.8073 - val_mae: 464.8073\n",
            "Epoch 83/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 473.0713 - mae: 473.0713 - val_loss: 465.7461 - val_mae: 465.7461\n",
            "Epoch 84/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 470.6433 - mae: 470.6433 - val_loss: 465.0574 - val_mae: 465.0574\n",
            "Epoch 85/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 471.0677 - mae: 471.0677 - val_loss: 465.7601 - val_mae: 465.7601\n",
            "Epoch 86/800\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 469.6366 - mae: 469.6366 - val_loss: 465.7261 - val_mae: 465.7261\n",
            "Epoch 87/800\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 470.5345 - mae: 470.5345 - val_loss: 466.0475 - val_mae: 466.0475\n",
            "Epoch 88/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 470.5634 - mae: 470.5634 - val_loss: 466.3922 - val_mae: 466.3922\n",
            "Epoch 89/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 470.9279 - mae: 470.9279 - val_loss: 465.2216 - val_mae: 465.2216\n",
            "Epoch 90/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 470.1554 - mae: 470.1554 - val_loss: 465.2299 - val_mae: 465.2299\n",
            "Epoch 91/800\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 472.0284 - mae: 472.0284 - val_loss: 466.0875 - val_mae: 466.0875\n",
            "Epoch 92/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 471.7567 - mae: 471.7567 - val_loss: 465.8481 - val_mae: 465.8481\n",
            "Epoch 93/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 470.2380 - mae: 470.2380 - val_loss: 464.9140 - val_mae: 464.9140\n",
            "Epoch 94/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 471.4779 - mae: 471.4779 - val_loss: 466.4133 - val_mae: 466.4133\n",
            "Epoch 95/800\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 469.2269 - mae: 469.2269 - val_loss: 465.2751 - val_mae: 465.2751\n",
            "Epoch 96/800\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 470.6692 - mae: 470.6692 - val_loss: 466.3348 - val_mae: 466.3348\n",
            "Epoch 97/800\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 470.0127 - mae: 470.0127 - val_loss: 465.6053 - val_mae: 465.6053\n",
            "Epoch 98/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 470.9179 - mae: 470.9179 - val_loss: 465.9032 - val_mae: 465.9032\n",
            "Epoch 99/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 469.4817 - mae: 469.4817 - val_loss: 465.6370 - val_mae: 465.6370\n",
            "Epoch 100/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 471.2082 - mae: 471.2082 - val_loss: 466.4865 - val_mae: 466.4865\n",
            "Epoch 101/800\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 470.5466 - mae: 470.5466 - val_loss: 466.6422 - val_mae: 466.6422\n",
            "Epoch 102/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 469.7781 - mae: 469.7781 - val_loss: 465.9879 - val_mae: 465.9879\n",
            "Epoch 103/800\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 470.1896 - mae: 470.1896 - val_loss: 465.6216 - val_mae: 465.6216\n",
            "Epoch 104/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 471.7134 - mae: 471.7134 - val_loss: 464.9577 - val_mae: 464.9577\n",
            "Epoch 105/800\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 470.5896 - mae: 470.5896 - val_loss: 465.8853 - val_mae: 465.8853\n",
            "Epoch 106/800\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 470.4375 - mae: 470.4375 - val_loss: 466.0552 - val_mae: 466.0552\n",
            "Epoch 107/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 470.3090 - mae: 470.3090 - val_loss: 465.5863 - val_mae: 465.5863\n",
            "Epoch 108/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 470.2459 - mae: 470.2459 - val_loss: 463.9725 - val_mae: 463.9725\n",
            "Epoch 109/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 468.9859 - mae: 468.9859 - val_loss: 465.1170 - val_mae: 465.1170\n",
            "Epoch 110/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 469.0243 - mae: 469.0243 - val_loss: 466.3925 - val_mae: 466.3925\n",
            "Epoch 111/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 468.4820 - mae: 468.4820 - val_loss: 465.1922 - val_mae: 465.1922\n",
            "Epoch 112/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 467.9217 - mae: 467.9217 - val_loss: 464.4183 - val_mae: 464.4183\n",
            "Epoch 113/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 470.5090 - mae: 470.5090 - val_loss: 466.8908 - val_mae: 466.8908\n",
            "Epoch 114/800\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 469.2365 - mae: 469.2365 - val_loss: 465.2111 - val_mae: 465.2111\n",
            "Epoch 115/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 468.9077 - mae: 468.9077 - val_loss: 464.5750 - val_mae: 464.5750\n",
            "Epoch 116/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 470.8319 - mae: 470.8319 - val_loss: 464.5581 - val_mae: 464.5581\n",
            "Epoch 117/800\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 470.5972 - mae: 470.5972 - val_loss: 464.8484 - val_mae: 464.8484\n",
            "Epoch 118/800\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 469.5720 - mae: 469.5720 - val_loss: 465.7927 - val_mae: 465.7927\n",
            "Epoch 119/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 469.8862 - mae: 469.8862 - val_loss: 466.9235 - val_mae: 466.9235\n",
            "Epoch 120/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 470.4673 - mae: 470.4673 - val_loss: 465.8962 - val_mae: 465.8962\n",
            "Epoch 121/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 470.6946 - mae: 470.6946 - val_loss: 465.5622 - val_mae: 465.5622\n",
            "Epoch 122/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 470.0315 - mae: 470.0315 - val_loss: 465.9052 - val_mae: 465.9052\n",
            "Epoch 123/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 468.1107 - mae: 468.1107 - val_loss: 466.1265 - val_mae: 466.1265\n",
            "Epoch 124/800\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 470.2724 - mae: 470.2724 - val_loss: 465.9975 - val_mae: 465.9975\n",
            "Epoch 125/800\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 468.5847 - mae: 468.5847 - val_loss: 465.4629 - val_mae: 465.4629\n",
            "Epoch 126/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 469.2234 - mae: 469.2234 - val_loss: 464.7669 - val_mae: 464.7669\n",
            "Epoch 127/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 469.1248 - mae: 469.1248 - val_loss: 466.1444 - val_mae: 466.1444\n",
            "Epoch 128/800\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 468.3683 - mae: 468.3683 - val_loss: 465.1276 - val_mae: 465.1276\n",
            "Epoch 129/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 469.3876 - mae: 469.3876 - val_loss: 464.7429 - val_mae: 464.7429\n",
            "Epoch 130/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 468.8212 - mae: 468.8212 - val_loss: 464.6279 - val_mae: 464.6279\n",
            "Epoch 131/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 470.3833 - mae: 470.3833 - val_loss: 465.6039 - val_mae: 465.6039\n",
            "Epoch 132/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 468.2069 - mae: 468.2069 - val_loss: 465.4827 - val_mae: 465.4827\n",
            "Epoch 133/800\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 471.0574 - mae: 471.0574 - val_loss: 465.2703 - val_mae: 465.2703\n",
            "Epoch 134/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 467.5804 - mae: 467.5804 - val_loss: 463.8981 - val_mae: 463.8981\n",
            "Epoch 135/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 470.0431 - mae: 470.0431 - val_loss: 466.0704 - val_mae: 466.0704\n",
            "Epoch 136/800\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 469.9744 - mae: 469.9744 - val_loss: 465.2583 - val_mae: 465.2583\n",
            "Epoch 137/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 470.0353 - mae: 470.0353 - val_loss: 466.8840 - val_mae: 466.8840\n",
            "Epoch 138/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 467.8368 - mae: 467.8368 - val_loss: 466.1358 - val_mae: 466.1358\n",
            "Epoch 139/800\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 468.6375 - mae: 468.6375 - val_loss: 465.2489 - val_mae: 465.2489\n",
            "Epoch 140/800\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 468.1655 - mae: 468.1655 - val_loss: 466.1827 - val_mae: 466.1827\n",
            "Epoch 141/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 469.9707 - mae: 469.9707 - val_loss: 466.8683 - val_mae: 466.8683\n",
            "Epoch 142/800\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 468.4785 - mae: 468.4785 - val_loss: 465.7593 - val_mae: 465.7593\n",
            "Epoch 143/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 467.1179 - mae: 467.1179 - val_loss: 465.9916 - val_mae: 465.9916\n",
            "Epoch 144/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 468.2268 - mae: 468.2268 - val_loss: 465.6570 - val_mae: 465.6570\n",
            "Epoch 145/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 468.4113 - mae: 468.4113 - val_loss: 465.4520 - val_mae: 465.4520\n",
            "Epoch 146/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 468.2867 - mae: 468.2867 - val_loss: 466.1936 - val_mae: 466.1936\n",
            "Epoch 147/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 468.9463 - mae: 468.9463 - val_loss: 466.6346 - val_mae: 466.6346\n",
            "Epoch 148/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 468.8545 - mae: 468.8545 - val_loss: 466.1102 - val_mae: 466.1102\n",
            "Epoch 149/800\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 469.1221 - mae: 469.1221 - val_loss: 466.6623 - val_mae: 466.6623\n",
            "Epoch 150/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 468.2153 - mae: 468.2153 - val_loss: 466.3111 - val_mae: 466.3111\n",
            "Epoch 151/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 467.7463 - mae: 467.7463 - val_loss: 465.4673 - val_mae: 465.4673\n",
            "Epoch 152/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 469.4982 - mae: 469.4982 - val_loss: 466.7805 - val_mae: 466.7805\n",
            "Epoch 153/800\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 468.8264 - mae: 468.8264 - val_loss: 465.3351 - val_mae: 465.3351\n",
            "Epoch 154/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 467.8276 - mae: 467.8276 - val_loss: 466.1415 - val_mae: 466.1415\n",
            "Epoch 155/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 469.3389 - mae: 469.3389 - val_loss: 465.3730 - val_mae: 465.3730\n",
            "Epoch 156/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 467.9786 - mae: 467.9786 - val_loss: 465.6664 - val_mae: 465.6664\n",
            "Epoch 157/800\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 468.7647 - mae: 468.7647 - val_loss: 466.4560 - val_mae: 466.4560\n",
            "Epoch 158/800\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 469.4668 - mae: 469.4668 - val_loss: 466.7439 - val_mae: 466.7439\n",
            "Epoch 159/800\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 467.4352 - mae: 467.4352 - val_loss: 465.7415 - val_mae: 465.7415\n",
            "Epoch 160/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 469.1815 - mae: 469.1815 - val_loss: 465.1718 - val_mae: 465.1718\n",
            "Epoch 161/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 467.5982 - mae: 467.5982 - val_loss: 464.8489 - val_mae: 464.8489\n",
            "Epoch 162/800\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 468.9681 - mae: 468.9681 - val_loss: 466.1891 - val_mae: 466.1891\n",
            "Epoch 163/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 468.4172 - mae: 468.4172 - val_loss: 467.0197 - val_mae: 467.0197\n",
            "Epoch 164/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 469.2036 - mae: 469.2036 - val_loss: 466.9676 - val_mae: 466.9676\n",
            "Epoch 165/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 468.5021 - mae: 468.5021 - val_loss: 466.2146 - val_mae: 466.2146\n",
            "Epoch 166/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 468.2726 - mae: 468.2726 - val_loss: 467.0271 - val_mae: 467.0271\n",
            "Epoch 167/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 468.2072 - mae: 468.2072 - val_loss: 466.6959 - val_mae: 466.6959\n",
            "Epoch 168/800\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 467.5786 - mae: 467.5786 - val_loss: 466.5735 - val_mae: 466.5735\n",
            "Epoch 169/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 468.5430 - mae: 468.5430 - val_loss: 467.0005 - val_mae: 467.0005\n",
            "Epoch 170/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 468.0764 - mae: 468.0764 - val_loss: 467.1299 - val_mae: 467.1299\n",
            "Epoch 171/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 467.1494 - mae: 467.1494 - val_loss: 466.6664 - val_mae: 466.6664\n",
            "Epoch 172/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 468.0313 - mae: 468.0313 - val_loss: 467.4318 - val_mae: 467.4318\n",
            "Epoch 173/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 467.4072 - mae: 467.4072 - val_loss: 466.8895 - val_mae: 466.8895\n",
            "Epoch 174/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 467.9174 - mae: 467.9174 - val_loss: 466.8010 - val_mae: 466.8010\n",
            "Epoch 175/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 469.7009 - mae: 469.7009 - val_loss: 467.2722 - val_mae: 467.2722\n",
            "Epoch 176/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 468.9788 - mae: 468.9788 - val_loss: 467.0208 - val_mae: 467.0208\n",
            "Epoch 177/800\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 469.5622 - mae: 469.5622 - val_loss: 466.8187 - val_mae: 466.8187\n",
            "Epoch 178/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 468.2482 - mae: 468.2482 - val_loss: 467.0886 - val_mae: 467.0886\n",
            "Epoch 179/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 467.2682 - mae: 467.2682 - val_loss: 467.7899 - val_mae: 467.7899\n",
            "Epoch 180/800\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 468.0780 - mae: 468.0780 - val_loss: 467.2292 - val_mae: 467.2292\n",
            "Epoch 181/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 467.7552 - mae: 467.7552 - val_loss: 466.8322 - val_mae: 466.8322\n",
            "Epoch 182/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 468.2534 - mae: 468.2534 - val_loss: 466.5576 - val_mae: 466.5576\n",
            "Epoch 183/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 465.6920 - mae: 465.6920 - val_loss: 466.7499 - val_mae: 466.7499\n",
            "Epoch 184/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 467.6116 - mae: 467.6116 - val_loss: 466.4715 - val_mae: 466.4715\n",
            "Epoch 185/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 468.7998 - mae: 468.7998 - val_loss: 467.1107 - val_mae: 467.1107\n",
            "Epoch 186/800\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 466.5726 - mae: 466.5726 - val_loss: 466.7672 - val_mae: 466.7672\n",
            "Epoch 187/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 466.1660 - mae: 466.1660 - val_loss: 466.0244 - val_mae: 466.0244\n",
            "Epoch 188/800\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 467.2228 - mae: 467.2228 - val_loss: 466.4449 - val_mae: 466.4449\n",
            "Epoch 189/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 467.5766 - mae: 467.5766 - val_loss: 467.1008 - val_mae: 467.1008\n",
            "Epoch 190/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 468.6460 - mae: 468.6460 - val_loss: 467.0896 - val_mae: 467.0896\n",
            "Epoch 191/800\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 467.4654 - mae: 467.4654 - val_loss: 466.4856 - val_mae: 466.4856\n",
            "Epoch 192/800\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 467.3033 - mae: 467.3033 - val_loss: 467.3700 - val_mae: 467.3700\n",
            "Epoch 193/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 467.7410 - mae: 467.7410 - val_loss: 467.0969 - val_mae: 467.0969\n",
            "Epoch 194/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 468.0104 - mae: 468.0104 - val_loss: 467.0668 - val_mae: 467.0668\n",
            "Epoch 195/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 467.0580 - mae: 467.0580 - val_loss: 467.2337 - val_mae: 467.2337\n",
            "Epoch 196/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 467.6487 - mae: 467.6487 - val_loss: 467.2571 - val_mae: 467.2571\n",
            "Epoch 197/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 468.4753 - mae: 468.4753 - val_loss: 467.7182 - val_mae: 467.7182\n",
            "Epoch 198/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 465.7877 - mae: 465.7877 - val_loss: 467.9153 - val_mae: 467.9153\n",
            "Epoch 199/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 467.9739 - mae: 467.9739 - val_loss: 467.6082 - val_mae: 467.6082\n",
            "Epoch 200/800\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 467.4371 - mae: 467.4371 - val_loss: 466.6366 - val_mae: 466.6366\n",
            "Epoch 201/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 468.4077 - mae: 468.4077 - val_loss: 468.6222 - val_mae: 468.6222\n",
            "Epoch 202/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 465.5932 - mae: 465.5932 - val_loss: 467.2759 - val_mae: 467.2759\n",
            "Epoch 203/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 467.9459 - mae: 467.9459 - val_loss: 467.3847 - val_mae: 467.3847\n",
            "Epoch 204/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 465.4666 - mae: 465.4666 - val_loss: 466.6355 - val_mae: 466.6355\n",
            "Epoch 205/800\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 468.2523 - mae: 468.2523 - val_loss: 467.3640 - val_mae: 467.3640\n",
            "Epoch 206/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 466.7324 - mae: 466.7324 - val_loss: 466.3174 - val_mae: 466.3174\n",
            "Epoch 207/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 466.7213 - mae: 466.7213 - val_loss: 467.7248 - val_mae: 467.7248\n",
            "Epoch 208/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 467.4854 - mae: 467.4854 - val_loss: 467.6461 - val_mae: 467.6461\n",
            "Epoch 209/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 466.8901 - mae: 466.8901 - val_loss: 467.1180 - val_mae: 467.1180\n",
            "Epoch 210/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 468.5845 - mae: 468.5845 - val_loss: 467.4831 - val_mae: 467.4831\n",
            "Epoch 211/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 467.3299 - mae: 467.3299 - val_loss: 467.0129 - val_mae: 467.0129\n",
            "Epoch 212/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 465.3558 - mae: 465.3558 - val_loss: 467.0109 - val_mae: 467.0109\n",
            "Epoch 213/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 466.5328 - mae: 466.5328 - val_loss: 467.0698 - val_mae: 467.0698\n",
            "Epoch 214/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 464.8191 - mae: 464.8191 - val_loss: 466.6846 - val_mae: 466.6846\n",
            "Epoch 215/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 467.1259 - mae: 467.1259 - val_loss: 467.3672 - val_mae: 467.3672\n",
            "Epoch 216/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 465.0261 - mae: 465.0261 - val_loss: 465.6223 - val_mae: 465.6223\n",
            "Epoch 217/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 465.6473 - mae: 465.6473 - val_loss: 466.0807 - val_mae: 466.0807\n",
            "Epoch 218/800\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 467.8751 - mae: 467.8751 - val_loss: 468.0596 - val_mae: 468.0596\n",
            "Epoch 219/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 465.7990 - mae: 465.7990 - val_loss: 468.7874 - val_mae: 468.7874\n",
            "Epoch 220/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 467.3969 - mae: 467.3969 - val_loss: 468.4940 - val_mae: 468.4940\n",
            "Epoch 221/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 468.5850 - mae: 468.5850 - val_loss: 468.1610 - val_mae: 468.1610\n",
            "Epoch 222/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 468.3533 - mae: 468.3533 - val_loss: 468.0908 - val_mae: 468.0908\n",
            "Epoch 223/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 465.2881 - mae: 465.2881 - val_loss: 467.8537 - val_mae: 467.8537\n",
            "Epoch 224/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 464.6155 - mae: 464.6155 - val_loss: 468.4830 - val_mae: 468.4830\n",
            "Epoch 225/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 466.3298 - mae: 466.3298 - val_loss: 469.3674 - val_mae: 469.3674\n",
            "Epoch 226/800\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 467.2670 - mae: 467.2670 - val_loss: 468.5244 - val_mae: 468.5244\n",
            "Epoch 227/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 466.5887 - mae: 466.5887 - val_loss: 466.4078 - val_mae: 466.4078\n",
            "Epoch 228/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 467.1609 - mae: 467.1609 - val_loss: 468.5940 - val_mae: 468.5940\n",
            "Epoch 229/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 467.1944 - mae: 467.1944 - val_loss: 468.2488 - val_mae: 468.2488\n",
            "Epoch 230/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 465.3901 - mae: 465.3901 - val_loss: 468.1371 - val_mae: 468.1371\n",
            "Epoch 231/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 466.6680 - mae: 466.6680 - val_loss: 468.4321 - val_mae: 468.4321\n",
            "Epoch 232/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 466.5433 - mae: 466.5433 - val_loss: 468.2618 - val_mae: 468.2618\n",
            "Epoch 233/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 466.0750 - mae: 466.0750 - val_loss: 468.5137 - val_mae: 468.5137\n",
            "Epoch 234/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 466.1478 - mae: 466.1478 - val_loss: 468.5380 - val_mae: 468.5380\n",
            "Epoch 235/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 467.1582 - mae: 467.1582 - val_loss: 468.5542 - val_mae: 468.5542\n",
            "Epoch 236/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 467.0856 - mae: 467.0856 - val_loss: 468.2819 - val_mae: 468.2819\n",
            "Epoch 237/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 465.2042 - mae: 465.2042 - val_loss: 468.0758 - val_mae: 468.0758\n",
            "Epoch 238/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 466.5463 - mae: 466.5463 - val_loss: 468.0437 - val_mae: 468.0437\n",
            "Epoch 239/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 464.6111 - mae: 464.6111 - val_loss: 467.4269 - val_mae: 467.4269\n",
            "Epoch 240/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 466.2744 - mae: 466.2744 - val_loss: 467.1669 - val_mae: 467.1669\n",
            "Epoch 241/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 464.6278 - mae: 464.6278 - val_loss: 466.5703 - val_mae: 466.5703\n",
            "Epoch 242/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 466.1429 - mae: 466.1429 - val_loss: 468.4343 - val_mae: 468.4343\n",
            "Epoch 243/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 466.9809 - mae: 466.9809 - val_loss: 467.2232 - val_mae: 467.2232\n",
            "Epoch 244/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 466.9231 - mae: 466.9231 - val_loss: 467.6838 - val_mae: 467.6838\n",
            "Epoch 245/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 465.2343 - mae: 465.2343 - val_loss: 468.7608 - val_mae: 468.7608\n",
            "Epoch 246/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 466.7957 - mae: 466.7957 - val_loss: 468.6053 - val_mae: 468.6053\n",
            "Epoch 247/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 466.2018 - mae: 466.2018 - val_loss: 466.9058 - val_mae: 466.9058\n",
            "Epoch 248/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 463.8286 - mae: 463.8286 - val_loss: 465.8483 - val_mae: 465.8483\n",
            "Epoch 249/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 465.8439 - mae: 465.8439 - val_loss: 467.5118 - val_mae: 467.5118\n",
            "Epoch 250/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 465.2194 - mae: 465.2194 - val_loss: 467.0595 - val_mae: 467.0595\n",
            "Epoch 251/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 464.2034 - mae: 464.2034 - val_loss: 468.1099 - val_mae: 468.1099\n",
            "Epoch 252/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 464.8214 - mae: 464.8214 - val_loss: 468.0120 - val_mae: 468.0120\n",
            "Epoch 253/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 467.5955 - mae: 467.5955 - val_loss: 468.2324 - val_mae: 468.2324\n",
            "Epoch 254/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 466.5049 - mae: 466.5049 - val_loss: 467.5678 - val_mae: 467.5678\n",
            "Epoch 255/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 466.9292 - mae: 466.9292 - val_loss: 469.0977 - val_mae: 469.0977\n",
            "Epoch 256/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 464.9531 - mae: 464.9531 - val_loss: 468.0435 - val_mae: 468.0435\n",
            "Epoch 257/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 466.1261 - mae: 466.1261 - val_loss: 468.7191 - val_mae: 468.7191\n",
            "Epoch 258/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 466.2322 - mae: 466.2322 - val_loss: 468.4042 - val_mae: 468.4042\n",
            "Epoch 259/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 464.1876 - mae: 464.1876 - val_loss: 468.7806 - val_mae: 468.7806\n",
            "Epoch 260/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 465.4203 - mae: 465.4203 - val_loss: 468.8103 - val_mae: 468.8103\n",
            "Epoch 261/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 463.8480 - mae: 463.8480 - val_loss: 467.9952 - val_mae: 467.9952\n",
            "Epoch 262/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 464.3224 - mae: 464.3224 - val_loss: 468.9077 - val_mae: 468.9077\n",
            "Epoch 263/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 466.2795 - mae: 466.2795 - val_loss: 468.6080 - val_mae: 468.6080\n",
            "Epoch 264/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 465.4173 - mae: 465.4173 - val_loss: 468.0974 - val_mae: 468.0974\n",
            "Epoch 265/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 465.3911 - mae: 465.3911 - val_loss: 468.3102 - val_mae: 468.3102\n",
            "Epoch 266/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 466.5821 - mae: 466.5821 - val_loss: 467.6807 - val_mae: 467.6807\n",
            "Epoch 267/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 463.5009 - mae: 463.5009 - val_loss: 468.4265 - val_mae: 468.4265\n",
            "Epoch 268/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 462.9982 - mae: 462.9982 - val_loss: 467.7120 - val_mae: 467.7120\n",
            "Epoch 269/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 464.7682 - mae: 464.7682 - val_loss: 468.6506 - val_mae: 468.6506\n",
            "Epoch 270/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 464.4626 - mae: 464.4626 - val_loss: 468.6935 - val_mae: 468.6935\n",
            "Epoch 271/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 465.2314 - mae: 465.2314 - val_loss: 467.9905 - val_mae: 467.9905\n",
            "Epoch 272/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 464.5001 - mae: 464.5001 - val_loss: 468.1482 - val_mae: 468.1482\n",
            "Epoch 273/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 465.4142 - mae: 465.4142 - val_loss: 467.5515 - val_mae: 467.5515\n",
            "Epoch 274/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 463.9488 - mae: 463.9488 - val_loss: 467.9781 - val_mae: 467.9781\n",
            "Epoch 275/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 465.1410 - mae: 465.1410 - val_loss: 467.9076 - val_mae: 467.9076\n",
            "Epoch 276/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 463.6972 - mae: 463.6972 - val_loss: 466.9669 - val_mae: 466.9669\n",
            "Epoch 277/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 466.0780 - mae: 466.0780 - val_loss: 467.4018 - val_mae: 467.4018\n",
            "Epoch 278/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 464.8117 - mae: 464.8117 - val_loss: 467.6510 - val_mae: 467.6510\n",
            "Epoch 279/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 465.1853 - mae: 465.1853 - val_loss: 468.0222 - val_mae: 468.0222\n",
            "Epoch 280/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 463.8254 - mae: 463.8254 - val_loss: 467.4991 - val_mae: 467.4991\n",
            "Epoch 281/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 464.2365 - mae: 464.2365 - val_loss: 467.9458 - val_mae: 467.9458\n",
            "Epoch 282/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 464.6932 - mae: 464.6932 - val_loss: 468.2173 - val_mae: 468.2173\n",
            "Epoch 283/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 463.8859 - mae: 463.8859 - val_loss: 468.3766 - val_mae: 468.3766\n",
            "Epoch 284/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 465.3151 - mae: 465.3151 - val_loss: 467.7209 - val_mae: 467.7209\n",
            "Epoch 285/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 463.7347 - mae: 463.7347 - val_loss: 466.8772 - val_mae: 466.8772\n",
            "Epoch 286/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 464.1310 - mae: 464.1310 - val_loss: 467.7967 - val_mae: 467.7967\n",
            "Epoch 287/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 464.4581 - mae: 464.4581 - val_loss: 466.2021 - val_mae: 466.2021\n",
            "Epoch 288/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 464.9055 - mae: 464.9055 - val_loss: 466.7697 - val_mae: 466.7697\n",
            "Epoch 289/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 465.1170 - mae: 465.1170 - val_loss: 466.8387 - val_mae: 466.8387\n",
            "Epoch 290/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 464.3409 - mae: 464.3409 - val_loss: 467.5268 - val_mae: 467.5268\n",
            "Epoch 291/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 464.6285 - mae: 464.6285 - val_loss: 467.8177 - val_mae: 467.8177\n",
            "Epoch 292/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 462.4412 - mae: 462.4412 - val_loss: 467.6963 - val_mae: 467.6963\n",
            "Epoch 293/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 462.6148 - mae: 462.6148 - val_loss: 467.0305 - val_mae: 467.0305\n",
            "Epoch 294/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 463.7610 - mae: 463.7610 - val_loss: 467.3057 - val_mae: 467.3057\n",
            "Epoch 295/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 463.9913 - mae: 463.9913 - val_loss: 467.6142 - val_mae: 467.6142\n",
            "Epoch 296/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 464.3798 - mae: 464.3798 - val_loss: 466.4058 - val_mae: 466.4058\n",
            "Epoch 297/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 462.8116 - mae: 462.8116 - val_loss: 466.4470 - val_mae: 466.4470\n",
            "Epoch 298/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 465.4095 - mae: 465.4095 - val_loss: 468.3841 - val_mae: 468.3841\n",
            "Epoch 299/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 465.1080 - mae: 465.1080 - val_loss: 468.2256 - val_mae: 468.2256\n",
            "Epoch 300/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 464.7792 - mae: 464.7792 - val_loss: 467.4609 - val_mae: 467.4609\n",
            "Epoch 301/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 464.0171 - mae: 464.0171 - val_loss: 467.0635 - val_mae: 467.0635\n",
            "Epoch 302/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 463.6850 - mae: 463.6850 - val_loss: 467.6867 - val_mae: 467.6867\n",
            "Epoch 303/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 467.9612 - mae: 467.9612 - val_loss: 467.8703 - val_mae: 467.8703\n",
            "Epoch 304/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 464.1419 - mae: 464.1419 - val_loss: 466.8142 - val_mae: 466.8142\n",
            "Epoch 305/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 466.2942 - mae: 466.2942 - val_loss: 466.6566 - val_mae: 466.6566\n",
            "Epoch 306/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 463.5910 - mae: 463.5910 - val_loss: 466.5128 - val_mae: 466.5128\n",
            "Epoch 307/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 462.4514 - mae: 462.4514 - val_loss: 467.3697 - val_mae: 467.3697\n",
            "Epoch 308/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 463.0556 - mae: 463.0556 - val_loss: 467.1109 - val_mae: 467.1109\n",
            "Epoch 309/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 463.9414 - mae: 463.9414 - val_loss: 467.7637 - val_mae: 467.7637\n",
            "Epoch 310/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 464.3538 - mae: 464.3538 - val_loss: 467.8012 - val_mae: 467.8012\n",
            "Epoch 311/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 463.4946 - mae: 463.4946 - val_loss: 467.6350 - val_mae: 467.6350\n",
            "Epoch 312/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 463.4730 - mae: 463.4730 - val_loss: 467.4485 - val_mae: 467.4485\n",
            "Epoch 313/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 463.7757 - mae: 463.7757 - val_loss: 468.6447 - val_mae: 468.6447\n",
            "Epoch 314/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 462.0713 - mae: 462.0713 - val_loss: 468.2258 - val_mae: 468.2258\n",
            "Epoch 315/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 465.1793 - mae: 465.1793 - val_loss: 467.3164 - val_mae: 467.3164\n",
            "Epoch 316/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 462.2161 - mae: 462.2161 - val_loss: 467.8923 - val_mae: 467.8923\n",
            "Epoch 317/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 462.9291 - mae: 462.9291 - val_loss: 466.9579 - val_mae: 466.9579\n",
            "Epoch 318/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 465.0577 - mae: 465.0577 - val_loss: 467.0587 - val_mae: 467.0587\n",
            "Epoch 319/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 462.5378 - mae: 462.5378 - val_loss: 467.8374 - val_mae: 467.8374\n",
            "Epoch 320/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 462.4753 - mae: 462.4753 - val_loss: 467.1582 - val_mae: 467.1582\n",
            "Epoch 321/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 465.4461 - mae: 465.4461 - val_loss: 466.9934 - val_mae: 466.9934\n",
            "Epoch 322/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 463.4780 - mae: 463.4780 - val_loss: 467.3421 - val_mae: 467.3421\n",
            "Epoch 323/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 464.0563 - mae: 464.0563 - val_loss: 466.6429 - val_mae: 466.6429\n",
            "Epoch 324/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 464.1688 - mae: 464.1688 - val_loss: 467.6514 - val_mae: 467.6514\n",
            "Epoch 325/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 464.6095 - mae: 464.6095 - val_loss: 467.2911 - val_mae: 467.2911\n",
            "Epoch 326/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 464.7951 - mae: 464.7951 - val_loss: 467.4151 - val_mae: 467.4151\n",
            "Epoch 327/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 462.6246 - mae: 462.6246 - val_loss: 467.6057 - val_mae: 467.6057\n",
            "Epoch 328/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 463.7743 - mae: 463.7743 - val_loss: 467.9272 - val_mae: 467.9272\n",
            "Epoch 329/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 462.4033 - mae: 462.4033 - val_loss: 468.3633 - val_mae: 468.3633\n",
            "Epoch 330/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 465.8644 - mae: 465.8644 - val_loss: 468.5471 - val_mae: 468.5471\n",
            "Epoch 331/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 463.7402 - mae: 463.7402 - val_loss: 467.0019 - val_mae: 467.0019\n",
            "Epoch 332/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 464.5150 - mae: 464.5150 - val_loss: 466.9918 - val_mae: 466.9918\n",
            "Epoch 333/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 465.0268 - mae: 465.0268 - val_loss: 467.6504 - val_mae: 467.6504\n",
            "Epoch 334/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 463.2273 - mae: 463.2273 - val_loss: 467.4656 - val_mae: 467.4656\n",
            "Epoch 335/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 463.9932 - mae: 463.9932 - val_loss: 467.9582 - val_mae: 467.9582\n",
            "Epoch 336/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 462.8428 - mae: 462.8428 - val_loss: 467.4470 - val_mae: 467.4470\n",
            "Epoch 337/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 464.1119 - mae: 464.1119 - val_loss: 467.7859 - val_mae: 467.7859\n",
            "Epoch 338/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 463.9347 - mae: 463.9347 - val_loss: 467.9681 - val_mae: 467.9681\n",
            "Epoch 339/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 462.6098 - mae: 462.6098 - val_loss: 467.6731 - val_mae: 467.6731\n",
            "Epoch 340/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 463.4314 - mae: 463.4314 - val_loss: 467.6268 - val_mae: 467.6268\n",
            "Epoch 341/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 463.8997 - mae: 463.8997 - val_loss: 467.7279 - val_mae: 467.7279\n",
            "Epoch 342/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 464.4545 - mae: 464.4545 - val_loss: 467.3755 - val_mae: 467.3755\n",
            "Epoch 343/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 461.6730 - mae: 461.6730 - val_loss: 468.5202 - val_mae: 468.5202\n",
            "Epoch 344/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 463.2979 - mae: 463.2979 - val_loss: 467.6738 - val_mae: 467.6738\n",
            "Epoch 345/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 464.0947 - mae: 464.0947 - val_loss: 466.7788 - val_mae: 466.7788\n",
            "Epoch 346/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 463.8730 - mae: 463.8730 - val_loss: 467.7197 - val_mae: 467.7197\n",
            "Epoch 347/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 462.6037 - mae: 462.6037 - val_loss: 466.5222 - val_mae: 466.5222\n",
            "Epoch 348/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 464.6364 - mae: 464.6364 - val_loss: 466.2199 - val_mae: 466.2199\n",
            "Epoch 349/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 462.7746 - mae: 462.7746 - val_loss: 467.0359 - val_mae: 467.0359\n",
            "Epoch 350/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 462.6542 - mae: 462.6542 - val_loss: 466.7393 - val_mae: 466.7393\n",
            "Epoch 351/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 464.8953 - mae: 464.8953 - val_loss: 465.7764 - val_mae: 465.7764\n",
            "Epoch 352/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 463.8796 - mae: 463.8796 - val_loss: 466.3646 - val_mae: 466.3646\n",
            "Epoch 353/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 462.7520 - mae: 462.7520 - val_loss: 466.0479 - val_mae: 466.0479\n",
            "Epoch 354/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 464.4001 - mae: 464.4001 - val_loss: 467.1683 - val_mae: 467.1683\n",
            "Epoch 355/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 462.0041 - mae: 462.0041 - val_loss: 467.3541 - val_mae: 467.3541\n",
            "Epoch 356/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 463.3809 - mae: 463.3809 - val_loss: 467.4874 - val_mae: 467.4874\n",
            "Epoch 357/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 462.3577 - mae: 462.3577 - val_loss: 466.9695 - val_mae: 466.9695\n",
            "Epoch 358/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 462.8731 - mae: 462.8731 - val_loss: 466.6611 - val_mae: 466.6611\n",
            "Epoch 359/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 462.1397 - mae: 462.1397 - val_loss: 466.2358 - val_mae: 466.2358\n",
            "Epoch 360/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 462.4970 - mae: 462.4970 - val_loss: 466.7456 - val_mae: 466.7456\n",
            "Epoch 361/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 463.6718 - mae: 463.6718 - val_loss: 467.0458 - val_mae: 467.0458\n",
            "Epoch 362/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 466.3046 - mae: 466.3046 - val_loss: 467.7908 - val_mae: 467.7908\n",
            "Epoch 363/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 461.8666 - mae: 461.8666 - val_loss: 465.5355 - val_mae: 465.5355\n",
            "Epoch 364/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 463.4724 - mae: 463.4724 - val_loss: 466.1999 - val_mae: 466.1999\n",
            "Epoch 365/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 462.7212 - mae: 462.7212 - val_loss: 466.2102 - val_mae: 466.2102\n",
            "Epoch 366/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 463.0070 - mae: 463.0070 - val_loss: 466.1017 - val_mae: 466.1017\n",
            "Epoch 367/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 462.8943 - mae: 462.8943 - val_loss: 465.9269 - val_mae: 465.9269\n",
            "Epoch 368/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 463.6547 - mae: 463.6547 - val_loss: 465.7592 - val_mae: 465.7592\n",
            "Epoch 369/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 461.7145 - mae: 461.7145 - val_loss: 464.7779 - val_mae: 464.7779\n",
            "Epoch 370/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 463.8871 - mae: 463.8871 - val_loss: 466.1301 - val_mae: 466.1301\n",
            "Epoch 371/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 462.5766 - mae: 462.5766 - val_loss: 465.4188 - val_mae: 465.4188\n",
            "Epoch 372/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 463.2888 - mae: 463.2888 - val_loss: 465.9056 - val_mae: 465.9056\n",
            "Epoch 373/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 462.8287 - mae: 462.8287 - val_loss: 466.1399 - val_mae: 466.1399\n",
            "Epoch 374/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 464.0151 - mae: 464.0151 - val_loss: 466.8589 - val_mae: 466.8589\n",
            "Epoch 375/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 464.2434 - mae: 464.2434 - val_loss: 466.6266 - val_mae: 466.6266\n",
            "Epoch 376/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 461.8340 - mae: 461.8340 - val_loss: 467.3038 - val_mae: 467.3038\n",
            "Epoch 377/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 462.9150 - mae: 462.9150 - val_loss: 466.5768 - val_mae: 466.5768\n",
            "Epoch 378/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 460.7137 - mae: 460.7137 - val_loss: 466.0760 - val_mae: 466.0760\n",
            "Epoch 379/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 464.4019 - mae: 464.4019 - val_loss: 467.1317 - val_mae: 467.1317\n",
            "Epoch 380/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 461.6435 - mae: 461.6435 - val_loss: 467.3818 - val_mae: 467.3818\n",
            "Epoch 381/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 462.5555 - mae: 462.5555 - val_loss: 466.6927 - val_mae: 466.6927\n",
            "Epoch 382/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 461.8269 - mae: 461.8269 - val_loss: 466.5480 - val_mae: 466.5480\n",
            "Epoch 383/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 463.8000 - mae: 463.8000 - val_loss: 467.3276 - val_mae: 467.3276\n",
            "Epoch 384/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 463.7092 - mae: 463.7092 - val_loss: 465.8206 - val_mae: 465.8206\n",
            "Epoch 385/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 461.5942 - mae: 461.5942 - val_loss: 467.0979 - val_mae: 467.0979\n",
            "Epoch 386/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 460.6221 - mae: 460.6221 - val_loss: 468.5789 - val_mae: 468.5789\n",
            "Epoch 387/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 463.2742 - mae: 463.2742 - val_loss: 466.2702 - val_mae: 466.2702\n",
            "Epoch 388/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 462.4860 - mae: 462.4860 - val_loss: 466.4052 - val_mae: 466.4052\n",
            "Epoch 389/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 464.3718 - mae: 464.3718 - val_loss: 467.6456 - val_mae: 467.6456\n",
            "Epoch 390/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 462.4675 - mae: 462.4675 - val_loss: 467.1442 - val_mae: 467.1442\n",
            "Epoch 391/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 463.4744 - mae: 463.4744 - val_loss: 467.2524 - val_mae: 467.2524\n",
            "Epoch 392/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 463.7352 - mae: 463.7352 - val_loss: 466.9103 - val_mae: 466.9103\n",
            "Epoch 393/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 463.6703 - mae: 463.6703 - val_loss: 466.3319 - val_mae: 466.3319\n",
            "Epoch 394/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 463.2099 - mae: 463.2099 - val_loss: 466.5348 - val_mae: 466.5348\n",
            "Epoch 395/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 462.3682 - mae: 462.3682 - val_loss: 466.2332 - val_mae: 466.2332\n",
            "Epoch 396/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 462.7951 - mae: 462.7951 - val_loss: 466.1493 - val_mae: 466.1493\n",
            "Epoch 397/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 460.1656 - mae: 460.1656 - val_loss: 467.2498 - val_mae: 467.2498\n",
            "Epoch 398/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 462.9457 - mae: 462.9457 - val_loss: 466.8164 - val_mae: 466.8164\n",
            "Epoch 399/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 463.1564 - mae: 463.1564 - val_loss: 466.9274 - val_mae: 466.9274\n",
            "Epoch 400/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 460.6627 - mae: 460.6627 - val_loss: 466.6801 - val_mae: 466.6801\n",
            "Epoch 401/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 463.0237 - mae: 463.0237 - val_loss: 466.6202 - val_mae: 466.6202\n",
            "Epoch 402/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 461.4427 - mae: 461.4427 - val_loss: 466.6487 - val_mae: 466.6487\n",
            "Epoch 403/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 460.6732 - mae: 460.6732 - val_loss: 467.4385 - val_mae: 467.4385\n",
            "Epoch 404/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 462.3917 - mae: 462.3917 - val_loss: 466.8508 - val_mae: 466.8508\n",
            "Epoch 405/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 462.2916 - mae: 462.2916 - val_loss: 467.0050 - val_mae: 467.0050\n",
            "Epoch 406/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 464.2323 - mae: 464.2323 - val_loss: 467.8588 - val_mae: 467.8588\n",
            "Epoch 407/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 462.7795 - mae: 462.7795 - val_loss: 466.7363 - val_mae: 466.7363\n",
            "Epoch 408/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 460.4591 - mae: 460.4591 - val_loss: 467.4464 - val_mae: 467.4464\n",
            "Epoch 409/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 462.1667 - mae: 462.1667 - val_loss: 466.6830 - val_mae: 466.6830\n",
            "Epoch 410/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 463.5632 - mae: 463.5632 - val_loss: 467.5489 - val_mae: 467.5489\n",
            "Epoch 411/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 465.1554 - mae: 465.1554 - val_loss: 467.6678 - val_mae: 467.6678\n",
            "Epoch 412/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 462.1173 - mae: 462.1173 - val_loss: 466.7301 - val_mae: 466.7301\n",
            "Epoch 413/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 461.6499 - mae: 461.6499 - val_loss: 467.0057 - val_mae: 467.0057\n",
            "Epoch 414/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 460.2886 - mae: 460.2886 - val_loss: 466.7691 - val_mae: 466.7691\n",
            "Epoch 415/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 460.8838 - mae: 460.8838 - val_loss: 466.7480 - val_mae: 466.7480\n",
            "Epoch 416/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 464.2071 - mae: 464.2071 - val_loss: 467.0273 - val_mae: 467.0273\n",
            "Epoch 417/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 462.1984 - mae: 462.1984 - val_loss: 467.8504 - val_mae: 467.8504\n",
            "Epoch 418/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 461.9045 - mae: 461.9045 - val_loss: 466.8724 - val_mae: 466.8724\n",
            "Epoch 419/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 463.2590 - mae: 463.2590 - val_loss: 466.4323 - val_mae: 466.4323\n",
            "Epoch 420/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 461.3894 - mae: 461.3894 - val_loss: 467.5729 - val_mae: 467.5729\n",
            "Epoch 421/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 463.3947 - mae: 463.3947 - val_loss: 465.9480 - val_mae: 465.9480\n",
            "Epoch 422/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 460.5891 - mae: 460.5891 - val_loss: 466.4247 - val_mae: 466.4247\n",
            "Epoch 423/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 461.4751 - mae: 461.4751 - val_loss: 466.6125 - val_mae: 466.6125\n",
            "Epoch 424/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 461.1744 - mae: 461.1744 - val_loss: 466.1596 - val_mae: 466.1596\n",
            "Epoch 425/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 462.3675 - mae: 462.3675 - val_loss: 465.7968 - val_mae: 465.7968\n",
            "Epoch 426/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 462.2009 - mae: 462.2009 - val_loss: 466.3824 - val_mae: 466.3824\n",
            "Epoch 427/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 461.2767 - mae: 461.2767 - val_loss: 466.0974 - val_mae: 466.0974\n",
            "Epoch 428/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 460.9940 - mae: 460.9940 - val_loss: 467.1410 - val_mae: 467.1410\n",
            "Epoch 429/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 462.0690 - mae: 462.0690 - val_loss: 467.0415 - val_mae: 467.0415\n",
            "Epoch 430/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 462.5675 - mae: 462.5675 - val_loss: 466.6596 - val_mae: 466.6596\n",
            "Epoch 431/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 462.4737 - mae: 462.4737 - val_loss: 466.4214 - val_mae: 466.4214\n",
            "Epoch 432/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 461.5581 - mae: 461.5581 - val_loss: 467.3597 - val_mae: 467.3597\n",
            "Epoch 433/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 463.9752 - mae: 463.9752 - val_loss: 467.4375 - val_mae: 467.4375\n",
            "Epoch 434/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 461.4117 - mae: 461.4117 - val_loss: 466.8813 - val_mae: 466.8813\n",
            "Epoch 435/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 462.1138 - mae: 462.1138 - val_loss: 465.6509 - val_mae: 465.6509\n",
            "Epoch 436/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 462.3665 - mae: 462.3665 - val_loss: 466.8787 - val_mae: 466.8787\n",
            "Epoch 437/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 463.8702 - mae: 463.8702 - val_loss: 466.1792 - val_mae: 466.1792\n",
            "Epoch 438/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 459.9906 - mae: 459.9906 - val_loss: 465.8083 - val_mae: 465.8083\n",
            "Epoch 439/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 461.5753 - mae: 461.5753 - val_loss: 466.3545 - val_mae: 466.3545\n",
            "Epoch 440/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 461.1878 - mae: 461.1878 - val_loss: 466.3427 - val_mae: 466.3427\n",
            "Epoch 441/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 463.7336 - mae: 463.7336 - val_loss: 467.8604 - val_mae: 467.8604\n",
            "Epoch 442/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 462.4592 - mae: 462.4592 - val_loss: 467.6259 - val_mae: 467.6259\n",
            "Epoch 443/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 462.2824 - mae: 462.2824 - val_loss: 467.3269 - val_mae: 467.3269\n",
            "Epoch 444/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 462.1590 - mae: 462.1590 - val_loss: 466.2398 - val_mae: 466.2398\n",
            "Epoch 445/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 463.3796 - mae: 463.3796 - val_loss: 467.1547 - val_mae: 467.1547\n",
            "Epoch 446/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 461.5217 - mae: 461.5217 - val_loss: 466.9698 - val_mae: 466.9698\n",
            "Epoch 447/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 460.8230 - mae: 460.8230 - val_loss: 466.2045 - val_mae: 466.2045\n",
            "Epoch 448/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 462.8534 - mae: 462.8534 - val_loss: 466.0811 - val_mae: 466.0811\n",
            "Epoch 449/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 462.0601 - mae: 462.0601 - val_loss: 466.6530 - val_mae: 466.6530\n",
            "Epoch 450/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 463.8636 - mae: 463.8636 - val_loss: 465.1373 - val_mae: 465.1373\n",
            "Epoch 451/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 464.0311 - mae: 464.0311 - val_loss: 466.0046 - val_mae: 466.0046\n",
            "Epoch 452/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 462.2930 - mae: 462.2930 - val_loss: 466.2374 - val_mae: 466.2374\n",
            "Epoch 453/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 461.6283 - mae: 461.6283 - val_loss: 466.0042 - val_mae: 466.0042\n",
            "Epoch 454/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 461.1910 - mae: 461.1910 - val_loss: 467.3980 - val_mae: 467.3980\n",
            "Epoch 455/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 459.9487 - mae: 459.9487 - val_loss: 466.6984 - val_mae: 466.6984\n",
            "Epoch 456/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 464.6292 - mae: 464.6292 - val_loss: 467.1281 - val_mae: 467.1281\n",
            "Epoch 457/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 461.7778 - mae: 461.7778 - val_loss: 466.0959 - val_mae: 466.0959\n",
            "Epoch 458/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 463.8065 - mae: 463.8065 - val_loss: 466.3229 - val_mae: 466.3229\n",
            "Epoch 459/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 461.5200 - mae: 461.5200 - val_loss: 466.7531 - val_mae: 466.7531\n",
            "Epoch 460/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 460.4832 - mae: 460.4832 - val_loss: 467.2736 - val_mae: 467.2736\n",
            "Epoch 461/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 459.0366 - mae: 459.0366 - val_loss: 465.8149 - val_mae: 465.8149\n",
            "Epoch 462/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 460.1050 - mae: 460.1050 - val_loss: 467.8900 - val_mae: 467.8900\n",
            "Epoch 463/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 459.4147 - mae: 459.4147 - val_loss: 467.7906 - val_mae: 467.7906\n",
            "Epoch 464/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 461.4646 - mae: 461.4646 - val_loss: 466.2478 - val_mae: 466.2478\n",
            "Epoch 465/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 461.0563 - mae: 461.0563 - val_loss: 466.4256 - val_mae: 466.4256\n",
            "Epoch 466/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 461.2184 - mae: 461.2184 - val_loss: 468.5759 - val_mae: 468.5759\n",
            "Epoch 467/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 460.7939 - mae: 460.7939 - val_loss: 467.5679 - val_mae: 467.5679\n",
            "Epoch 468/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 461.4240 - mae: 461.4240 - val_loss: 467.2717 - val_mae: 467.2717\n",
            "Epoch 469/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 461.3719 - mae: 461.3719 - val_loss: 467.0836 - val_mae: 467.0836\n",
            "Epoch 470/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 460.4977 - mae: 460.4977 - val_loss: 467.1020 - val_mae: 467.1020\n",
            "Epoch 471/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 463.3452 - mae: 463.3452 - val_loss: 467.3073 - val_mae: 467.3073\n",
            "Epoch 472/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 460.7305 - mae: 460.7305 - val_loss: 466.7165 - val_mae: 466.7165\n",
            "Epoch 473/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 460.8796 - mae: 460.8796 - val_loss: 467.8609 - val_mae: 467.8609\n",
            "Epoch 474/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 461.7727 - mae: 461.7727 - val_loss: 467.2479 - val_mae: 467.2479\n",
            "Epoch 475/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 459.7707 - mae: 459.7707 - val_loss: 466.7195 - val_mae: 466.7195\n",
            "Epoch 476/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 462.5604 - mae: 462.5604 - val_loss: 466.8628 - val_mae: 466.8628\n",
            "Epoch 477/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 461.0265 - mae: 461.0265 - val_loss: 466.8351 - val_mae: 466.8351\n",
            "Epoch 478/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 463.7063 - mae: 463.7063 - val_loss: 467.3299 - val_mae: 467.3299\n",
            "Epoch 479/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 460.2366 - mae: 460.2366 - val_loss: 466.4893 - val_mae: 466.4893\n",
            "Epoch 480/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 462.3530 - mae: 462.3530 - val_loss: 466.9947 - val_mae: 466.9947\n",
            "Epoch 481/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 460.6454 - mae: 460.6454 - val_loss: 466.8286 - val_mae: 466.8286\n",
            "Epoch 482/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 460.0529 - mae: 460.0529 - val_loss: 467.0972 - val_mae: 467.0972\n",
            "Epoch 483/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 462.4308 - mae: 462.4308 - val_loss: 466.2264 - val_mae: 466.2264\n",
            "Epoch 484/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 460.6250 - mae: 460.6250 - val_loss: 466.9603 - val_mae: 466.9603\n",
            "Epoch 485/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 460.5280 - mae: 460.5280 - val_loss: 466.6093 - val_mae: 466.6093\n",
            "Epoch 486/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 461.0116 - mae: 461.0116 - val_loss: 467.0813 - val_mae: 467.0813\n",
            "Epoch 487/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 459.5673 - mae: 459.5673 - val_loss: 466.0021 - val_mae: 466.0021\n",
            "Epoch 488/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 461.1931 - mae: 461.1931 - val_loss: 466.4274 - val_mae: 466.4274\n",
            "Epoch 489/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 458.8361 - mae: 458.8361 - val_loss: 467.2917 - val_mae: 467.2917\n",
            "Epoch 490/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 460.0364 - mae: 460.0364 - val_loss: 466.3991 - val_mae: 466.3991\n",
            "Epoch 491/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 461.4019 - mae: 461.4019 - val_loss: 465.9991 - val_mae: 465.9991\n",
            "Epoch 492/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 460.1323 - mae: 460.1323 - val_loss: 465.6282 - val_mae: 465.6282\n",
            "Epoch 493/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 461.8933 - mae: 461.8933 - val_loss: 466.1317 - val_mae: 466.1317\n",
            "Epoch 494/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 460.6050 - mae: 460.6050 - val_loss: 466.6974 - val_mae: 466.6974\n",
            "Epoch 495/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 458.6467 - mae: 458.6467 - val_loss: 466.6886 - val_mae: 466.6886\n",
            "Epoch 496/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 460.1691 - mae: 460.1691 - val_loss: 466.9214 - val_mae: 466.9214\n",
            "Epoch 497/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 460.7226 - mae: 460.7226 - val_loss: 467.2968 - val_mae: 467.2968\n",
            "Epoch 498/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 459.8457 - mae: 459.8457 - val_loss: 467.3986 - val_mae: 467.3986\n",
            "Epoch 499/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 458.5889 - mae: 458.5889 - val_loss: 467.3061 - val_mae: 467.3061\n",
            "Epoch 500/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 460.7463 - mae: 460.7463 - val_loss: 466.9131 - val_mae: 466.9131\n",
            "Epoch 501/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 460.4049 - mae: 460.4049 - val_loss: 468.2791 - val_mae: 468.2791\n",
            "Epoch 502/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 460.5534 - mae: 460.5534 - val_loss: 468.2150 - val_mae: 468.2150\n",
            "Epoch 503/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 458.6830 - mae: 458.6830 - val_loss: 467.8682 - val_mae: 467.8682\n",
            "Epoch 504/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 457.0773 - mae: 457.0773 - val_loss: 467.5263 - val_mae: 467.5263\n",
            "Epoch 505/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 461.5651 - mae: 461.5651 - val_loss: 467.3538 - val_mae: 467.3538\n",
            "Epoch 506/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 460.5232 - mae: 460.5232 - val_loss: 467.2383 - val_mae: 467.2383\n",
            "Epoch 507/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 462.0021 - mae: 462.0021 - val_loss: 466.8962 - val_mae: 466.8962\n",
            "Epoch 508/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 460.7732 - mae: 460.7732 - val_loss: 467.7828 - val_mae: 467.7828\n",
            "Epoch 509/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 459.9784 - mae: 459.9784 - val_loss: 466.8865 - val_mae: 466.8865\n",
            "Epoch 510/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 461.6394 - mae: 461.6394 - val_loss: 466.3255 - val_mae: 466.3255\n",
            "Epoch 511/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 457.9522 - mae: 457.9522 - val_loss: 467.1958 - val_mae: 467.1958\n",
            "Epoch 512/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 459.5867 - mae: 459.5867 - val_loss: 467.0995 - val_mae: 467.0995\n",
            "Epoch 513/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 459.9470 - mae: 459.9470 - val_loss: 467.5265 - val_mae: 467.5265\n",
            "Epoch 514/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 458.5913 - mae: 458.5913 - val_loss: 467.5561 - val_mae: 467.5561\n",
            "Epoch 515/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 461.7208 - mae: 461.7208 - val_loss: 468.3020 - val_mae: 468.3020\n",
            "Epoch 516/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 460.1536 - mae: 460.1536 - val_loss: 469.0667 - val_mae: 469.0667\n",
            "Epoch 517/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 461.1666 - mae: 461.1666 - val_loss: 468.0647 - val_mae: 468.0647\n",
            "Epoch 518/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 460.0632 - mae: 460.0632 - val_loss: 468.0033 - val_mae: 468.0033\n",
            "Epoch 519/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 458.2127 - mae: 458.2127 - val_loss: 468.2111 - val_mae: 468.2111\n",
            "Epoch 520/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 457.9979 - mae: 457.9979 - val_loss: 467.6772 - val_mae: 467.6772\n",
            "Epoch 521/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 463.3441 - mae: 463.3441 - val_loss: 467.6534 - val_mae: 467.6534\n",
            "Epoch 522/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 458.5058 - mae: 458.5058 - val_loss: 467.2682 - val_mae: 467.2682\n",
            "Epoch 523/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 460.9214 - mae: 460.9214 - val_loss: 468.6480 - val_mae: 468.6480\n",
            "Epoch 524/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 458.9506 - mae: 458.9506 - val_loss: 468.3385 - val_mae: 468.3385\n",
            "Epoch 525/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 461.3518 - mae: 461.3518 - val_loss: 468.0421 - val_mae: 468.0421\n",
            "Epoch 526/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 458.6847 - mae: 458.6847 - val_loss: 467.5436 - val_mae: 467.5436\n",
            "Epoch 527/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 458.4062 - mae: 458.4062 - val_loss: 468.1645 - val_mae: 468.1645\n",
            "Epoch 528/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 457.9200 - mae: 457.9200 - val_loss: 467.8103 - val_mae: 467.8103\n",
            "Epoch 529/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 460.4764 - mae: 460.4764 - val_loss: 468.0529 - val_mae: 468.0529\n",
            "Epoch 530/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 460.1152 - mae: 460.1152 - val_loss: 467.4605 - val_mae: 467.4605\n",
            "Epoch 531/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 457.7346 - mae: 457.7346 - val_loss: 468.2805 - val_mae: 468.2805\n",
            "Epoch 532/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 458.5629 - mae: 458.5629 - val_loss: 469.3055 - val_mae: 469.3055\n",
            "Epoch 533/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 459.4677 - mae: 459.4677 - val_loss: 469.0473 - val_mae: 469.0473\n",
            "Epoch 534/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 455.8203 - mae: 455.8203 - val_loss: 468.3613 - val_mae: 468.3613\n",
            "Epoch 535/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 460.0160 - mae: 460.0160 - val_loss: 467.7554 - val_mae: 467.7554\n",
            "Epoch 536/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 457.3257 - mae: 457.3257 - val_loss: 469.1990 - val_mae: 469.1990\n",
            "Epoch 537/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 459.4690 - mae: 459.4690 - val_loss: 468.9122 - val_mae: 468.9122\n",
            "Epoch 538/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 459.5399 - mae: 459.5399 - val_loss: 469.4682 - val_mae: 469.4682\n",
            "Epoch 539/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 462.1304 - mae: 462.1304 - val_loss: 468.5656 - val_mae: 468.5656\n",
            "Epoch 540/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 457.5485 - mae: 457.5485 - val_loss: 468.2713 - val_mae: 468.2713\n",
            "Epoch 541/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 460.4070 - mae: 460.4070 - val_loss: 469.4424 - val_mae: 469.4424\n",
            "Epoch 542/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 458.3341 - mae: 458.3341 - val_loss: 469.8733 - val_mae: 469.8733\n",
            "Epoch 543/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 457.0916 - mae: 457.0916 - val_loss: 469.2204 - val_mae: 469.2204\n",
            "Epoch 544/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 459.0429 - mae: 459.0429 - val_loss: 468.7472 - val_mae: 468.7472\n",
            "Epoch 545/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 458.4908 - mae: 458.4908 - val_loss: 467.2478 - val_mae: 467.2478\n",
            "Epoch 546/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 461.8430 - mae: 461.8430 - val_loss: 468.8586 - val_mae: 468.8586\n",
            "Epoch 547/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 458.3320 - mae: 458.3320 - val_loss: 469.1933 - val_mae: 469.1933\n",
            "Epoch 548/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 457.8186 - mae: 457.8186 - val_loss: 468.9669 - val_mae: 468.9669\n",
            "Epoch 549/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 459.4046 - mae: 459.4046 - val_loss: 469.7074 - val_mae: 469.7074\n",
            "Epoch 550/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 458.0653 - mae: 458.0653 - val_loss: 469.8018 - val_mae: 469.8018\n",
            "Epoch 551/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 462.2028 - mae: 462.2028 - val_loss: 467.8815 - val_mae: 467.8815\n",
            "Epoch 552/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 461.9496 - mae: 461.9496 - val_loss: 468.0151 - val_mae: 468.0151\n",
            "Epoch 553/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 457.0468 - mae: 457.0468 - val_loss: 468.0531 - val_mae: 468.0531\n",
            "Epoch 554/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 458.7851 - mae: 458.7851 - val_loss: 469.2946 - val_mae: 469.2946\n",
            "Epoch 555/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 457.6427 - mae: 457.6427 - val_loss: 468.2477 - val_mae: 468.2477\n",
            "Epoch 556/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 461.8702 - mae: 461.8702 - val_loss: 469.2552 - val_mae: 469.2552\n",
            "Epoch 557/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 458.7920 - mae: 458.7920 - val_loss: 468.0911 - val_mae: 468.0911\n",
            "Epoch 558/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 460.4545 - mae: 460.4545 - val_loss: 466.3829 - val_mae: 466.3829\n",
            "Epoch 559/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 460.4765 - mae: 460.4765 - val_loss: 467.6328 - val_mae: 467.6328\n",
            "Epoch 560/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 457.9407 - mae: 457.9407 - val_loss: 468.3484 - val_mae: 468.3484\n",
            "Epoch 561/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 456.6042 - mae: 456.6042 - val_loss: 468.1224 - val_mae: 468.1224\n",
            "Epoch 562/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 457.7203 - mae: 457.7203 - val_loss: 467.3956 - val_mae: 467.3956\n",
            "Epoch 563/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 459.9784 - mae: 459.9784 - val_loss: 467.6858 - val_mae: 467.6858\n",
            "Epoch 564/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 457.8498 - mae: 457.8498 - val_loss: 467.6557 - val_mae: 467.6557\n",
            "Epoch 565/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 457.9081 - mae: 457.9081 - val_loss: 468.1700 - val_mae: 468.1700\n",
            "Epoch 566/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 458.4475 - mae: 458.4475 - val_loss: 468.4186 - val_mae: 468.4186\n",
            "Epoch 567/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 457.1847 - mae: 457.1847 - val_loss: 468.2277 - val_mae: 468.2277\n",
            "Epoch 568/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 460.0232 - mae: 460.0232 - val_loss: 468.6370 - val_mae: 468.6370\n",
            "Epoch 569/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 458.2336 - mae: 458.2336 - val_loss: 469.3789 - val_mae: 469.3789\n",
            "Epoch 570/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 457.2688 - mae: 457.2688 - val_loss: 470.8715 - val_mae: 470.8715\n",
            "Epoch 571/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 457.8630 - mae: 457.8630 - val_loss: 468.2527 - val_mae: 468.2527\n",
            "Epoch 572/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 458.0249 - mae: 458.0249 - val_loss: 470.1358 - val_mae: 470.1358\n",
            "Epoch 573/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 458.4931 - mae: 458.4931 - val_loss: 468.4259 - val_mae: 468.4259\n",
            "Epoch 574/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 457.7462 - mae: 457.7462 - val_loss: 468.3440 - val_mae: 468.3440\n",
            "Epoch 575/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 460.1060 - mae: 460.1060 - val_loss: 469.8371 - val_mae: 469.8371\n",
            "Epoch 576/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 455.8869 - mae: 455.8869 - val_loss: 469.7538 - val_mae: 469.7538\n",
            "Epoch 577/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 456.8387 - mae: 456.8387 - val_loss: 469.7245 - val_mae: 469.7245\n",
            "Epoch 578/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 458.1850 - mae: 458.1850 - val_loss: 470.8684 - val_mae: 470.8684\n",
            "Epoch 579/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 459.5553 - mae: 459.5553 - val_loss: 470.9656 - val_mae: 470.9656\n",
            "Epoch 580/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 456.0474 - mae: 456.0474 - val_loss: 470.7006 - val_mae: 470.7006\n",
            "Epoch 581/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 458.5654 - mae: 458.5654 - val_loss: 472.7151 - val_mae: 472.7151\n",
            "Epoch 582/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 458.1420 - mae: 458.1420 - val_loss: 471.7876 - val_mae: 471.7876\n",
            "Epoch 583/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 458.8922 - mae: 458.8922 - val_loss: 471.9487 - val_mae: 471.9487\n",
            "Epoch 584/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 457.1212 - mae: 457.1212 - val_loss: 470.7223 - val_mae: 470.7223\n",
            "Epoch 585/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 457.0795 - mae: 457.0795 - val_loss: 471.9149 - val_mae: 471.9149\n",
            "Epoch 586/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 455.8263 - mae: 455.8263 - val_loss: 471.1602 - val_mae: 471.1602\n",
            "Epoch 587/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 458.1652 - mae: 458.1652 - val_loss: 469.3262 - val_mae: 469.3262\n",
            "Epoch 588/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 457.9415 - mae: 457.9415 - val_loss: 470.3320 - val_mae: 470.3320\n",
            "Epoch 589/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 459.0568 - mae: 459.0568 - val_loss: 470.1483 - val_mae: 470.1483\n",
            "Epoch 590/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 458.0116 - mae: 458.0116 - val_loss: 468.7953 - val_mae: 468.7953\n",
            "Epoch 591/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 457.3616 - mae: 457.3616 - val_loss: 471.1905 - val_mae: 471.1905\n",
            "Epoch 592/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 458.3600 - mae: 458.3600 - val_loss: 469.4259 - val_mae: 469.4259\n",
            "Epoch 593/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 457.7076 - mae: 457.7076 - val_loss: 470.0027 - val_mae: 470.0027\n",
            "Epoch 594/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 459.6044 - mae: 459.6044 - val_loss: 469.9476 - val_mae: 469.9476\n",
            "Epoch 595/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 455.0867 - mae: 455.0867 - val_loss: 468.8554 - val_mae: 468.8554\n",
            "Epoch 596/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 455.1107 - mae: 455.1107 - val_loss: 471.1167 - val_mae: 471.1167\n",
            "Epoch 597/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 461.2874 - mae: 461.2874 - val_loss: 470.7854 - val_mae: 470.7854\n",
            "Epoch 598/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 458.1029 - mae: 458.1029 - val_loss: 471.2071 - val_mae: 471.2071\n",
            "Epoch 599/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 459.3176 - mae: 459.3176 - val_loss: 470.1901 - val_mae: 470.1901\n",
            "Epoch 600/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 457.3044 - mae: 457.3044 - val_loss: 471.4135 - val_mae: 471.4135\n",
            "Epoch 601/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 457.1172 - mae: 457.1172 - val_loss: 469.9105 - val_mae: 469.9105\n",
            "Epoch 602/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 456.4277 - mae: 456.4277 - val_loss: 471.8185 - val_mae: 471.8185\n",
            "Epoch 603/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 455.6890 - mae: 455.6890 - val_loss: 472.4120 - val_mae: 472.4120\n",
            "Epoch 604/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 455.9843 - mae: 455.9843 - val_loss: 471.7426 - val_mae: 471.7426\n",
            "Epoch 605/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 457.5273 - mae: 457.5273 - val_loss: 470.6565 - val_mae: 470.6565\n",
            "Epoch 606/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 458.9349 - mae: 458.9349 - val_loss: 469.1302 - val_mae: 469.1302\n",
            "Epoch 607/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 457.1180 - mae: 457.1180 - val_loss: 468.7003 - val_mae: 468.7003\n",
            "Epoch 608/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 458.5448 - mae: 458.5448 - val_loss: 469.7341 - val_mae: 469.7341\n",
            "Epoch 609/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 457.6273 - mae: 457.6273 - val_loss: 468.5310 - val_mae: 468.5310\n",
            "Epoch 610/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 458.9157 - mae: 458.9157 - val_loss: 468.3816 - val_mae: 468.3816\n",
            "Epoch 611/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 458.4689 - mae: 458.4689 - val_loss: 469.2172 - val_mae: 469.2172\n",
            "Epoch 612/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 456.3420 - mae: 456.3420 - val_loss: 469.6449 - val_mae: 469.6449\n",
            "Epoch 613/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 459.5082 - mae: 459.5082 - val_loss: 470.4972 - val_mae: 470.4972\n",
            "Epoch 614/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 458.4961 - mae: 458.4961 - val_loss: 469.2839 - val_mae: 469.2839\n",
            "Epoch 615/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 455.6354 - mae: 455.6354 - val_loss: 470.7528 - val_mae: 470.7528\n",
            "Epoch 616/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 457.4874 - mae: 457.4874 - val_loss: 469.6573 - val_mae: 469.6573\n",
            "Epoch 617/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 456.9704 - mae: 456.9704 - val_loss: 469.9588 - val_mae: 469.9588\n",
            "Epoch 618/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 458.3285 - mae: 458.3285 - val_loss: 468.7209 - val_mae: 468.7209\n",
            "Epoch 619/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 456.8997 - mae: 456.8997 - val_loss: 470.5818 - val_mae: 470.5818\n",
            "Epoch 620/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 458.1767 - mae: 458.1767 - val_loss: 471.0887 - val_mae: 471.0887\n",
            "Epoch 621/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 455.4729 - mae: 455.4729 - val_loss: 471.4092 - val_mae: 471.4092\n",
            "Epoch 622/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 458.3328 - mae: 458.3328 - val_loss: 470.4362 - val_mae: 470.4362\n",
            "Epoch 623/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 454.9675 - mae: 454.9675 - val_loss: 472.3665 - val_mae: 472.3665\n",
            "Epoch 624/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 456.1701 - mae: 456.1701 - val_loss: 472.3624 - val_mae: 472.3624\n",
            "Epoch 625/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 457.6862 - mae: 457.6862 - val_loss: 471.1646 - val_mae: 471.1646\n",
            "Epoch 626/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 457.1103 - mae: 457.1103 - val_loss: 471.4889 - val_mae: 471.4889\n",
            "Epoch 627/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 456.5595 - mae: 456.5595 - val_loss: 470.1694 - val_mae: 470.1694\n",
            "Epoch 628/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 458.0817 - mae: 458.0817 - val_loss: 468.5094 - val_mae: 468.5094\n",
            "Epoch 629/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 456.1829 - mae: 456.1829 - val_loss: 470.8537 - val_mae: 470.8537\n",
            "Epoch 630/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 455.6654 - mae: 455.6654 - val_loss: 471.3827 - val_mae: 471.3827\n",
            "Epoch 631/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 455.4675 - mae: 455.4675 - val_loss: 469.2241 - val_mae: 469.2241\n",
            "Epoch 632/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 457.2157 - mae: 457.2157 - val_loss: 470.0113 - val_mae: 470.0113\n",
            "Epoch 633/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 455.3950 - mae: 455.3950 - val_loss: 472.3899 - val_mae: 472.3899\n",
            "Epoch 634/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 457.6198 - mae: 457.6198 - val_loss: 472.9095 - val_mae: 472.9095\n",
            "Epoch 635/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 458.7793 - mae: 458.7793 - val_loss: 471.3517 - val_mae: 471.3517\n",
            "Epoch 636/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 455.7152 - mae: 455.7152 - val_loss: 472.4712 - val_mae: 472.4712\n",
            "Epoch 637/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 455.5170 - mae: 455.5170 - val_loss: 475.3203 - val_mae: 475.3203\n",
            "Epoch 638/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 457.2019 - mae: 457.2019 - val_loss: 473.4185 - val_mae: 473.4185\n",
            "Epoch 639/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 454.0760 - mae: 454.0760 - val_loss: 470.8580 - val_mae: 470.8580\n",
            "Epoch 640/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 457.7226 - mae: 457.7226 - val_loss: 471.3665 - val_mae: 471.3665\n",
            "Epoch 641/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 456.6469 - mae: 456.6469 - val_loss: 470.7805 - val_mae: 470.7805\n",
            "Epoch 642/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 456.2042 - mae: 456.2042 - val_loss: 471.8192 - val_mae: 471.8192\n",
            "Epoch 643/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 456.7575 - mae: 456.7575 - val_loss: 470.6852 - val_mae: 470.6852\n",
            "Epoch 644/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 456.8352 - mae: 456.8352 - val_loss: 473.1459 - val_mae: 473.1459\n",
            "Epoch 645/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 456.8095 - mae: 456.8095 - val_loss: 472.9198 - val_mae: 472.9198\n",
            "Epoch 646/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 457.4564 - mae: 457.4564 - val_loss: 471.4014 - val_mae: 471.4014\n",
            "Epoch 647/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 454.6012 - mae: 454.6012 - val_loss: 472.3065 - val_mae: 472.3065\n",
            "Epoch 648/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 453.3867 - mae: 453.3867 - val_loss: 473.9965 - val_mae: 473.9965\n",
            "Epoch 649/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 458.2316 - mae: 458.2316 - val_loss: 472.0023 - val_mae: 472.0023\n",
            "Epoch 650/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 455.5450 - mae: 455.5450 - val_loss: 473.7265 - val_mae: 473.7265\n",
            "Epoch 651/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 456.2095 - mae: 456.2095 - val_loss: 473.8439 - val_mae: 473.8439\n",
            "Epoch 652/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 455.0574 - mae: 455.0574 - val_loss: 473.3925 - val_mae: 473.3925\n",
            "Epoch 653/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 458.9357 - mae: 458.9357 - val_loss: 471.9228 - val_mae: 471.9228\n",
            "Epoch 654/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 457.5019 - mae: 457.5019 - val_loss: 471.6664 - val_mae: 471.6664\n",
            "Epoch 655/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 454.3547 - mae: 454.3547 - val_loss: 473.4404 - val_mae: 473.4404\n",
            "Epoch 656/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 453.9564 - mae: 453.9564 - val_loss: 471.8843 - val_mae: 471.8843\n",
            "Epoch 657/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 459.2789 - mae: 459.2789 - val_loss: 471.5723 - val_mae: 471.5723\n",
            "Epoch 658/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 455.7587 - mae: 455.7587 - val_loss: 471.0896 - val_mae: 471.0896\n",
            "Epoch 659/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 455.7458 - mae: 455.7458 - val_loss: 471.6064 - val_mae: 471.6064\n",
            "Epoch 660/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 459.6546 - mae: 459.6546 - val_loss: 470.9763 - val_mae: 470.9763\n",
            "Epoch 661/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 456.2117 - mae: 456.2117 - val_loss: 472.1058 - val_mae: 472.1058\n",
            "Epoch 662/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 455.7049 - mae: 455.7049 - val_loss: 472.1730 - val_mae: 472.1730\n",
            "Epoch 663/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 455.8016 - mae: 455.8016 - val_loss: 470.8986 - val_mae: 470.8986\n",
            "Epoch 664/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 455.8878 - mae: 455.8878 - val_loss: 471.9716 - val_mae: 471.9716\n",
            "Epoch 665/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 453.3837 - mae: 453.3837 - val_loss: 472.1169 - val_mae: 472.1169\n",
            "Epoch 666/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 454.3581 - mae: 454.3581 - val_loss: 473.1987 - val_mae: 473.1987\n",
            "Epoch 667/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 456.1233 - mae: 456.1233 - val_loss: 472.5835 - val_mae: 472.5835\n",
            "Epoch 668/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 454.4945 - mae: 454.4945 - val_loss: 473.5583 - val_mae: 473.5583\n",
            "Epoch 669/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 461.5998 - mae: 461.5998 - val_loss: 471.8636 - val_mae: 471.8636\n",
            "Epoch 670/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 455.3958 - mae: 455.3958 - val_loss: 472.3665 - val_mae: 472.3665\n",
            "Epoch 671/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 457.3734 - mae: 457.3734 - val_loss: 472.6436 - val_mae: 472.6436\n",
            "Epoch 672/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 457.6987 - mae: 457.6987 - val_loss: 472.5001 - val_mae: 472.5001\n",
            "Epoch 673/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 455.3701 - mae: 455.3701 - val_loss: 473.1438 - val_mae: 473.1438\n",
            "Epoch 674/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 456.3179 - mae: 456.3179 - val_loss: 473.6904 - val_mae: 473.6904\n",
            "Epoch 675/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 455.5695 - mae: 455.5695 - val_loss: 471.8663 - val_mae: 471.8663\n",
            "Epoch 676/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 456.5252 - mae: 456.5252 - val_loss: 472.4835 - val_mae: 472.4835\n",
            "Epoch 677/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 455.0229 - mae: 455.0229 - val_loss: 471.1844 - val_mae: 471.1844\n",
            "Epoch 678/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 458.8092 - mae: 458.8092 - val_loss: 471.3781 - val_mae: 471.3781\n",
            "Epoch 679/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 455.4820 - mae: 455.4820 - val_loss: 472.5182 - val_mae: 472.5182\n",
            "Epoch 680/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 457.2438 - mae: 457.2438 - val_loss: 472.6605 - val_mae: 472.6605\n",
            "Epoch 681/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 453.3722 - mae: 453.3722 - val_loss: 473.7297 - val_mae: 473.7297\n",
            "Epoch 682/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 455.3875 - mae: 455.3875 - val_loss: 473.0673 - val_mae: 473.0673\n",
            "Epoch 683/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 455.8247 - mae: 455.8247 - val_loss: 473.0461 - val_mae: 473.0461\n",
            "Epoch 684/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 453.7986 - mae: 453.7986 - val_loss: 472.6902 - val_mae: 472.6902\n",
            "Epoch 685/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 454.5618 - mae: 454.5618 - val_loss: 473.4493 - val_mae: 473.4493\n",
            "Epoch 686/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 457.5874 - mae: 457.5874 - val_loss: 472.4681 - val_mae: 472.4681\n",
            "Epoch 687/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 455.2438 - mae: 455.2438 - val_loss: 473.3149 - val_mae: 473.3149\n",
            "Epoch 688/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 454.7522 - mae: 454.7522 - val_loss: 474.5722 - val_mae: 474.5722\n",
            "Epoch 689/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 452.5808 - mae: 452.5808 - val_loss: 472.8825 - val_mae: 472.8825\n",
            "Epoch 690/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 454.3567 - mae: 454.3567 - val_loss: 474.8206 - val_mae: 474.8206\n",
            "Epoch 691/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 454.3581 - mae: 454.3581 - val_loss: 473.2569 - val_mae: 473.2569\n",
            "Epoch 692/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 455.5076 - mae: 455.5076 - val_loss: 472.9789 - val_mae: 472.9789\n",
            "Epoch 693/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 455.9691 - mae: 455.9691 - val_loss: 470.6155 - val_mae: 470.6155\n",
            "Epoch 694/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 453.8154 - mae: 453.8154 - val_loss: 474.2131 - val_mae: 474.2131\n",
            "Epoch 695/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 457.7072 - mae: 457.7072 - val_loss: 474.2931 - val_mae: 474.2931\n",
            "Epoch 696/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 454.2469 - mae: 454.2469 - val_loss: 472.6043 - val_mae: 472.6043\n",
            "Epoch 697/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 455.4137 - mae: 455.4137 - val_loss: 471.8812 - val_mae: 471.8812\n",
            "Epoch 698/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 453.6821 - mae: 453.6821 - val_loss: 472.9756 - val_mae: 472.9756\n",
            "Epoch 699/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 456.2880 - mae: 456.2880 - val_loss: 471.7051 - val_mae: 471.7051\n",
            "Epoch 700/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 457.6431 - mae: 457.6431 - val_loss: 471.8774 - val_mae: 471.8774\n",
            "Epoch 701/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 450.9522 - mae: 450.9522 - val_loss: 474.9368 - val_mae: 474.9368\n",
            "Epoch 702/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 454.4491 - mae: 454.4491 - val_loss: 473.0688 - val_mae: 473.0688\n",
            "Epoch 703/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 455.3637 - mae: 455.3637 - val_loss: 472.4281 - val_mae: 472.4281\n",
            "Epoch 704/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 452.9978 - mae: 452.9978 - val_loss: 474.7268 - val_mae: 474.7268\n",
            "Epoch 705/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 454.1684 - mae: 454.1684 - val_loss: 473.6701 - val_mae: 473.6701\n",
            "Epoch 706/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 455.5321 - mae: 455.5321 - val_loss: 474.8351 - val_mae: 474.8351\n",
            "Epoch 707/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 455.0736 - mae: 455.0736 - val_loss: 474.4282 - val_mae: 474.4282\n",
            "Epoch 708/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 453.5609 - mae: 453.5609 - val_loss: 473.1461 - val_mae: 473.1461\n",
            "Epoch 709/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 453.1122 - mae: 453.1122 - val_loss: 472.8190 - val_mae: 472.8190\n",
            "Epoch 710/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 456.2645 - mae: 456.2645 - val_loss: 474.5055 - val_mae: 474.5055\n",
            "Epoch 711/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 454.7602 - mae: 454.7602 - val_loss: 474.8335 - val_mae: 474.8335\n",
            "Epoch 712/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 452.3608 - mae: 452.3608 - val_loss: 473.9734 - val_mae: 473.9734\n",
            "Epoch 713/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 452.9400 - mae: 452.9400 - val_loss: 474.8318 - val_mae: 474.8318\n",
            "Epoch 714/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 455.3567 - mae: 455.3567 - val_loss: 473.2434 - val_mae: 473.2434\n",
            "Epoch 715/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 455.8279 - mae: 455.8279 - val_loss: 472.1332 - val_mae: 472.1332\n",
            "Epoch 716/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 450.8254 - mae: 450.8254 - val_loss: 476.5639 - val_mae: 476.5639\n",
            "Epoch 717/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 455.0896 - mae: 455.0896 - val_loss: 474.5222 - val_mae: 474.5222\n",
            "Epoch 718/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 455.0293 - mae: 455.0293 - val_loss: 473.6728 - val_mae: 473.6728\n",
            "Epoch 719/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 454.0220 - mae: 454.0220 - val_loss: 473.1151 - val_mae: 473.1151\n",
            "Epoch 720/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 456.3041 - mae: 456.3041 - val_loss: 474.8531 - val_mae: 474.8531\n",
            "Epoch 721/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 454.9502 - mae: 454.9502 - val_loss: 475.7803 - val_mae: 475.7803\n",
            "Epoch 722/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 453.7083 - mae: 453.7083 - val_loss: 474.7869 - val_mae: 474.7869\n",
            "Epoch 723/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 453.4112 - mae: 453.4112 - val_loss: 475.1303 - val_mae: 475.1303\n",
            "Epoch 724/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 456.6492 - mae: 456.6492 - val_loss: 474.8807 - val_mae: 474.8807\n",
            "Epoch 725/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 454.0262 - mae: 454.0262 - val_loss: 476.5581 - val_mae: 476.5581\n",
            "Epoch 726/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 452.9599 - mae: 452.9599 - val_loss: 476.8616 - val_mae: 476.8616\n",
            "Epoch 727/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 453.5526 - mae: 453.5526 - val_loss: 475.3498 - val_mae: 475.3498\n",
            "Epoch 728/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 454.8580 - mae: 454.8580 - val_loss: 475.4281 - val_mae: 475.4281\n",
            "Epoch 729/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 455.4547 - mae: 455.4547 - val_loss: 474.1489 - val_mae: 474.1489\n",
            "Epoch 730/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 453.0341 - mae: 453.0341 - val_loss: 476.4474 - val_mae: 476.4474\n",
            "Epoch 731/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 452.7852 - mae: 452.7852 - val_loss: 476.5638 - val_mae: 476.5638\n",
            "Epoch 732/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 455.9554 - mae: 455.9554 - val_loss: 474.7784 - val_mae: 474.7784\n",
            "Epoch 733/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 453.8812 - mae: 453.8812 - val_loss: 474.6195 - val_mae: 474.6195\n",
            "Epoch 734/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 453.9970 - mae: 453.9970 - val_loss: 474.2778 - val_mae: 474.2778\n",
            "Epoch 735/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 455.1259 - mae: 455.1259 - val_loss: 473.1460 - val_mae: 473.1460\n",
            "Epoch 736/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 454.0720 - mae: 454.0720 - val_loss: 473.8739 - val_mae: 473.8739\n",
            "Epoch 737/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 456.7174 - mae: 456.7174 - val_loss: 471.8095 - val_mae: 471.8095\n",
            "Epoch 738/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 452.1386 - mae: 452.1386 - val_loss: 475.3693 - val_mae: 475.3693\n",
            "Epoch 739/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 453.9190 - mae: 453.9190 - val_loss: 474.4338 - val_mae: 474.4338\n",
            "Epoch 740/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 454.7912 - mae: 454.7912 - val_loss: 473.9888 - val_mae: 473.9888\n",
            "Epoch 741/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 453.3455 - mae: 453.3455 - val_loss: 478.4218 - val_mae: 478.4218\n",
            "Epoch 742/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 452.7135 - mae: 452.7135 - val_loss: 476.0092 - val_mae: 476.0092\n",
            "Epoch 743/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 454.8374 - mae: 454.8374 - val_loss: 476.0071 - val_mae: 476.0071\n",
            "Epoch 744/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 453.2328 - mae: 453.2328 - val_loss: 475.6847 - val_mae: 475.6847\n",
            "Epoch 745/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 453.4357 - mae: 453.4357 - val_loss: 476.0721 - val_mae: 476.0721\n",
            "Epoch 746/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 452.9804 - mae: 452.9804 - val_loss: 474.0638 - val_mae: 474.0638\n",
            "Epoch 747/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 453.2848 - mae: 453.2848 - val_loss: 475.1748 - val_mae: 475.1748\n",
            "Epoch 748/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 452.3427 - mae: 452.3427 - val_loss: 478.4346 - val_mae: 478.4346\n",
            "Epoch 749/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 452.8625 - mae: 452.8625 - val_loss: 477.6110 - val_mae: 477.6110\n",
            "Epoch 750/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 450.6384 - mae: 450.6384 - val_loss: 478.3904 - val_mae: 478.3904\n",
            "Epoch 751/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 455.4321 - mae: 455.4321 - val_loss: 477.3273 - val_mae: 477.3273\n",
            "Epoch 752/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 459.0107 - mae: 459.0107 - val_loss: 477.4140 - val_mae: 477.4140\n",
            "Epoch 753/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 453.1323 - mae: 453.1323 - val_loss: 478.5891 - val_mae: 478.5891\n",
            "Epoch 754/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 452.0143 - mae: 452.0143 - val_loss: 477.1839 - val_mae: 477.1839\n",
            "Epoch 755/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 454.0152 - mae: 454.0152 - val_loss: 476.3550 - val_mae: 476.3550\n",
            "Epoch 756/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 452.2357 - mae: 452.2357 - val_loss: 476.9790 - val_mae: 476.9790\n",
            "Epoch 757/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 455.3776 - mae: 455.3776 - val_loss: 475.5497 - val_mae: 475.5497\n",
            "Epoch 758/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 452.0383 - mae: 452.0383 - val_loss: 475.4652 - val_mae: 475.4652\n",
            "Epoch 759/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 453.4857 - mae: 453.4857 - val_loss: 474.9601 - val_mae: 474.9601\n",
            "Epoch 760/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 450.5817 - mae: 450.5817 - val_loss: 473.9753 - val_mae: 473.9753\n",
            "Epoch 761/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 451.3922 - mae: 451.3922 - val_loss: 474.9609 - val_mae: 474.9609\n",
            "Epoch 762/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 457.1624 - mae: 457.1624 - val_loss: 473.6212 - val_mae: 473.6212\n",
            "Epoch 763/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 451.1641 - mae: 451.1641 - val_loss: 474.1017 - val_mae: 474.1017\n",
            "Epoch 764/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 452.6970 - mae: 452.6970 - val_loss: 475.4052 - val_mae: 475.4052\n",
            "Epoch 765/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 454.5988 - mae: 454.5988 - val_loss: 474.5591 - val_mae: 474.5591\n",
            "Epoch 766/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 449.9190 - mae: 449.9190 - val_loss: 478.4073 - val_mae: 478.4073\n",
            "Epoch 767/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 454.0694 - mae: 454.0694 - val_loss: 474.3887 - val_mae: 474.3887\n",
            "Epoch 768/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 453.2000 - mae: 453.2000 - val_loss: 475.7649 - val_mae: 475.7649\n",
            "Epoch 769/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 453.3863 - mae: 453.3863 - val_loss: 478.0096 - val_mae: 478.0096\n",
            "Epoch 770/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 453.1564 - mae: 453.1564 - val_loss: 474.8570 - val_mae: 474.8570\n",
            "Epoch 771/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 454.7638 - mae: 454.7638 - val_loss: 475.9156 - val_mae: 475.9156\n",
            "Epoch 772/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 452.0785 - mae: 452.0785 - val_loss: 475.6570 - val_mae: 475.6570\n",
            "Epoch 773/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 453.1789 - mae: 453.1789 - val_loss: 477.6320 - val_mae: 477.6320\n",
            "Epoch 774/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 453.5730 - mae: 453.5730 - val_loss: 479.1998 - val_mae: 479.1998\n",
            "Epoch 775/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 453.5894 - mae: 453.5894 - val_loss: 476.7904 - val_mae: 476.7904\n",
            "Epoch 776/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 449.6414 - mae: 449.6414 - val_loss: 476.2803 - val_mae: 476.2803\n",
            "Epoch 777/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 453.2347 - mae: 453.2347 - val_loss: 475.7259 - val_mae: 475.7259\n",
            "Epoch 778/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 451.6412 - mae: 451.6412 - val_loss: 476.5950 - val_mae: 476.5950\n",
            "Epoch 779/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 454.0717 - mae: 454.0717 - val_loss: 474.7037 - val_mae: 474.7037\n",
            "Epoch 780/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 452.4574 - mae: 452.4574 - val_loss: 476.0820 - val_mae: 476.0820\n",
            "Epoch 781/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 460.9676 - mae: 460.9676 - val_loss: 476.1185 - val_mae: 476.1185\n",
            "Epoch 782/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 452.2200 - mae: 452.2200 - val_loss: 477.2495 - val_mae: 477.2495\n",
            "Epoch 783/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 452.7516 - mae: 452.7516 - val_loss: 477.2184 - val_mae: 477.2184\n",
            "Epoch 784/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 452.6768 - mae: 452.6768 - val_loss: 477.2398 - val_mae: 477.2398\n",
            "Epoch 785/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 455.1702 - mae: 455.1702 - val_loss: 477.3994 - val_mae: 477.3994\n",
            "Epoch 786/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 454.0868 - mae: 454.0868 - val_loss: 479.1911 - val_mae: 479.1911\n",
            "Epoch 787/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 451.3142 - mae: 451.3142 - val_loss: 475.9265 - val_mae: 475.9265\n",
            "Epoch 788/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 452.2525 - mae: 452.2525 - val_loss: 477.6368 - val_mae: 477.6368\n",
            "Epoch 789/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 452.5184 - mae: 452.5184 - val_loss: 476.8788 - val_mae: 476.8788\n",
            "Epoch 790/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 452.7988 - mae: 452.7988 - val_loss: 476.8443 - val_mae: 476.8443\n",
            "Epoch 791/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 453.3952 - mae: 453.3952 - val_loss: 476.0058 - val_mae: 476.0058\n",
            "Epoch 792/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 453.3740 - mae: 453.3740 - val_loss: 478.0087 - val_mae: 478.0087\n",
            "Epoch 793/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 453.0486 - mae: 453.0486 - val_loss: 474.6969 - val_mae: 474.6969\n",
            "Epoch 794/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 449.3171 - mae: 449.3171 - val_loss: 475.3681 - val_mae: 475.3681\n",
            "Epoch 795/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 450.8638 - mae: 450.8638 - val_loss: 479.9158 - val_mae: 479.9158\n",
            "Epoch 796/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 453.7745 - mae: 453.7745 - val_loss: 477.3497 - val_mae: 477.3497\n",
            "Epoch 797/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 455.4349 - mae: 455.4349 - val_loss: 479.0443 - val_mae: 479.0443\n",
            "Epoch 798/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 453.5632 - mae: 453.5632 - val_loss: 478.2036 - val_mae: 478.2036\n",
            "Epoch 799/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 451.7413 - mae: 451.7413 - val_loss: 478.0819 - val_mae: 478.0819\n",
            "Epoch 800/800\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 452.5368 - mae: 452.5368 - val_loss: 478.7156 - val_mae: 478.7156\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "loss = pd.read_csv('log_enc.csv',  sep=';')\n",
        "print(loss.head())\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(5,4))\n",
        "ax = sns.lineplot(data=loss, x='epoch', y='mae', label='training')\n",
        "ax = sns.lineplot(data=loss, x='epoch', y='val_mae', label='validation')\n",
        "ax.set_title('After Feature Engineering')\n",
        "ax.grid()\n",
        "ax.legend()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 420
        },
        "id": "LXj_z_7LcW9I",
        "outputId": "b6076b02-713d-4082-86c9-c1bd96347811"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   epoch        loss         mae    val_loss     val_mae\n",
            "0      0  506.154602  506.154602  496.431091  496.431091\n",
            "1      1  493.901459  493.901459  485.535400  485.535400\n",
            "2      2  491.083527  491.083527  483.346283  483.346283\n",
            "3      3  489.126465  489.126465  481.894989  481.894989\n",
            "4      4  488.415833  488.415833  480.851990  480.851990\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fb11e061a90>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 360x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model1.fit(X_train,y_train,epochs=40,batch_size=64,validation_data=[X_test,y_test])\n",
        "print('Final MAE of validation: %f' %(model1.evaluate(X_test, y_test)[1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "isNYZlWZgqhV",
        "outputId": "409aa89b-86f2-4b1c-d9f1-e3205696e761"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 452.1525 - mae: 452.1525 - val_loss: 479.0789 - val_mae: 479.0789\n",
            "Epoch 2/40\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 452.2858 - mae: 452.2858 - val_loss: 477.5071 - val_mae: 477.5071\n",
            "Epoch 3/40\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 454.1473 - mae: 454.1473 - val_loss: 476.5750 - val_mae: 476.5750\n",
            "Epoch 4/40\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 452.5591 - mae: 452.5591 - val_loss: 477.2542 - val_mae: 477.2542\n",
            "Epoch 5/40\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 451.6518 - mae: 451.6518 - val_loss: 479.1536 - val_mae: 479.1536\n",
            "Epoch 6/40\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 449.5033 - mae: 449.5033 - val_loss: 477.7381 - val_mae: 477.7381\n",
            "Epoch 7/40\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 449.0901 - mae: 449.0901 - val_loss: 480.2352 - val_mae: 480.2352\n",
            "Epoch 8/40\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 450.1414 - mae: 450.1414 - val_loss: 478.8029 - val_mae: 478.8029\n",
            "Epoch 9/40\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 452.0066 - mae: 452.0066 - val_loss: 478.9375 - val_mae: 478.9375\n",
            "Epoch 10/40\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 450.7515 - mae: 450.7515 - val_loss: 480.7853 - val_mae: 480.7853\n",
            "Epoch 11/40\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 451.6857 - mae: 451.6857 - val_loss: 482.6481 - val_mae: 482.6481\n",
            "Epoch 12/40\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 450.9989 - mae: 450.9989 - val_loss: 479.9471 - val_mae: 479.9471\n",
            "Epoch 13/40\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 449.2393 - mae: 449.2393 - val_loss: 478.9502 - val_mae: 478.9502\n",
            "Epoch 14/40\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 450.8027 - mae: 450.8027 - val_loss: 480.5762 - val_mae: 480.5762\n",
            "Epoch 15/40\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 453.6569 - mae: 453.6569 - val_loss: 478.8964 - val_mae: 478.8964\n",
            "Epoch 16/40\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 455.9344 - mae: 455.9344 - val_loss: 480.4533 - val_mae: 480.4533\n",
            "Epoch 17/40\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 452.2477 - mae: 452.2477 - val_loss: 478.2781 - val_mae: 478.2781\n",
            "Epoch 18/40\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 451.9401 - mae: 451.9401 - val_loss: 480.3472 - val_mae: 480.3472\n",
            "Epoch 19/40\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 453.2318 - mae: 453.2318 - val_loss: 477.1746 - val_mae: 477.1746\n",
            "Epoch 20/40\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 451.6104 - mae: 451.6104 - val_loss: 480.3651 - val_mae: 480.3651\n",
            "Epoch 21/40\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 448.8683 - mae: 448.8683 - val_loss: 478.5693 - val_mae: 478.5693\n",
            "Epoch 22/40\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 453.2686 - mae: 453.2686 - val_loss: 479.9015 - val_mae: 479.9015\n",
            "Epoch 23/40\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 451.4073 - mae: 451.4073 - val_loss: 477.2870 - val_mae: 477.2870\n",
            "Epoch 24/40\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 451.1232 - mae: 451.1232 - val_loss: 478.5231 - val_mae: 478.5231\n",
            "Epoch 25/40\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 452.0692 - mae: 452.0692 - val_loss: 480.1516 - val_mae: 480.1516\n",
            "Epoch 26/40\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 455.4415 - mae: 455.4415 - val_loss: 479.6682 - val_mae: 479.6682\n",
            "Epoch 27/40\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 452.7987 - mae: 452.7987 - val_loss: 481.0286 - val_mae: 481.0286\n",
            "Epoch 28/40\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 450.1488 - mae: 450.1488 - val_loss: 479.0864 - val_mae: 479.0864\n",
            "Epoch 29/40\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 450.5212 - mae: 450.5212 - val_loss: 479.0987 - val_mae: 479.0987\n",
            "Epoch 30/40\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 451.8024 - mae: 451.8024 - val_loss: 479.9342 - val_mae: 479.9342\n",
            "Epoch 31/40\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 454.5440 - mae: 454.5440 - val_loss: 480.0046 - val_mae: 480.0046\n",
            "Epoch 32/40\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 453.7959 - mae: 453.7959 - val_loss: 479.1670 - val_mae: 479.1670\n",
            "Epoch 33/40\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 452.2302 - mae: 452.2302 - val_loss: 477.8235 - val_mae: 477.8235\n",
            "Epoch 34/40\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 449.7701 - mae: 449.7701 - val_loss: 479.4893 - val_mae: 479.4893\n",
            "Epoch 35/40\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 452.6486 - mae: 452.6486 - val_loss: 479.1992 - val_mae: 479.1992\n",
            "Epoch 36/40\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 450.5372 - mae: 450.5372 - val_loss: 480.2408 - val_mae: 480.2408\n",
            "Epoch 37/40\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 453.2350 - mae: 453.2350 - val_loss: 479.4765 - val_mae: 479.4765\n",
            "Epoch 38/40\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 452.0986 - mae: 452.0986 - val_loss: 479.7311 - val_mae: 479.7311\n",
            "Epoch 39/40\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 453.3974 - mae: 453.3974 - val_loss: 479.7030 - val_mae: 479.7030\n",
            "Epoch 40/40\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 451.8091 - mae: 451.8091 - val_loss: 480.3490 - val_mae: 480.3490\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 480.3489 - mae: 480.3489\n",
            "Final MAE of validation: 480.348907\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "There is no any significant different on the performance of the model."
      ],
      "metadata": {
        "id": "07AiEYAbj3J0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Does removing the outliers in the tenure column improve the performance?\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "-PckbEcpiFZU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(data.shape)\n",
        "data_noout = data[data.tenure<data.std().tenure*3]\n",
        "print(data_noout.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6bSVopyWj4mG",
        "outputId": "934addf4-1356-432b-e251-1fe47e3c1ccd"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(20000, 9)\n",
            "(18906, 9)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
            "  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1094 datapoints were removed."
      ],
      "metadata": {
        "id": "oTz44_h6kWHE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "target = data_noout.deposit_next\n",
        "input_features = data_noout[['tenure', 'deposit', 'turnover', 'withdrawal']]\n",
        "\n",
        "scaled = scaler.fit_transform(input_features)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(scaled, target, test_size=0.2, random_state=42)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(128, input_shape=(4,), activation='relu'))\n",
        "model.add(Dropout(0.5)) \n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(1))\n",
        "model.compile(optimizer='adam', loss='mae', metrics='mae')\n",
        "\n",
        "csv_logger = CSVLogger('log_noout.csv', append=True, separator=';')\n",
        "history=model.fit(X_train,y_train,epochs=400,batch_size=64,validation_data=[X_test,y_test],callbacks=[csv_logger])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "agCxiGZbmbN_",
        "outputId": "8bb6dc54-2c59-44e3-98c0-963c37455283"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 496.5328 - mae: 496.5328 - val_loss: 473.6009 - val_mae: 473.6009\n",
            "Epoch 2/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 486.0244 - mae: 486.0244 - val_loss: 462.7421 - val_mae: 462.7421\n",
            "Epoch 3/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 481.2907 - mae: 481.2907 - val_loss: 460.6243 - val_mae: 460.6243\n",
            "Epoch 4/400\n",
            "237/237 [==============================] - 1s 2ms/step - loss: 479.6432 - mae: 479.6432 - val_loss: 459.1657 - val_mae: 459.1657\n",
            "Epoch 5/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 478.9394 - mae: 478.9394 - val_loss: 458.5659 - val_mae: 458.5659\n",
            "Epoch 6/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 476.9500 - mae: 476.9500 - val_loss: 457.6697 - val_mae: 457.6697\n",
            "Epoch 7/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 475.4907 - mae: 475.4907 - val_loss: 457.3167 - val_mae: 457.3167\n",
            "Epoch 8/400\n",
            "237/237 [==============================] - 1s 2ms/step - loss: 475.5811 - mae: 475.5811 - val_loss: 456.5996 - val_mae: 456.5996\n",
            "Epoch 9/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 472.7019 - mae: 472.7019 - val_loss: 456.0983 - val_mae: 456.0983\n",
            "Epoch 10/400\n",
            "237/237 [==============================] - 1s 2ms/step - loss: 472.4679 - mae: 472.4679 - val_loss: 456.1042 - val_mae: 456.1042\n",
            "Epoch 11/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 471.9778 - mae: 471.9778 - val_loss: 455.7070 - val_mae: 455.7070\n",
            "Epoch 12/400\n",
            "237/237 [==============================] - 1s 2ms/step - loss: 470.5968 - mae: 470.5968 - val_loss: 455.3578 - val_mae: 455.3578\n",
            "Epoch 13/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 470.0247 - mae: 470.0247 - val_loss: 455.4463 - val_mae: 455.4463\n",
            "Epoch 14/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 470.7266 - mae: 470.7266 - val_loss: 455.1038 - val_mae: 455.1038\n",
            "Epoch 15/400\n",
            "237/237 [==============================] - 1s 2ms/step - loss: 469.0607 - mae: 469.0607 - val_loss: 454.9367 - val_mae: 454.9367\n",
            "Epoch 16/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 468.4941 - mae: 468.4941 - val_loss: 454.7602 - val_mae: 454.7602\n",
            "Epoch 17/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 468.9223 - mae: 468.9223 - val_loss: 454.7610 - val_mae: 454.7610\n",
            "Epoch 18/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 468.9328 - mae: 468.9328 - val_loss: 455.0645 - val_mae: 455.0645\n",
            "Epoch 19/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 468.5497 - mae: 468.5497 - val_loss: 455.3663 - val_mae: 455.3663\n",
            "Epoch 20/400\n",
            "237/237 [==============================] - 1s 2ms/step - loss: 467.9822 - mae: 467.9822 - val_loss: 454.9995 - val_mae: 454.9995\n",
            "Epoch 21/400\n",
            "237/237 [==============================] - 1s 2ms/step - loss: 466.9568 - mae: 466.9568 - val_loss: 455.4795 - val_mae: 455.4795\n",
            "Epoch 22/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 467.7141 - mae: 467.7141 - val_loss: 455.3479 - val_mae: 455.3479\n",
            "Epoch 23/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 466.5685 - mae: 466.5685 - val_loss: 454.6343 - val_mae: 454.6343\n",
            "Epoch 24/400\n",
            "237/237 [==============================] - 1s 2ms/step - loss: 467.0790 - mae: 467.0790 - val_loss: 455.6304 - val_mae: 455.6304\n",
            "Epoch 25/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 466.2239 - mae: 466.2239 - val_loss: 454.6124 - val_mae: 454.6124\n",
            "Epoch 26/400\n",
            "237/237 [==============================] - 1s 2ms/step - loss: 466.8904 - mae: 466.8904 - val_loss: 455.0150 - val_mae: 455.0150\n",
            "Epoch 27/400\n",
            "237/237 [==============================] - 1s 2ms/step - loss: 465.3697 - mae: 465.3697 - val_loss: 454.7565 - val_mae: 454.7565\n",
            "Epoch 28/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 466.5997 - mae: 466.5997 - val_loss: 454.8195 - val_mae: 454.8195\n",
            "Epoch 29/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 465.6740 - mae: 465.6740 - val_loss: 454.5123 - val_mae: 454.5123\n",
            "Epoch 30/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 466.6634 - mae: 466.6634 - val_loss: 454.1413 - val_mae: 454.1413\n",
            "Epoch 31/400\n",
            "237/237 [==============================] - 1s 2ms/step - loss: 467.0666 - mae: 467.0666 - val_loss: 454.2302 - val_mae: 454.2302\n",
            "Epoch 32/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 466.0703 - mae: 466.0703 - val_loss: 454.2539 - val_mae: 454.2539\n",
            "Epoch 33/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 465.7447 - mae: 465.7447 - val_loss: 454.3268 - val_mae: 454.3268\n",
            "Epoch 34/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 464.9810 - mae: 464.9810 - val_loss: 453.9294 - val_mae: 453.9294\n",
            "Epoch 35/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 464.6820 - mae: 464.6820 - val_loss: 453.4688 - val_mae: 453.4688\n",
            "Epoch 36/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 466.1723 - mae: 466.1723 - val_loss: 453.9987 - val_mae: 453.9987\n",
            "Epoch 37/400\n",
            "237/237 [==============================] - 1s 2ms/step - loss: 464.4218 - mae: 464.4218 - val_loss: 453.1128 - val_mae: 453.1128\n",
            "Epoch 38/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 464.9955 - mae: 464.9955 - val_loss: 453.4688 - val_mae: 453.4688\n",
            "Epoch 39/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 464.1562 - mae: 464.1562 - val_loss: 452.8644 - val_mae: 452.8644\n",
            "Epoch 40/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 463.8228 - mae: 463.8228 - val_loss: 453.1015 - val_mae: 453.1015\n",
            "Epoch 41/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 464.4453 - mae: 464.4453 - val_loss: 452.9221 - val_mae: 452.9221\n",
            "Epoch 42/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 466.3594 - mae: 466.3594 - val_loss: 452.7108 - val_mae: 452.7108\n",
            "Epoch 43/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 463.1087 - mae: 463.1087 - val_loss: 452.5578 - val_mae: 452.5578\n",
            "Epoch 44/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 463.3817 - mae: 463.3817 - val_loss: 452.5594 - val_mae: 452.5594\n",
            "Epoch 45/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 463.8506 - mae: 463.8506 - val_loss: 451.7646 - val_mae: 451.7646\n",
            "Epoch 46/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 462.9080 - mae: 462.9080 - val_loss: 452.1016 - val_mae: 452.1016\n",
            "Epoch 47/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 462.5612 - mae: 462.5612 - val_loss: 452.7374 - val_mae: 452.7374\n",
            "Epoch 48/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 463.3913 - mae: 463.3913 - val_loss: 451.8865 - val_mae: 451.8865\n",
            "Epoch 49/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 462.6736 - mae: 462.6736 - val_loss: 452.3708 - val_mae: 452.3708\n",
            "Epoch 50/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 462.3992 - mae: 462.3992 - val_loss: 452.2935 - val_mae: 452.2935\n",
            "Epoch 51/400\n",
            "237/237 [==============================] - 1s 2ms/step - loss: 461.9676 - mae: 461.9676 - val_loss: 452.3752 - val_mae: 452.3752\n",
            "Epoch 52/400\n",
            "237/237 [==============================] - 1s 2ms/step - loss: 463.0747 - mae: 463.0747 - val_loss: 452.1470 - val_mae: 452.1470\n",
            "Epoch 53/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 462.2104 - mae: 462.2104 - val_loss: 451.4966 - val_mae: 451.4966\n",
            "Epoch 54/400\n",
            "237/237 [==============================] - 1s 2ms/step - loss: 462.2054 - mae: 462.2054 - val_loss: 451.4464 - val_mae: 451.4464\n",
            "Epoch 55/400\n",
            "237/237 [==============================] - 1s 2ms/step - loss: 462.5816 - mae: 462.5816 - val_loss: 451.8119 - val_mae: 451.8119\n",
            "Epoch 56/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 461.7698 - mae: 461.7698 - val_loss: 451.6217 - val_mae: 451.6217\n",
            "Epoch 57/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 462.2579 - mae: 462.2579 - val_loss: 451.4086 - val_mae: 451.4086\n",
            "Epoch 58/400\n",
            "237/237 [==============================] - 1s 2ms/step - loss: 462.6600 - mae: 462.6600 - val_loss: 451.3410 - val_mae: 451.3410\n",
            "Epoch 59/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 462.7110 - mae: 462.7110 - val_loss: 451.4918 - val_mae: 451.4918\n",
            "Epoch 60/400\n",
            "237/237 [==============================] - 1s 2ms/step - loss: 462.4928 - mae: 462.4928 - val_loss: 450.9440 - val_mae: 450.9440\n",
            "Epoch 61/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 462.3417 - mae: 462.3417 - val_loss: 451.0836 - val_mae: 451.0836\n",
            "Epoch 62/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 460.9123 - mae: 460.9123 - val_loss: 451.3019 - val_mae: 451.3019\n",
            "Epoch 63/400\n",
            "237/237 [==============================] - 1s 2ms/step - loss: 461.1404 - mae: 461.1404 - val_loss: 451.6804 - val_mae: 451.6804\n",
            "Epoch 64/400\n",
            "237/237 [==============================] - 1s 2ms/step - loss: 460.7968 - mae: 460.7968 - val_loss: 451.0555 - val_mae: 451.0555\n",
            "Epoch 65/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 461.6569 - mae: 461.6569 - val_loss: 450.7300 - val_mae: 450.7300\n",
            "Epoch 66/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 460.6819 - mae: 460.6819 - val_loss: 450.8497 - val_mae: 450.8497\n",
            "Epoch 67/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 461.0524 - mae: 461.0524 - val_loss: 450.7568 - val_mae: 450.7568\n",
            "Epoch 68/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 461.4520 - mae: 461.4520 - val_loss: 450.7002 - val_mae: 450.7002\n",
            "Epoch 69/400\n",
            "237/237 [==============================] - 1s 2ms/step - loss: 461.1725 - mae: 461.1725 - val_loss: 451.0909 - val_mae: 451.0909\n",
            "Epoch 70/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 461.9127 - mae: 461.9127 - val_loss: 450.6885 - val_mae: 450.6885\n",
            "Epoch 71/400\n",
            "237/237 [==============================] - 1s 2ms/step - loss: 461.7322 - mae: 461.7322 - val_loss: 450.5851 - val_mae: 450.5851\n",
            "Epoch 72/400\n",
            "237/237 [==============================] - 1s 2ms/step - loss: 459.5130 - mae: 459.5130 - val_loss: 450.5639 - val_mae: 450.5639\n",
            "Epoch 73/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 461.1381 - mae: 461.1381 - val_loss: 451.1211 - val_mae: 451.1211\n",
            "Epoch 74/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 460.9276 - mae: 460.9276 - val_loss: 450.5803 - val_mae: 450.5803\n",
            "Epoch 75/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 461.3136 - mae: 461.3136 - val_loss: 450.5520 - val_mae: 450.5520\n",
            "Epoch 76/400\n",
            "237/237 [==============================] - 1s 2ms/step - loss: 460.2543 - mae: 460.2543 - val_loss: 450.5216 - val_mae: 450.5216\n",
            "Epoch 77/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 461.7301 - mae: 461.7301 - val_loss: 450.2141 - val_mae: 450.2141\n",
            "Epoch 78/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 460.2490 - mae: 460.2490 - val_loss: 450.5857 - val_mae: 450.5857\n",
            "Epoch 79/400\n",
            "237/237 [==============================] - 1s 2ms/step - loss: 460.7673 - mae: 460.7673 - val_loss: 450.5805 - val_mae: 450.5805\n",
            "Epoch 80/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 460.0830 - mae: 460.0830 - val_loss: 451.3622 - val_mae: 451.3622\n",
            "Epoch 81/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 460.0688 - mae: 460.0688 - val_loss: 450.9822 - val_mae: 450.9822\n",
            "Epoch 82/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 460.6684 - mae: 460.6684 - val_loss: 450.4024 - val_mae: 450.4024\n",
            "Epoch 83/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 459.9275 - mae: 459.9275 - val_loss: 451.0450 - val_mae: 451.0450\n",
            "Epoch 84/400\n",
            "237/237 [==============================] - 1s 2ms/step - loss: 460.5008 - mae: 460.5008 - val_loss: 451.0994 - val_mae: 451.0994\n",
            "Epoch 85/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 459.4983 - mae: 459.4983 - val_loss: 451.0921 - val_mae: 451.0921\n",
            "Epoch 86/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 458.7291 - mae: 458.7291 - val_loss: 450.1736 - val_mae: 450.1736\n",
            "Epoch 87/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 459.8832 - mae: 459.8832 - val_loss: 450.8829 - val_mae: 450.8829\n",
            "Epoch 88/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 459.0695 - mae: 459.0695 - val_loss: 450.8208 - val_mae: 450.8208\n",
            "Epoch 89/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 459.1518 - mae: 459.1518 - val_loss: 450.4322 - val_mae: 450.4322\n",
            "Epoch 90/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 459.3662 - mae: 459.3662 - val_loss: 450.2261 - val_mae: 450.2261\n",
            "Epoch 91/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 459.0894 - mae: 459.0894 - val_loss: 450.6926 - val_mae: 450.6926\n",
            "Epoch 92/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 460.2465 - mae: 460.2465 - val_loss: 450.5660 - val_mae: 450.5660\n",
            "Epoch 93/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 457.0125 - mae: 457.0125 - val_loss: 449.9781 - val_mae: 449.9781\n",
            "Epoch 94/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 458.1729 - mae: 458.1729 - val_loss: 450.1096 - val_mae: 450.1096\n",
            "Epoch 95/400\n",
            "237/237 [==============================] - 1s 2ms/step - loss: 458.8883 - mae: 458.8883 - val_loss: 450.7747 - val_mae: 450.7747\n",
            "Epoch 96/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 460.0258 - mae: 460.0258 - val_loss: 451.1244 - val_mae: 451.1244\n",
            "Epoch 97/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 458.4885 - mae: 458.4885 - val_loss: 450.5920 - val_mae: 450.5920\n",
            "Epoch 98/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 459.6158 - mae: 459.6158 - val_loss: 450.2248 - val_mae: 450.2248\n",
            "Epoch 99/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 458.5975 - mae: 458.5975 - val_loss: 450.8446 - val_mae: 450.8446\n",
            "Epoch 100/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 457.5905 - mae: 457.5905 - val_loss: 450.9237 - val_mae: 450.9237\n",
            "Epoch 101/400\n",
            "237/237 [==============================] - 1s 5ms/step - loss: 457.8578 - mae: 457.8578 - val_loss: 451.3147 - val_mae: 451.3147\n",
            "Epoch 102/400\n",
            "237/237 [==============================] - 1s 5ms/step - loss: 460.0328 - mae: 460.0328 - val_loss: 450.1078 - val_mae: 450.1078\n",
            "Epoch 103/400\n",
            "237/237 [==============================] - 1s 5ms/step - loss: 459.0833 - mae: 459.0833 - val_loss: 450.3860 - val_mae: 450.3860\n",
            "Epoch 104/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 458.2922 - mae: 458.2922 - val_loss: 451.1862 - val_mae: 451.1862\n",
            "Epoch 105/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 458.7517 - mae: 458.7517 - val_loss: 450.5916 - val_mae: 450.5916\n",
            "Epoch 106/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 457.3144 - mae: 457.3144 - val_loss: 451.7914 - val_mae: 451.7914\n",
            "Epoch 107/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 457.9413 - mae: 457.9413 - val_loss: 451.6744 - val_mae: 451.6744\n",
            "Epoch 108/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 457.9467 - mae: 457.9467 - val_loss: 450.8707 - val_mae: 450.8707\n",
            "Epoch 109/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 458.0901 - mae: 458.0901 - val_loss: 450.8263 - val_mae: 450.8263\n",
            "Epoch 110/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 457.6878 - mae: 457.6878 - val_loss: 450.6107 - val_mae: 450.6107\n",
            "Epoch 111/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 457.0803 - mae: 457.0803 - val_loss: 451.3507 - val_mae: 451.3507\n",
            "Epoch 112/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 458.4123 - mae: 458.4123 - val_loss: 450.6916 - val_mae: 450.6916\n",
            "Epoch 113/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 457.5300 - mae: 457.5300 - val_loss: 450.3368 - val_mae: 450.3368\n",
            "Epoch 114/400\n",
            "237/237 [==============================] - 1s 5ms/step - loss: 458.2385 - mae: 458.2385 - val_loss: 450.5178 - val_mae: 450.5178\n",
            "Epoch 115/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 457.5566 - mae: 457.5566 - val_loss: 450.4279 - val_mae: 450.4279\n",
            "Epoch 116/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 456.5861 - mae: 456.5861 - val_loss: 450.9833 - val_mae: 450.9833\n",
            "Epoch 117/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 457.3920 - mae: 457.3920 - val_loss: 450.3593 - val_mae: 450.3593\n",
            "Epoch 118/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 456.7309 - mae: 456.7309 - val_loss: 450.4683 - val_mae: 450.4683\n",
            "Epoch 119/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 457.3545 - mae: 457.3545 - val_loss: 450.5367 - val_mae: 450.5367\n",
            "Epoch 120/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 457.4967 - mae: 457.4967 - val_loss: 451.9645 - val_mae: 451.9645\n",
            "Epoch 121/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 458.6686 - mae: 458.6686 - val_loss: 450.5341 - val_mae: 450.5341\n",
            "Epoch 122/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 457.2851 - mae: 457.2851 - val_loss: 450.9302 - val_mae: 450.9302\n",
            "Epoch 123/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 456.9945 - mae: 456.9945 - val_loss: 450.9840 - val_mae: 450.9840\n",
            "Epoch 124/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 458.1401 - mae: 458.1401 - val_loss: 451.2240 - val_mae: 451.2240\n",
            "Epoch 125/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 457.9657 - mae: 457.9657 - val_loss: 450.5186 - val_mae: 450.5186\n",
            "Epoch 126/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 456.6767 - mae: 456.6767 - val_loss: 450.4933 - val_mae: 450.4933\n",
            "Epoch 127/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 456.2213 - mae: 456.2213 - val_loss: 451.5135 - val_mae: 451.5135\n",
            "Epoch 128/400\n",
            "237/237 [==============================] - 1s 5ms/step - loss: 455.5044 - mae: 455.5044 - val_loss: 451.1882 - val_mae: 451.1882\n",
            "Epoch 129/400\n",
            "237/237 [==============================] - 1s 5ms/step - loss: 456.8255 - mae: 456.8255 - val_loss: 450.7106 - val_mae: 450.7106\n",
            "Epoch 130/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 455.9838 - mae: 455.9838 - val_loss: 452.0244 - val_mae: 452.0244\n",
            "Epoch 131/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 457.9539 - mae: 457.9539 - val_loss: 451.1070 - val_mae: 451.1070\n",
            "Epoch 132/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 457.3161 - mae: 457.3161 - val_loss: 451.1211 - val_mae: 451.1211\n",
            "Epoch 133/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 457.7619 - mae: 457.7619 - val_loss: 451.3928 - val_mae: 451.3928\n",
            "Epoch 134/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 456.3832 - mae: 456.3832 - val_loss: 450.7629 - val_mae: 450.7629\n",
            "Epoch 135/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 456.7342 - mae: 456.7342 - val_loss: 451.0149 - val_mae: 451.0149\n",
            "Epoch 136/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 457.3792 - mae: 457.3792 - val_loss: 450.8397 - val_mae: 450.8397\n",
            "Epoch 137/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 456.4341 - mae: 456.4341 - val_loss: 451.0562 - val_mae: 451.0562\n",
            "Epoch 138/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 458.6819 - mae: 458.6819 - val_loss: 451.2906 - val_mae: 451.2906\n",
            "Epoch 139/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 457.2828 - mae: 457.2828 - val_loss: 451.0449 - val_mae: 451.0449\n",
            "Epoch 140/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 457.4940 - mae: 457.4940 - val_loss: 451.3429 - val_mae: 451.3429\n",
            "Epoch 141/400\n",
            "237/237 [==============================] - 1s 2ms/step - loss: 457.1633 - mae: 457.1633 - val_loss: 451.2547 - val_mae: 451.2547\n",
            "Epoch 142/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 455.6580 - mae: 455.6580 - val_loss: 451.1591 - val_mae: 451.1591\n",
            "Epoch 143/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 456.6526 - mae: 456.6526 - val_loss: 451.3732 - val_mae: 451.3732\n",
            "Epoch 144/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 456.4604 - mae: 456.4604 - val_loss: 451.0118 - val_mae: 451.0118\n",
            "Epoch 145/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 457.1299 - mae: 457.1299 - val_loss: 451.0359 - val_mae: 451.0359\n",
            "Epoch 146/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 457.0809 - mae: 457.0809 - val_loss: 451.0024 - val_mae: 451.0024\n",
            "Epoch 147/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 457.0509 - mae: 457.0509 - val_loss: 450.8832 - val_mae: 450.8832\n",
            "Epoch 148/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 456.7632 - mae: 456.7632 - val_loss: 451.0493 - val_mae: 451.0493\n",
            "Epoch 149/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 456.7073 - mae: 456.7073 - val_loss: 451.0981 - val_mae: 451.0981\n",
            "Epoch 150/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 456.7759 - mae: 456.7759 - val_loss: 451.2261 - val_mae: 451.2261\n",
            "Epoch 151/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 455.9310 - mae: 455.9310 - val_loss: 451.0877 - val_mae: 451.0877\n",
            "Epoch 152/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 456.0648 - mae: 456.0648 - val_loss: 451.0752 - val_mae: 451.0752\n",
            "Epoch 153/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 456.4953 - mae: 456.4953 - val_loss: 451.1588 - val_mae: 451.1588\n",
            "Epoch 154/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 456.4151 - mae: 456.4151 - val_loss: 451.1731 - val_mae: 451.1731\n",
            "Epoch 155/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 456.9981 - mae: 456.9981 - val_loss: 452.1428 - val_mae: 452.1428\n",
            "Epoch 156/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 456.8385 - mae: 456.8385 - val_loss: 451.1563 - val_mae: 451.1563\n",
            "Epoch 157/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 456.0528 - mae: 456.0528 - val_loss: 450.8159 - val_mae: 450.8159\n",
            "Epoch 158/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 454.5900 - mae: 454.5900 - val_loss: 450.7411 - val_mae: 450.7411\n",
            "Epoch 159/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 455.4191 - mae: 455.4191 - val_loss: 450.9966 - val_mae: 450.9966\n",
            "Epoch 160/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 455.9762 - mae: 455.9762 - val_loss: 450.9124 - val_mae: 450.9124\n",
            "Epoch 161/400\n",
            "237/237 [==============================] - 1s 2ms/step - loss: 454.1476 - mae: 454.1476 - val_loss: 451.4242 - val_mae: 451.4242\n",
            "Epoch 162/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 454.2348 - mae: 454.2348 - val_loss: 451.6769 - val_mae: 451.6769\n",
            "Epoch 163/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 455.4217 - mae: 455.4217 - val_loss: 451.7916 - val_mae: 451.7916\n",
            "Epoch 164/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 455.9478 - mae: 455.9478 - val_loss: 451.2785 - val_mae: 451.2785\n",
            "Epoch 165/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 455.6664 - mae: 455.6664 - val_loss: 451.0060 - val_mae: 451.0060\n",
            "Epoch 166/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 455.5048 - mae: 455.5048 - val_loss: 451.2026 - val_mae: 451.2026\n",
            "Epoch 167/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 456.2745 - mae: 456.2745 - val_loss: 451.3096 - val_mae: 451.3096\n",
            "Epoch 168/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 455.0714 - mae: 455.0714 - val_loss: 451.3525 - val_mae: 451.3525\n",
            "Epoch 169/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 456.0437 - mae: 456.0437 - val_loss: 451.5294 - val_mae: 451.5294\n",
            "Epoch 170/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 456.4555 - mae: 456.4555 - val_loss: 451.6035 - val_mae: 451.6035\n",
            "Epoch 171/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 457.4453 - mae: 457.4453 - val_loss: 451.3307 - val_mae: 451.3307\n",
            "Epoch 172/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 455.8236 - mae: 455.8236 - val_loss: 451.3676 - val_mae: 451.3676\n",
            "Epoch 173/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 455.9872 - mae: 455.9872 - val_loss: 451.2780 - val_mae: 451.2780\n",
            "Epoch 174/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 455.4213 - mae: 455.4213 - val_loss: 452.3178 - val_mae: 452.3178\n",
            "Epoch 175/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 454.9866 - mae: 454.9866 - val_loss: 451.5634 - val_mae: 451.5634\n",
            "Epoch 176/400\n",
            "237/237 [==============================] - 1s 2ms/step - loss: 455.4210 - mae: 455.4210 - val_loss: 451.7553 - val_mae: 451.7553\n",
            "Epoch 177/400\n",
            "237/237 [==============================] - 1s 2ms/step - loss: 456.0192 - mae: 456.0192 - val_loss: 451.2907 - val_mae: 451.2907\n",
            "Epoch 178/400\n",
            "237/237 [==============================] - 1s 2ms/step - loss: 456.0615 - mae: 456.0615 - val_loss: 451.1288 - val_mae: 451.1288\n",
            "Epoch 179/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 455.3771 - mae: 455.3771 - val_loss: 451.8893 - val_mae: 451.8893\n",
            "Epoch 180/400\n",
            "237/237 [==============================] - 1s 2ms/step - loss: 455.1774 - mae: 455.1774 - val_loss: 450.9996 - val_mae: 450.9996\n",
            "Epoch 181/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 454.7771 - mae: 454.7771 - val_loss: 451.1697 - val_mae: 451.1697\n",
            "Epoch 182/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 456.2607 - mae: 456.2607 - val_loss: 450.6072 - val_mae: 450.6072\n",
            "Epoch 183/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 455.7028 - mae: 455.7028 - val_loss: 450.5977 - val_mae: 450.5977\n",
            "Epoch 184/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 453.2342 - mae: 453.2342 - val_loss: 450.8672 - val_mae: 450.8672\n",
            "Epoch 185/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 454.0339 - mae: 454.0339 - val_loss: 450.9608 - val_mae: 450.9608\n",
            "Epoch 186/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 454.8087 - mae: 454.8087 - val_loss: 451.6317 - val_mae: 451.6317\n",
            "Epoch 187/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 455.8734 - mae: 455.8734 - val_loss: 451.4100 - val_mae: 451.4100\n",
            "Epoch 188/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 454.5107 - mae: 454.5107 - val_loss: 451.3781 - val_mae: 451.3781\n",
            "Epoch 189/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 454.5028 - mae: 454.5028 - val_loss: 450.6625 - val_mae: 450.6625\n",
            "Epoch 190/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 453.3112 - mae: 453.3112 - val_loss: 450.6625 - val_mae: 450.6625\n",
            "Epoch 191/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 453.6506 - mae: 453.6506 - val_loss: 451.2957 - val_mae: 451.2957\n",
            "Epoch 192/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 455.0398 - mae: 455.0398 - val_loss: 451.3904 - val_mae: 451.3904\n",
            "Epoch 193/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 454.2447 - mae: 454.2447 - val_loss: 451.2995 - val_mae: 451.2995\n",
            "Epoch 194/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 455.0956 - mae: 455.0956 - val_loss: 453.4467 - val_mae: 453.4467\n",
            "Epoch 195/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 455.1231 - mae: 455.1231 - val_loss: 450.8399 - val_mae: 450.8399\n",
            "Epoch 196/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 455.0768 - mae: 455.0768 - val_loss: 451.0865 - val_mae: 451.0865\n",
            "Epoch 197/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 456.2242 - mae: 456.2242 - val_loss: 451.5168 - val_mae: 451.5168\n",
            "Epoch 198/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 456.2515 - mae: 456.2515 - val_loss: 452.3022 - val_mae: 452.3022\n",
            "Epoch 199/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 454.0161 - mae: 454.0161 - val_loss: 451.4704 - val_mae: 451.4704\n",
            "Epoch 200/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 455.8735 - mae: 455.8735 - val_loss: 452.1341 - val_mae: 452.1341\n",
            "Epoch 201/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 456.0056 - mae: 456.0056 - val_loss: 451.5016 - val_mae: 451.5016\n",
            "Epoch 202/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 455.4239 - mae: 455.4239 - val_loss: 451.5753 - val_mae: 451.5753\n",
            "Epoch 203/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 454.9112 - mae: 454.9112 - val_loss: 450.9583 - val_mae: 450.9583\n",
            "Epoch 204/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 456.3154 - mae: 456.3154 - val_loss: 451.1116 - val_mae: 451.1116\n",
            "Epoch 205/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 454.9532 - mae: 454.9532 - val_loss: 451.1037 - val_mae: 451.1037\n",
            "Epoch 206/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 454.5899 - mae: 454.5899 - val_loss: 451.0347 - val_mae: 451.0347\n",
            "Epoch 207/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 454.2652 - mae: 454.2652 - val_loss: 451.7504 - val_mae: 451.7504\n",
            "Epoch 208/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 454.7849 - mae: 454.7849 - val_loss: 451.5827 - val_mae: 451.5827\n",
            "Epoch 209/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 454.4317 - mae: 454.4317 - val_loss: 451.3753 - val_mae: 451.3753\n",
            "Epoch 210/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 453.9647 - mae: 453.9647 - val_loss: 450.7136 - val_mae: 450.7136\n",
            "Epoch 211/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 453.4990 - mae: 453.4990 - val_loss: 450.8329 - val_mae: 450.8329\n",
            "Epoch 212/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 454.6017 - mae: 454.6017 - val_loss: 451.3886 - val_mae: 451.3886\n",
            "Epoch 213/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 453.3195 - mae: 453.3195 - val_loss: 451.8224 - val_mae: 451.8224\n",
            "Epoch 214/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 453.9682 - mae: 453.9682 - val_loss: 451.6176 - val_mae: 451.6176\n",
            "Epoch 215/400\n",
            "237/237 [==============================] - 1s 2ms/step - loss: 453.4079 - mae: 453.4079 - val_loss: 452.1257 - val_mae: 452.1257\n",
            "Epoch 216/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 455.6070 - mae: 455.6070 - val_loss: 452.0924 - val_mae: 452.0924\n",
            "Epoch 217/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 455.8779 - mae: 455.8779 - val_loss: 451.3979 - val_mae: 451.3979\n",
            "Epoch 218/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 454.0442 - mae: 454.0442 - val_loss: 452.1174 - val_mae: 452.1174\n",
            "Epoch 219/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 454.8734 - mae: 454.8734 - val_loss: 451.1868 - val_mae: 451.1868\n",
            "Epoch 220/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 454.3296 - mae: 454.3296 - val_loss: 451.3459 - val_mae: 451.3459\n",
            "Epoch 221/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 453.5173 - mae: 453.5173 - val_loss: 451.7989 - val_mae: 451.7989\n",
            "Epoch 222/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 454.9518 - mae: 454.9518 - val_loss: 451.4886 - val_mae: 451.4886\n",
            "Epoch 223/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 454.4861 - mae: 454.4861 - val_loss: 451.5274 - val_mae: 451.5274\n",
            "Epoch 224/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 455.2688 - mae: 455.2688 - val_loss: 451.7391 - val_mae: 451.7391\n",
            "Epoch 225/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 454.3859 - mae: 454.3859 - val_loss: 452.2810 - val_mae: 452.2810\n",
            "Epoch 226/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 454.7089 - mae: 454.7089 - val_loss: 451.8377 - val_mae: 451.8377\n",
            "Epoch 227/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 455.6449 - mae: 455.6449 - val_loss: 452.7758 - val_mae: 452.7758\n",
            "Epoch 228/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 453.1181 - mae: 453.1181 - val_loss: 452.8863 - val_mae: 452.8863\n",
            "Epoch 229/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 455.8634 - mae: 455.8634 - val_loss: 451.9787 - val_mae: 451.9787\n",
            "Epoch 230/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 453.7354 - mae: 453.7354 - val_loss: 452.4039 - val_mae: 452.4039\n",
            "Epoch 231/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 454.3995 - mae: 454.3995 - val_loss: 452.3291 - val_mae: 452.3291\n",
            "Epoch 232/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 454.6079 - mae: 454.6079 - val_loss: 452.2519 - val_mae: 452.2519\n",
            "Epoch 233/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 453.6647 - mae: 453.6647 - val_loss: 452.0219 - val_mae: 452.0219\n",
            "Epoch 234/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 454.5605 - mae: 454.5605 - val_loss: 451.6779 - val_mae: 451.6779\n",
            "Epoch 235/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 455.1767 - mae: 455.1767 - val_loss: 452.3709 - val_mae: 452.3709\n",
            "Epoch 236/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 454.8170 - mae: 454.8170 - val_loss: 452.2611 - val_mae: 452.2611\n",
            "Epoch 237/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 452.0977 - mae: 452.0977 - val_loss: 452.4144 - val_mae: 452.4144\n",
            "Epoch 238/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 453.7135 - mae: 453.7135 - val_loss: 452.4618 - val_mae: 452.4618\n",
            "Epoch 239/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 454.0405 - mae: 454.0405 - val_loss: 452.4214 - val_mae: 452.4214\n",
            "Epoch 240/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 453.8050 - mae: 453.8050 - val_loss: 451.6924 - val_mae: 451.6924\n",
            "Epoch 241/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 453.5832 - mae: 453.5832 - val_loss: 451.9659 - val_mae: 451.9659\n",
            "Epoch 242/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 452.7372 - mae: 452.7372 - val_loss: 452.2303 - val_mae: 452.2303\n",
            "Epoch 243/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 453.8358 - mae: 453.8358 - val_loss: 452.3266 - val_mae: 452.3266\n",
            "Epoch 244/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 453.3840 - mae: 453.3840 - val_loss: 452.0738 - val_mae: 452.0738\n",
            "Epoch 245/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 452.3783 - mae: 452.3783 - val_loss: 452.0450 - val_mae: 452.0450\n",
            "Epoch 246/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 453.9878 - mae: 453.9878 - val_loss: 452.0991 - val_mae: 452.0991\n",
            "Epoch 247/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 452.6013 - mae: 452.6013 - val_loss: 452.1440 - val_mae: 452.1440\n",
            "Epoch 248/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 454.1531 - mae: 454.1531 - val_loss: 451.4474 - val_mae: 451.4474\n",
            "Epoch 249/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 453.9393 - mae: 453.9393 - val_loss: 452.6364 - val_mae: 452.6364\n",
            "Epoch 250/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 454.3233 - mae: 454.3233 - val_loss: 452.4560 - val_mae: 452.4560\n",
            "Epoch 251/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 453.3754 - mae: 453.3754 - val_loss: 452.1512 - val_mae: 452.1512\n",
            "Epoch 252/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 451.9893 - mae: 451.9893 - val_loss: 452.3805 - val_mae: 452.3805\n",
            "Epoch 253/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 452.7563 - mae: 452.7563 - val_loss: 452.5329 - val_mae: 452.5329\n",
            "Epoch 254/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 454.1490 - mae: 454.1490 - val_loss: 452.3168 - val_mae: 452.3168\n",
            "Epoch 255/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 455.1089 - mae: 455.1089 - val_loss: 452.0135 - val_mae: 452.0135\n",
            "Epoch 256/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 453.5286 - mae: 453.5286 - val_loss: 451.8275 - val_mae: 451.8275\n",
            "Epoch 257/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 452.8013 - mae: 452.8013 - val_loss: 452.4163 - val_mae: 452.4163\n",
            "Epoch 258/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 452.9795 - mae: 452.9795 - val_loss: 452.8243 - val_mae: 452.8243\n",
            "Epoch 259/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 454.0818 - mae: 454.0818 - val_loss: 452.5208 - val_mae: 452.5208\n",
            "Epoch 260/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 454.7475 - mae: 454.7475 - val_loss: 453.1882 - val_mae: 453.1882\n",
            "Epoch 261/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 453.5042 - mae: 453.5042 - val_loss: 452.1424 - val_mae: 452.1424\n",
            "Epoch 262/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 453.2744 - mae: 453.2744 - val_loss: 453.1115 - val_mae: 453.1115\n",
            "Epoch 263/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 453.0612 - mae: 453.0612 - val_loss: 452.2844 - val_mae: 452.2844\n",
            "Epoch 264/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 454.4745 - mae: 454.4745 - val_loss: 451.7877 - val_mae: 451.7877\n",
            "Epoch 265/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 453.0906 - mae: 453.0906 - val_loss: 452.6024 - val_mae: 452.6024\n",
            "Epoch 266/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 453.6332 - mae: 453.6332 - val_loss: 452.6456 - val_mae: 452.6456\n",
            "Epoch 267/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 453.3161 - mae: 453.3161 - val_loss: 452.6356 - val_mae: 452.6356\n",
            "Epoch 268/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 453.6788 - mae: 453.6788 - val_loss: 451.8791 - val_mae: 451.8791\n",
            "Epoch 269/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 453.6375 - mae: 453.6375 - val_loss: 453.3731 - val_mae: 453.3731\n",
            "Epoch 270/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 452.8897 - mae: 452.8897 - val_loss: 453.7412 - val_mae: 453.7412\n",
            "Epoch 271/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 453.8501 - mae: 453.8501 - val_loss: 452.3370 - val_mae: 452.3370\n",
            "Epoch 272/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 454.1067 - mae: 454.1067 - val_loss: 452.0874 - val_mae: 452.0874\n",
            "Epoch 273/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 453.0537 - mae: 453.0537 - val_loss: 452.6442 - val_mae: 452.6442\n",
            "Epoch 274/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 451.2546 - mae: 451.2546 - val_loss: 452.3871 - val_mae: 452.3871\n",
            "Epoch 275/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 454.6146 - mae: 454.6146 - val_loss: 452.8465 - val_mae: 452.8465\n",
            "Epoch 276/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 452.8364 - mae: 452.8364 - val_loss: 452.8406 - val_mae: 452.8406\n",
            "Epoch 277/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 453.5840 - mae: 453.5840 - val_loss: 452.8403 - val_mae: 452.8403\n",
            "Epoch 278/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 455.7479 - mae: 455.7479 - val_loss: 453.0029 - val_mae: 453.0029\n",
            "Epoch 279/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 450.5073 - mae: 450.5073 - val_loss: 452.8717 - val_mae: 452.8717\n",
            "Epoch 280/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 452.3557 - mae: 452.3557 - val_loss: 453.3532 - val_mae: 453.3532\n",
            "Epoch 281/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 452.6758 - mae: 452.6758 - val_loss: 452.9266 - val_mae: 452.9266\n",
            "Epoch 282/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 454.1842 - mae: 454.1842 - val_loss: 452.6831 - val_mae: 452.6831\n",
            "Epoch 283/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 454.1194 - mae: 454.1194 - val_loss: 452.7471 - val_mae: 452.7471\n",
            "Epoch 284/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 453.6700 - mae: 453.6700 - val_loss: 453.3846 - val_mae: 453.3846\n",
            "Epoch 285/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 451.7671 - mae: 451.7671 - val_loss: 452.8270 - val_mae: 452.8270\n",
            "Epoch 286/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 452.9511 - mae: 452.9511 - val_loss: 452.5999 - val_mae: 452.5999\n",
            "Epoch 287/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 451.5255 - mae: 451.5255 - val_loss: 453.7173 - val_mae: 453.7173\n",
            "Epoch 288/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 452.8814 - mae: 452.8814 - val_loss: 452.7738 - val_mae: 452.7738\n",
            "Epoch 289/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 453.0980 - mae: 453.0980 - val_loss: 453.2083 - val_mae: 453.2083\n",
            "Epoch 290/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 453.4567 - mae: 453.4567 - val_loss: 453.9874 - val_mae: 453.9874\n",
            "Epoch 291/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 451.9801 - mae: 451.9801 - val_loss: 453.4178 - val_mae: 453.4178\n",
            "Epoch 292/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 452.9591 - mae: 452.9591 - val_loss: 453.0784 - val_mae: 453.0784\n",
            "Epoch 293/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 453.0531 - mae: 453.0531 - val_loss: 451.8067 - val_mae: 451.8067\n",
            "Epoch 294/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 453.5009 - mae: 453.5009 - val_loss: 454.5218 - val_mae: 454.5218\n",
            "Epoch 295/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 452.3743 - mae: 452.3743 - val_loss: 453.2340 - val_mae: 453.2340\n",
            "Epoch 296/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 451.9476 - mae: 451.9476 - val_loss: 453.3648 - val_mae: 453.3648\n",
            "Epoch 297/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 451.2393 - mae: 451.2393 - val_loss: 453.4037 - val_mae: 453.4037\n",
            "Epoch 298/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 452.2739 - mae: 452.2739 - val_loss: 452.3450 - val_mae: 452.3450\n",
            "Epoch 299/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 450.7934 - mae: 450.7934 - val_loss: 452.3982 - val_mae: 452.3982\n",
            "Epoch 300/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 451.6592 - mae: 451.6592 - val_loss: 452.9412 - val_mae: 452.9412\n",
            "Epoch 301/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 452.5779 - mae: 452.5779 - val_loss: 452.9746 - val_mae: 452.9746\n",
            "Epoch 302/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 452.7761 - mae: 452.7761 - val_loss: 453.5744 - val_mae: 453.5744\n",
            "Epoch 303/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 452.3149 - mae: 452.3149 - val_loss: 453.2024 - val_mae: 453.2024\n",
            "Epoch 304/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 452.3605 - mae: 452.3605 - val_loss: 453.4268 - val_mae: 453.4268\n",
            "Epoch 305/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 451.7900 - mae: 451.7900 - val_loss: 453.3205 - val_mae: 453.3205\n",
            "Epoch 306/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 452.8595 - mae: 452.8595 - val_loss: 452.0239 - val_mae: 452.0239\n",
            "Epoch 307/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 452.0981 - mae: 452.0981 - val_loss: 453.2223 - val_mae: 453.2223\n",
            "Epoch 308/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 452.1537 - mae: 452.1537 - val_loss: 454.1024 - val_mae: 454.1024\n",
            "Epoch 309/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 450.7893 - mae: 450.7893 - val_loss: 452.7536 - val_mae: 452.7536\n",
            "Epoch 310/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 452.4001 - mae: 452.4001 - val_loss: 453.0198 - val_mae: 453.0198\n",
            "Epoch 311/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 452.2798 - mae: 452.2798 - val_loss: 452.5384 - val_mae: 452.5384\n",
            "Epoch 312/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 451.7829 - mae: 451.7829 - val_loss: 452.9796 - val_mae: 452.9796\n",
            "Epoch 313/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 450.9248 - mae: 450.9248 - val_loss: 452.9942 - val_mae: 452.9942\n",
            "Epoch 314/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 452.8562 - mae: 452.8562 - val_loss: 452.8456 - val_mae: 452.8456\n",
            "Epoch 315/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 453.1330 - mae: 453.1330 - val_loss: 452.7344 - val_mae: 452.7344\n",
            "Epoch 316/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 451.0610 - mae: 451.0610 - val_loss: 452.2122 - val_mae: 452.2122\n",
            "Epoch 317/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 451.7632 - mae: 451.7632 - val_loss: 452.9469 - val_mae: 452.9469\n",
            "Epoch 318/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 453.2221 - mae: 453.2221 - val_loss: 452.2060 - val_mae: 452.2060\n",
            "Epoch 319/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 452.7109 - mae: 452.7109 - val_loss: 452.1133 - val_mae: 452.1133\n",
            "Epoch 320/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 452.1288 - mae: 452.1288 - val_loss: 452.7731 - val_mae: 452.7731\n",
            "Epoch 321/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 452.1599 - mae: 452.1599 - val_loss: 452.9821 - val_mae: 452.9821\n",
            "Epoch 322/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 452.3284 - mae: 452.3284 - val_loss: 452.9242 - val_mae: 452.9242\n",
            "Epoch 323/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 452.7138 - mae: 452.7138 - val_loss: 453.4639 - val_mae: 453.4639\n",
            "Epoch 324/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 451.8057 - mae: 451.8057 - val_loss: 453.1205 - val_mae: 453.1205\n",
            "Epoch 325/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 453.2849 - mae: 453.2849 - val_loss: 453.3377 - val_mae: 453.3377\n",
            "Epoch 326/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 452.7216 - mae: 452.7216 - val_loss: 453.3899 - val_mae: 453.3899\n",
            "Epoch 327/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 452.0777 - mae: 452.0777 - val_loss: 453.0133 - val_mae: 453.0133\n",
            "Epoch 328/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 452.6295 - mae: 452.6295 - val_loss: 452.8294 - val_mae: 452.8294\n",
            "Epoch 329/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 451.1664 - mae: 451.1664 - val_loss: 453.3103 - val_mae: 453.3103\n",
            "Epoch 330/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 452.0869 - mae: 452.0869 - val_loss: 454.3307 - val_mae: 454.3307\n",
            "Epoch 331/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 454.1971 - mae: 454.1971 - val_loss: 452.9995 - val_mae: 452.9995\n",
            "Epoch 332/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 452.8461 - mae: 452.8461 - val_loss: 453.9636 - val_mae: 453.9636\n",
            "Epoch 333/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 452.2226 - mae: 452.2226 - val_loss: 453.4965 - val_mae: 453.4965\n",
            "Epoch 334/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 452.7491 - mae: 452.7491 - val_loss: 453.3267 - val_mae: 453.3267\n",
            "Epoch 335/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 452.0580 - mae: 452.0580 - val_loss: 454.4704 - val_mae: 454.4704\n",
            "Epoch 336/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 453.2007 - mae: 453.2007 - val_loss: 452.5669 - val_mae: 452.5669\n",
            "Epoch 337/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 452.4140 - mae: 452.4140 - val_loss: 452.8007 - val_mae: 452.8007\n",
            "Epoch 338/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 453.1702 - mae: 453.1702 - val_loss: 452.8888 - val_mae: 452.8888\n",
            "Epoch 339/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 451.1302 - mae: 451.1302 - val_loss: 452.7176 - val_mae: 452.7176\n",
            "Epoch 340/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 451.7473 - mae: 451.7473 - val_loss: 452.5795 - val_mae: 452.5795\n",
            "Epoch 341/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 451.7422 - mae: 451.7422 - val_loss: 452.5844 - val_mae: 452.5844\n",
            "Epoch 342/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 451.2539 - mae: 451.2539 - val_loss: 452.6875 - val_mae: 452.6875\n",
            "Epoch 343/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 453.0444 - mae: 453.0444 - val_loss: 453.0733 - val_mae: 453.0733\n",
            "Epoch 344/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 451.7935 - mae: 451.7935 - val_loss: 452.3249 - val_mae: 452.3249\n",
            "Epoch 345/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 452.7743 - mae: 452.7743 - val_loss: 453.1822 - val_mae: 453.1822\n",
            "Epoch 346/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 451.5132 - mae: 451.5132 - val_loss: 452.6289 - val_mae: 452.6289\n",
            "Epoch 347/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 454.0605 - mae: 454.0605 - val_loss: 452.8510 - val_mae: 452.8510\n",
            "Epoch 348/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 452.9312 - mae: 452.9312 - val_loss: 452.5961 - val_mae: 452.5961\n",
            "Epoch 349/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 452.2076 - mae: 452.2076 - val_loss: 453.0208 - val_mae: 453.0208\n",
            "Epoch 350/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 452.0188 - mae: 452.0188 - val_loss: 452.5962 - val_mae: 452.5962\n",
            "Epoch 351/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 452.4428 - mae: 452.4428 - val_loss: 452.9799 - val_mae: 452.9799\n",
            "Epoch 352/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 453.4825 - mae: 453.4825 - val_loss: 453.0809 - val_mae: 453.0809\n",
            "Epoch 353/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 451.2254 - mae: 451.2254 - val_loss: 452.9504 - val_mae: 452.9504\n",
            "Epoch 354/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 452.2277 - mae: 452.2277 - val_loss: 452.5733 - val_mae: 452.5733\n",
            "Epoch 355/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 449.6187 - mae: 449.6187 - val_loss: 452.5929 - val_mae: 452.5929\n",
            "Epoch 356/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 452.7446 - mae: 452.7446 - val_loss: 452.4072 - val_mae: 452.4072\n",
            "Epoch 357/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 452.1572 - mae: 452.1572 - val_loss: 452.9889 - val_mae: 452.9889\n",
            "Epoch 358/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 451.2751 - mae: 451.2751 - val_loss: 453.0934 - val_mae: 453.0934\n",
            "Epoch 359/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 450.4965 - mae: 450.4965 - val_loss: 451.5257 - val_mae: 451.5257\n",
            "Epoch 360/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 451.3598 - mae: 451.3598 - val_loss: 452.1386 - val_mae: 452.1386\n",
            "Epoch 361/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 452.1945 - mae: 452.1945 - val_loss: 452.6989 - val_mae: 452.6989\n",
            "Epoch 362/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 451.8760 - mae: 451.8760 - val_loss: 452.5791 - val_mae: 452.5791\n",
            "Epoch 363/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 452.6193 - mae: 452.6193 - val_loss: 453.3781 - val_mae: 453.3781\n",
            "Epoch 364/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 452.8731 - mae: 452.8731 - val_loss: 453.2513 - val_mae: 453.2513\n",
            "Epoch 365/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 451.5139 - mae: 451.5139 - val_loss: 453.1721 - val_mae: 453.1721\n",
            "Epoch 366/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 453.3607 - mae: 453.3607 - val_loss: 453.1293 - val_mae: 453.1293\n",
            "Epoch 367/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 451.6599 - mae: 451.6599 - val_loss: 452.9897 - val_mae: 452.9897\n",
            "Epoch 368/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 451.2234 - mae: 451.2234 - val_loss: 453.7626 - val_mae: 453.7626\n",
            "Epoch 369/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 451.8373 - mae: 451.8373 - val_loss: 454.3962 - val_mae: 454.3962\n",
            "Epoch 370/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 449.2711 - mae: 449.2711 - val_loss: 453.6693 - val_mae: 453.6693\n",
            "Epoch 371/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 451.3702 - mae: 451.3702 - val_loss: 453.0669 - val_mae: 453.0669\n",
            "Epoch 372/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 451.0098 - mae: 451.0098 - val_loss: 452.8727 - val_mae: 452.8727\n",
            "Epoch 373/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 450.2957 - mae: 450.2957 - val_loss: 453.4153 - val_mae: 453.4153\n",
            "Epoch 374/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 451.3222 - mae: 451.3222 - val_loss: 453.1773 - val_mae: 453.1773\n",
            "Epoch 375/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 451.3839 - mae: 451.3839 - val_loss: 453.5450 - val_mae: 453.5450\n",
            "Epoch 376/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 450.7305 - mae: 450.7305 - val_loss: 453.1460 - val_mae: 453.1460\n",
            "Epoch 377/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 452.4742 - mae: 452.4742 - val_loss: 453.7708 - val_mae: 453.7708\n",
            "Epoch 378/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 452.3992 - mae: 452.3992 - val_loss: 452.7941 - val_mae: 452.7941\n",
            "Epoch 379/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 452.4646 - mae: 452.4646 - val_loss: 453.2143 - val_mae: 453.2143\n",
            "Epoch 380/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 452.5805 - mae: 452.5805 - val_loss: 453.0131 - val_mae: 453.0131\n",
            "Epoch 381/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 451.9656 - mae: 451.9656 - val_loss: 453.4484 - val_mae: 453.4484\n",
            "Epoch 382/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 451.4855 - mae: 451.4855 - val_loss: 453.0684 - val_mae: 453.0684\n",
            "Epoch 383/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 451.8094 - mae: 451.8094 - val_loss: 451.9940 - val_mae: 451.9940\n",
            "Epoch 384/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 452.7762 - mae: 452.7762 - val_loss: 453.3028 - val_mae: 453.3028\n",
            "Epoch 385/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 451.8090 - mae: 451.8090 - val_loss: 453.8542 - val_mae: 453.8542\n",
            "Epoch 386/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 452.9998 - mae: 452.9998 - val_loss: 453.4038 - val_mae: 453.4038\n",
            "Epoch 387/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 451.9428 - mae: 451.9428 - val_loss: 453.1318 - val_mae: 453.1318\n",
            "Epoch 388/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 450.1896 - mae: 450.1896 - val_loss: 453.1096 - val_mae: 453.1096\n",
            "Epoch 389/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 450.6839 - mae: 450.6839 - val_loss: 453.4558 - val_mae: 453.4558\n",
            "Epoch 390/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 452.0919 - mae: 452.0919 - val_loss: 452.8313 - val_mae: 452.8313\n",
            "Epoch 391/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 451.6228 - mae: 451.6228 - val_loss: 454.0328 - val_mae: 454.0328\n",
            "Epoch 392/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 451.9953 - mae: 451.9953 - val_loss: 453.1391 - val_mae: 453.1391\n",
            "Epoch 393/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 451.8878 - mae: 451.8878 - val_loss: 452.8762 - val_mae: 452.8762\n",
            "Epoch 394/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 450.2315 - mae: 450.2315 - val_loss: 453.7947 - val_mae: 453.7947\n",
            "Epoch 395/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 451.6341 - mae: 451.6341 - val_loss: 453.1492 - val_mae: 453.1492\n",
            "Epoch 396/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 451.0330 - mae: 451.0330 - val_loss: 453.0901 - val_mae: 453.0901\n",
            "Epoch 397/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 451.1438 - mae: 451.1438 - val_loss: 452.9732 - val_mae: 452.9732\n",
            "Epoch 398/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 451.8393 - mae: 451.8393 - val_loss: 453.9078 - val_mae: 453.9078\n",
            "Epoch 399/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 452.1278 - mae: 452.1278 - val_loss: 454.2258 - val_mae: 454.2258\n",
            "Epoch 400/400\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 451.1368 - mae: 451.1368 - val_loss: 453.9956 - val_mae: 453.9956\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "loss = pd.read_csv('log_noout.csv',  sep=';')\n",
        "print(loss.head())\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(5,4))\n",
        "ax = sns.lineplot(data=loss, x='epoch', y='mae', label='training')\n",
        "ax = sns.lineplot(data=loss, x='epoch', y='val_mae', label='validation')\n",
        "ax.set_title('after feature engineering')\n",
        "ax.grid()\n",
        "ax.legend()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 420
        },
        "id": "HswUAg_ZmE_w",
        "outputId": "a034427a-d888-417c-df58-d19a918b7656"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   epoch        loss         mae    val_loss     val_mae\n",
            "0      0  496.532837  496.532837  473.600861  473.600861\n",
            "1      1  486.024384  486.024384  462.742096  462.742096\n",
            "2      2  481.290710  481.290710  460.624329  460.624329\n",
            "3      3  479.643158  479.643158  459.165680  459.165680\n",
            "4      4  478.939423  478.939423  458.565948  458.565948\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fb11e1326d0>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 360x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train,y_train,epochs=75,batch_size=64,validation_data=[X_test,y_test])\n",
        "print('Final MAE of validation: %f' %(model.evaluate(X_test, y_test)[1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jiBiiJyomFle",
        "outputId": "9bf76765-b753-4b3e-c78e-77ead6a0336e"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/75\n",
            "237/237 [==============================] - 2s 7ms/step - loss: 449.9264 - mae: 449.9264 - val_loss: 453.5988 - val_mae: 453.5988\n",
            "Epoch 2/75\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 450.9687 - mae: 450.9687 - val_loss: 453.6865 - val_mae: 453.6865\n",
            "Epoch 3/75\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 451.8118 - mae: 451.8118 - val_loss: 453.9709 - val_mae: 453.9709\n",
            "Epoch 4/75\n",
            "237/237 [==============================] - 1s 5ms/step - loss: 452.4342 - mae: 452.4342 - val_loss: 453.8517 - val_mae: 453.8517\n",
            "Epoch 5/75\n",
            "237/237 [==============================] - 1s 4ms/step - loss: 450.5044 - mae: 450.5044 - val_loss: 453.9947 - val_mae: 453.9947\n",
            "Epoch 6/75\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 452.1294 - mae: 452.1294 - val_loss: 453.3079 - val_mae: 453.3079\n",
            "Epoch 7/75\n",
            "237/237 [==============================] - 1s 2ms/step - loss: 450.2321 - mae: 450.2321 - val_loss: 453.2312 - val_mae: 453.2312\n",
            "Epoch 8/75\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 450.8373 - mae: 450.8373 - val_loss: 453.4652 - val_mae: 453.4652\n",
            "Epoch 9/75\n",
            "237/237 [==============================] - 1s 2ms/step - loss: 451.3229 - mae: 451.3229 - val_loss: 453.7874 - val_mae: 453.7874\n",
            "Epoch 10/75\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 451.3162 - mae: 451.3162 - val_loss: 453.4330 - val_mae: 453.4330\n",
            "Epoch 11/75\n",
            "237/237 [==============================] - 1s 2ms/step - loss: 449.9603 - mae: 449.9603 - val_loss: 453.2636 - val_mae: 453.2636\n",
            "Epoch 12/75\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 452.1954 - mae: 452.1954 - val_loss: 453.9844 - val_mae: 453.9844\n",
            "Epoch 13/75\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 450.8403 - mae: 450.8403 - val_loss: 453.8855 - val_mae: 453.8855\n",
            "Epoch 14/75\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 451.5971 - mae: 451.5971 - val_loss: 453.9685 - val_mae: 453.9685\n",
            "Epoch 15/75\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 449.0853 - mae: 449.0853 - val_loss: 453.4999 - val_mae: 453.4999\n",
            "Epoch 16/75\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 454.2317 - mae: 454.2317 - val_loss: 453.8369 - val_mae: 453.8369\n",
            "Epoch 17/75\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 451.2256 - mae: 451.2256 - val_loss: 453.7950 - val_mae: 453.7950\n",
            "Epoch 18/75\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 450.5713 - mae: 450.5713 - val_loss: 454.2354 - val_mae: 454.2354\n",
            "Epoch 19/75\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 451.0711 - mae: 451.0711 - val_loss: 454.5953 - val_mae: 454.5953\n",
            "Epoch 20/75\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 451.7524 - mae: 451.7524 - val_loss: 454.2734 - val_mae: 454.2734\n",
            "Epoch 21/75\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 451.2053 - mae: 451.2053 - val_loss: 454.1126 - val_mae: 454.1126\n",
            "Epoch 22/75\n",
            "237/237 [==============================] - 1s 2ms/step - loss: 449.8870 - mae: 449.8870 - val_loss: 454.1718 - val_mae: 454.1718\n",
            "Epoch 23/75\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 450.8790 - mae: 450.8790 - val_loss: 453.7613 - val_mae: 453.7613\n",
            "Epoch 24/75\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 450.9772 - mae: 450.9772 - val_loss: 453.9995 - val_mae: 453.9995\n",
            "Epoch 25/75\n",
            "237/237 [==============================] - 1s 2ms/step - loss: 451.2090 - mae: 451.2090 - val_loss: 453.7860 - val_mae: 453.7860\n",
            "Epoch 26/75\n",
            "237/237 [==============================] - 1s 2ms/step - loss: 449.9084 - mae: 449.9084 - val_loss: 453.1509 - val_mae: 453.1509\n",
            "Epoch 27/75\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 450.7711 - mae: 450.7711 - val_loss: 453.9449 - val_mae: 453.9449\n",
            "Epoch 28/75\n",
            "237/237 [==============================] - 1s 2ms/step - loss: 451.8024 - mae: 451.8024 - val_loss: 453.3140 - val_mae: 453.3140\n",
            "Epoch 29/75\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 451.2567 - mae: 451.2567 - val_loss: 454.9726 - val_mae: 454.9726\n",
            "Epoch 30/75\n",
            "237/237 [==============================] - 1s 2ms/step - loss: 450.7738 - mae: 450.7738 - val_loss: 454.0410 - val_mae: 454.0410\n",
            "Epoch 31/75\n",
            "237/237 [==============================] - 1s 2ms/step - loss: 450.2046 - mae: 450.2046 - val_loss: 454.2707 - val_mae: 454.2707\n",
            "Epoch 32/75\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 451.9703 - mae: 451.9703 - val_loss: 454.6691 - val_mae: 454.6691\n",
            "Epoch 33/75\n",
            "237/237 [==============================] - 1s 2ms/step - loss: 453.2987 - mae: 453.2987 - val_loss: 454.0527 - val_mae: 454.0527\n",
            "Epoch 34/75\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 451.0555 - mae: 451.0555 - val_loss: 454.4479 - val_mae: 454.4479\n",
            "Epoch 35/75\n",
            "237/237 [==============================] - 1s 2ms/step - loss: 449.7402 - mae: 449.7402 - val_loss: 453.6312 - val_mae: 453.6312\n",
            "Epoch 36/75\n",
            "237/237 [==============================] - 1s 2ms/step - loss: 450.7472 - mae: 450.7472 - val_loss: 454.0940 - val_mae: 454.0940\n",
            "Epoch 37/75\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 451.7263 - mae: 451.7263 - val_loss: 453.9934 - val_mae: 453.9934\n",
            "Epoch 38/75\n",
            "237/237 [==============================] - 1s 2ms/step - loss: 451.4544 - mae: 451.4544 - val_loss: 454.2045 - val_mae: 454.2045\n",
            "Epoch 39/75\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 451.2273 - mae: 451.2273 - val_loss: 453.4789 - val_mae: 453.4789\n",
            "Epoch 40/75\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 449.0698 - mae: 449.0698 - val_loss: 453.7995 - val_mae: 453.7995\n",
            "Epoch 41/75\n",
            "237/237 [==============================] - 1s 2ms/step - loss: 451.4218 - mae: 451.4218 - val_loss: 454.2212 - val_mae: 454.2212\n",
            "Epoch 42/75\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 450.3852 - mae: 450.3852 - val_loss: 454.3715 - val_mae: 454.3715\n",
            "Epoch 43/75\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 451.4637 - mae: 451.4637 - val_loss: 454.5695 - val_mae: 454.5695\n",
            "Epoch 44/75\n",
            "237/237 [==============================] - 1s 2ms/step - loss: 450.4700 - mae: 450.4700 - val_loss: 453.5583 - val_mae: 453.5583\n",
            "Epoch 45/75\n",
            "237/237 [==============================] - 1s 2ms/step - loss: 449.3232 - mae: 449.3232 - val_loss: 453.5551 - val_mae: 453.5551\n",
            "Epoch 46/75\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 450.4916 - mae: 450.4916 - val_loss: 454.3837 - val_mae: 454.3837\n",
            "Epoch 47/75\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 451.0499 - mae: 451.0499 - val_loss: 454.1581 - val_mae: 454.1581\n",
            "Epoch 48/75\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 451.0159 - mae: 451.0159 - val_loss: 454.0560 - val_mae: 454.0560\n",
            "Epoch 49/75\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 450.0535 - mae: 450.0535 - val_loss: 453.9042 - val_mae: 453.9042\n",
            "Epoch 50/75\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 451.2130 - mae: 451.2130 - val_loss: 454.7978 - val_mae: 454.7978\n",
            "Epoch 51/75\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 449.8682 - mae: 449.8682 - val_loss: 454.7417 - val_mae: 454.7417\n",
            "Epoch 52/75\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 448.7750 - mae: 448.7750 - val_loss: 454.8868 - val_mae: 454.8868\n",
            "Epoch 53/75\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 449.2042 - mae: 449.2042 - val_loss: 454.4420 - val_mae: 454.4420\n",
            "Epoch 54/75\n",
            "237/237 [==============================] - 1s 2ms/step - loss: 453.2031 - mae: 453.2031 - val_loss: 454.5302 - val_mae: 454.5302\n",
            "Epoch 55/75\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 450.0838 - mae: 450.0838 - val_loss: 455.1057 - val_mae: 455.1057\n",
            "Epoch 56/75\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 451.8202 - mae: 451.8202 - val_loss: 454.2115 - val_mae: 454.2115\n",
            "Epoch 57/75\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 449.5022 - mae: 449.5022 - val_loss: 453.9066 - val_mae: 453.9066\n",
            "Epoch 58/75\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 452.1926 - mae: 452.1926 - val_loss: 455.2357 - val_mae: 455.2357\n",
            "Epoch 59/75\n",
            "237/237 [==============================] - 1s 2ms/step - loss: 449.8202 - mae: 449.8202 - val_loss: 455.1100 - val_mae: 455.1100\n",
            "Epoch 60/75\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 450.1498 - mae: 450.1498 - val_loss: 454.5721 - val_mae: 454.5721\n",
            "Epoch 61/75\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 450.3035 - mae: 450.3035 - val_loss: 454.2185 - val_mae: 454.2185\n",
            "Epoch 62/75\n",
            "237/237 [==============================] - 1s 2ms/step - loss: 451.0975 - mae: 451.0975 - val_loss: 453.7468 - val_mae: 453.7468\n",
            "Epoch 63/75\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 450.3648 - mae: 450.3648 - val_loss: 454.1801 - val_mae: 454.1801\n",
            "Epoch 64/75\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 452.3102 - mae: 452.3102 - val_loss: 454.7529 - val_mae: 454.7529\n",
            "Epoch 65/75\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 451.0139 - mae: 451.0139 - val_loss: 454.3402 - val_mae: 454.3402\n",
            "Epoch 66/75\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 449.8698 - mae: 449.8698 - val_loss: 453.9639 - val_mae: 453.9639\n",
            "Epoch 67/75\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 449.4158 - mae: 449.4158 - val_loss: 454.2699 - val_mae: 454.2699\n",
            "Epoch 68/75\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 449.8029 - mae: 449.8029 - val_loss: 454.4766 - val_mae: 454.4766\n",
            "Epoch 69/75\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 450.7012 - mae: 450.7012 - val_loss: 454.4013 - val_mae: 454.4013\n",
            "Epoch 70/75\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 450.9801 - mae: 450.9801 - val_loss: 454.3169 - val_mae: 454.3169\n",
            "Epoch 71/75\n",
            "237/237 [==============================] - 1s 2ms/step - loss: 447.3221 - mae: 447.3221 - val_loss: 454.5064 - val_mae: 454.5064\n",
            "Epoch 72/75\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 449.4836 - mae: 449.4836 - val_loss: 454.3582 - val_mae: 454.3582\n",
            "Epoch 73/75\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 450.5959 - mae: 450.5959 - val_loss: 455.0581 - val_mae: 455.0581\n",
            "Epoch 74/75\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 449.8901 - mae: 449.8901 - val_loss: 454.6864 - val_mae: 454.6864\n",
            "Epoch 75/75\n",
            "237/237 [==============================] - 1s 3ms/step - loss: 450.5266 - mae: 450.5266 - val_loss: 454.6939 - val_mae: 454.6939\n",
            "119/119 [==============================] - 0s 1ms/step - loss: 454.6938 - mae: 454.6938\n",
            "Final MAE of validation: 454.693756\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model improved."
      ],
      "metadata": {
        "id": "a-PMMHF06CHZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss3 = pd.read_csv('log_noout.csv',  sep=';')\n",
        "loss2 = pd.read_csv('log_enc.csv',  sep=';')\n",
        "loss1 = pd.read_csv('log.csv',  sep=';')\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(9,6))\n",
        "ax = sns.lineplot(data=loss3, x='epoch', y='mae', label='training_3', color='b',linestyle=\"dashed\")\n",
        "ax = sns.lineplot(data=loss3, x='epoch', y='val_mae', label='validation', color='b')\n",
        "ax = sns.lineplot(data=loss2, x='epoch', y='mae', label='training_2',color='r', linestyle=\"dashed\")\n",
        "ax = sns.lineplot(data=loss2, x='epoch', y='val_mae', label='validation', color='r')\n",
        "ax = sns.lineplot(data=loss1, x='epoch', y='mae', label='training_1', color='k', linestyle=\"dashed\")\n",
        "ax = sns.lineplot(data=loss1, x='epoch', y='val_mae', label='validation', color='k')\n",
        "ax.set_title('Comparison of three models')\n",
        "ax.grid()\n",
        "ax.set_xlim(0,250)\n",
        "ax.legend()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        },
        "id": "RPFLs2kHUNnJ",
        "outputId": "eb0445bb-9b02-4dc1-ee83-9548f3855837"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fb116cfa150>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 648x432 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}